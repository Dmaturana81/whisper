 Hi everybody, welcome to lesson two. Thanks for coming back. A slight change of environment here. We had a bit of an administrative issue at our university, somebody booked our room. I'm doing this from the study at home. Sorry about the lack of decorations behind me. I'm actually really, really pumped about this lesson. It feels like going back to what things were like in the very early days, because we're doing some really new, really cool stuff. Which, you know, stuff that hasn't really been in courses like this before, so I'm super, super excited. So thanks a lot for coming back after lesson one, and I hope it's worth you coming back. I think you're going to love it. I am really excited about this. Now remember that the course goes with the book, so be sure that you're following, I mean not following along in the book, because we're covering similar things in different directions, but like read the book as well. And remember the book is entirely available for free as well. You can go to the fast.io fast book repo to see the notebooks or through course.fast.ai. You can read it there through example through through collab. And also remember that the book, I mean the book's got a lot of stuff that we didn't cover in the course, like, you know, stuff I find pretty interesting about the history of neural networks, some of which has some really interesting personal stories actually, as you'll read here. And at the end of each chapter, there is a quiz. And remember, it's not a bad idea before you watch the video to read the quiz. So if you want to read the chapter two quiz, you know, and then come back. That's not a bad idea. And then make sure that you can do the quiz after you've watched the video and you've read chapter two of the book. Something I didn't mention last week is there's also a very cool thing that Radak, who I mentioned last week, has written called AI quizzes.com, which is a site specifically for quizzes about the book. And it actually uses repetitive space learning techniques to make sure that you never forget. So do check out AI quizzes.com. It's all brand new questions. They're different to the ones in the book. And they're really nicely curated and put together. So check out AI quizzes.com as well. And remember as well as course.fast.ai, there's also forums.fast.ai. So course.fast.ai is where you want to go to get links to all the notebooks and Kaggle stuff and all that stuff. You'll also find on forums.fast.ai, every lesson has an official topic with all the information you'll need. Generally, there'll be a bit more info on the forums. We try to keep the course lean and mean. And the forums are a bit more detailed. So if you find, in this case, you'd want to look at the lesson two official topic, but here's a lesson one official topic so far. So from the lesson one official topic already after just a few days since I recorded it, we haven't even launched the course. So it's just the people doing it live. There's already a lot of replies. And that can get pretty overwhelming. So be aware that there's a button at the bottom of my post that says, summarize this topic. And if you hit that, then you'll just see the most upvoted replies. And that's a really good way to just make sure that you hit on the main stuff. So there's the button. And here's what it looks like after you hit it, you'll just get the upvoted stuff from fast.ai legends like Sanjarm and Tenishk. So hopefully you'll find that a useful way to use the forum. So one of the cool things about this week is I, as promised, put up the show us what you've made post. And already a lot of people have posted. I took the screenshot a few days ago. It's way above 39 replies already, if I remember correctly. I had a lot of trouble deciding which ones to share because they're all so good. So I've actually decided to kind of, you know, went the easy route and I just picked the first. So I'm just going to show you the first ones that were posted because they're also good. So the very, very first one to be posted is a damaged car, classifier. So that worked out pretty well, it looks like. And I really liked what Matt, the creator said about this is that, you know, wow, it's a bit uncomfortable to run this code. I don't really understand yet, but I'm just doing it. And so I'm like, yeah, good on you, Matt, for just doing it. That's the way to get started. It's all going to make sense, don't worry. It's very nice to see that the next one posted was actually a blog post in fast pages. Very nice to see. So just describing some stuff, some experiments that they ran over the week. And what did they find? Next one was the amazing beard detector, which if I understand correctly was mainly because it's very easy to get from bird to beard by just changing one letter to two. And this is doing a very good job of finding gentlemen with beards. So very nice. And then this one is another level again. It's a whole in production web app to classify food, which is kind of like extra credit. Apparently we're up to 80 replies now in that thread. Thank you, Sun Yung. Very cool. So, you know, obviously, so this was actually created by a subash who's been doing the courses for a few years now, I believe. And so, you know, one day you too might be able to create your very own web app and put it in production. And when I say one day, more specifically, today, I'm actually going to show you how to do this right now. So it's actually quite lucky coincidence that the best put this up there because it's exactly the topic that we're going to pick today. So how do we go about putting a model in production? Step one is, well, you've kind of done step one, right? Step one is step one, two, three, four, it's figure out what problem you want to solve, figure out how to find the data for it, gather some data, and so forth. So what's the kind of first step after you've got your data? The next step is data cleaning. And if you go to chapter two of the book, which I'm going to go ahead and open up now. So here is the book. So you can open it in co lab directly from the course, or if you've ploned it to your computer or whatever, you can do it there. So remember, course.fast.ai will run you through exactly how to run these notebooks. And so you can see chapter two is all about putting stuff in production. And so here is chapter two. All right. And so remember, we hit shift enter to run cells, okay, to execute them. And so we're going to go to the part of the book where we start cleaning the data. So I'll click on navigate and we'll go down here, gathering data. There we are. So we could do a quick bit of revision first. Now, by the way, I will mention a lot of people ask me what are the little tricks I use for getting around Jupyter notebook so quickly and easily. One of the really nice ones as you'll see is this navigate menu, which actually doesn't appear by default. So if you install something called Jupyter notebook extensions, Jupyter notebook extensions. And so you just you just pip install them, follow the instructions. And then restart Jupyter. Obviously, this color already has a table of contents, by the way, so this is just if you're using something local, for example, then you'll see here that this nb extension scene will appear. And if you click on table of contents to, that gets you this handy navigation bar. The other thing I really like is this one here called collapsible headings. And that's the one which gives me these nice little things here to close and open up. And actually, that's not even the best part. The best part for me is if I hit right arrow, it goes to the end of a section. And if I hit left arrow, it goes to the start of a section. So it's like if I want to move around sections, it just press up left down right, down right, very handy. And if you hit left again, when you're here, it'll close it up. Hit right again here, open it up. So that's collapsible headings. Anyway, a couple of really handy things. And we'll be talking a lot more about getting your notebook set up today in a moment. Okay, so one thing you'll notice is in the book, we use the Bing API for searching images. I've just kind of had and replaced Bing with DDG because the Bing API requires getting an SDK key, which honestly, it's like the hardest thing in deep learning is figuring out the Bing Azure website and getting that sorted out. DDG doesn't. So it's basically exactly the same. And you can, I'll share this notebook as well on the course website and the forum. But all I've basically done is I've replaced Bing with DDG and got rid of the key. So then just like we did last week, we can search for things. And so in the book, we did a bear detector because at the time I wrote it, my then toddler was very interested in me helping identify teddy bears. And I certainly didn't want to accidentally cuddling a grizzly bear. So we show how here how we can search for grizzly bears just like last week. Something that loops through grizzly bears, black bears and teddy bears just like last week. Get rid of the ones that failed just like last week. And one thing a few people have asked on the forum is how do I find out more information about basically any Python or fast AI or PyTorch thing. There's a few tips here in the book. One is that if you put a double question mark next to any function name, you'll actually get the whole source code for it. And by the same token, if you put a single question mark, you'll get a brief little bit of information. If you've got a nbdev installed, I think it's nbdev you need, then you can type doc and that will give you, perhaps most importantly, a link straight to the documentation. Where you can find out more information. And generally there will be examples as well. And also a link here to the source code if you want to run, let's do that with a control. Okay, a link to the source code and that way you can jump around. Notice that in github in the source code you can click on things and jump to their definition. So it's kind of a nice way of skipping around to understand exactly what's going on. Okay, so lots of correct ways of getting help. But what I promised you is that we're going to now clean the data. So I'm going to tell you something that you might find really surprising. Before you clean the data, you train a model. Now I know that's going to sound really backwards to what you've probably heard a thousand times, which is that first you build, you train your, you clean your data and then you train your model. But I'm going to show you something really amazing. First we're going to train a model. And you'll see why in a moment. So the train a model, just like before, we use a data block to grab our data loaders. There's lots of information here in the book about what's going on here. There we go. And so then we can call show batch to see them as per usual. There's a little sidebar here in the book I'll quickly mention, which is about the different ways we can resize. I think we briefly mentioned it last week. We can squish. Last week I used a string. You can use a string or this kind of enum like thing that we have. You can see with a squish, you can end up with some very thin bears. Right? So this is the real site that's the shape of the bear. Here it's become thin. But you can see now we've got all of its cubs. Is it called cubs? Yeah, bear cubs. So it's squished to make sure we can see the whole picture. Same one here. This one was out of the picture. We squished it. This guy now looks weirdly thin. We can see the whole thing. So that's squishing. Or else this one here is cropping. It's cropped out just the center of the image. So we get a better aspect ratio, but we lose some stuff. This is so we can get square images. And the other approach is we can use pad. And so you can pad with various different things. If you pad with zeros, which is black, you can see here now we've got the whole image and the correct aspect. And the correct aspect ratio. So that's another way we can do it. And you know, different situations result in different quality models. You can try them all. It doesn't normally make too big a difference. I wouldn't worry about it too much. I tell you one though that is very interesting is random resized crop. So instead of saying resize, we can say random resized crop. And if we do that, you'll see we get a different bit of an image every time. So during the week this week, somebody asked on the forum, I'm trying to, this is a really just idea. It turned out worked slightly. Was they wanted to recognize pictures of French and German texts. So obviously this is not the normal way you would do that, but just for a bit of an experiment. And I love experiments. So they had very big scans of documents. And they wanted to figure out whether it was French or German just by looking at images. And they said the pictures were too big. What should I do? I said use random resized crop and that way you would grab different bits of the image. And this is very nice because you could run lots and lots of epochs and get slightly different pictures each time. So this is a very good technique. And this idea of getting different pictures each time from the same image is called data augmentation. And again, I'm not going to go into too much detail about data augmentation because it's in the book. But I'll just quickly point out here that if you use this thing called aug transforms, so augmentation transforms. And here I have multiplied them by two. So I've made them super big so you can see them more easily. You can see that these teddies are getting turned and squished and warped and recolored and saturated. All this stuff to make every picture different. And generally speaking, if you're training for more than about five or ten epochs, which you'll probably want to do most of the time unless you've got a super easy problem to solve, you'll probably want to use random resized crop and these orb transforms. But don't put the molecules to just leave that empty. I'm just putting it there so you can see them more clearly. So I've got an interesting question here from Alex in our audience, which is, is this copying the image multiple times during something like this or something like this? And the answer is no, we're not copying the image. What happens is that image, so each epoch, every image gets red. And what happens here is though is kind of in memory, in RAM, the image is being warped. It's being recropping it and recoloring it and so forth. So it's a real time process that's happening during model training. So there's no copies being stored on your computer, but effectively it's almost like there's infinitely slightly different copies because that's what the model is. So I hope that makes sense, Alex and everybody else. That's a great question. Okay, so we've got, we're going to use random resized crop. We're going to use augmentation transforms so that we get a dirty loaders from that. And then we can go ahead and train our model. It takes about a minute. In this case, we only did four epochs of fine tuning. We'll talk about why there's five here later in the course, but four main epochs of fine tuning. So we probably didn't really need random resized crop and aug transforms because there's so few epochs. But, you know, if you want to run more epochs, this is a good approach. Under 3% error, that's good. Okay, so remember I said we're going to train a model before we clean. Okay, so let's go ahead and train it. So while that's training, that's running on my laptop, which only has a four gigabyte GPU, it's pretty basic, but it's enough to get started. While that's training, we'll take a look at the next one. So the first thing we're going to look at is the confusion matrix. And the confusion matrix is something that it only is meaningful for when your labels are categories, right? And what it says is how, what category errors are you making? And so this is showing that the model that we've got at this point, there was two times when there was actually a grizzly bear, and it thought it was a black bear. And there was two times when there was actually a black bear and it thought it was a grizzly bear, and there was no times that it got Teddy's wrong, which makes sense, right? Because Teddy's too look quite different to both. In a lot of situations, when you look at this, it'll kind of give you a real sense of like, okay, well what are the hard ones, right? So for example, if you use the PETs dataset that we quite often play within the book and of course, this classification matrix for different breeds of PET, you know, really shows you which ones are difficult to identify, and I've actually gone in and like read Wikipedia pages and PET breeding reports about how to identify these particular types because they're so difficult and even experts find it difficult. And one of the things I've learned from during the course actually is black bears and grizzly bears are much harder to pick apart than I had realized, so I'm not even going to try. But I'll show you the really interesting thing we can do with this model is that now we've created this classification interpretation object, which we use for confusion metrics. We can say plot top losses. And this is very interesting. What it does is it tells us the places where the loss is the highest. Now if you remember from the last lesson, the loss is that measurement of how good our model is that we take after each time we run through an item of data. A loss will be bad if we predict wrongly, and we're very confident about that prediction. So here's an example where we predicted is the order here prediction actual loss probability, where we predicted grizzly, and it was actually a black. And we were 96% sure our model was that it's a grizzly. Now, I don't know enough about bears to know whether the model made a mistake or whether this actually is a picture of a grizzly bear. But so an expert would obviously go back and check those out. Now, you'll notice a couple here. It's got grizzly grizzly teddy teddy. They're actually correct. Right. So why is this loss bad when it was correct? And the reason is because it wasn't very confident. It was only 60% confident. Right. So here's a teddy. It's only 72% confident. Right. So you can have a bad loss either by being wrong and confident or being right and uncomfortable. Now, the reason that's really helpful is that now we can use something called the fast AI image classifier cleaner to clean up the ones that are wrongly labeled in our data set. So when we use the image classifier cleaner, it actually runs our models. That's why we pass it learn. Right. And I mentioned that I don't know much about black bears and grizzly bears, but I do know a lot about teddy bears. So I'll pick teddy bears. And if I click teddy bears, it's now showing me all the things in the training set. You can pick training or valid that were marked as teddy bears. And here's what's really important. They're ordered by loss. So they're ordered by confidence. Right. So I can scroll through just the first few and check there. Correct. Right. And oh, here's a mistake. Right. So when I find one that was wrongly gathered, I can either put it if it's in the wrong category. I can choose the correct category. Or if it shouldn't be there at all, I click delete. So here I'll go ahead and click delete. Right. So I can see some reasons that some of these are hard. Like, for example, here's two teddy bears, which is just, I guess, confusing. So it doesn't see that often. This one here is a bit weird looking. It looks almost like a one bat. This is an awful lot of teddy bears. This one maybe is just a bit hard to see from the background, but these otherwise they look fine. Fine. So we just looked through the first few. And if you don't see any problem or problems in the first few, you're probably fine. So that's cleaned up our training set. Let's clean up our validation set as well. So here's that one it had trouble with. I don't know why it had trouble with that one, but so be it. And we'll have a quick scroll through. Okay. I'm not really sure that's a bear. So I'm just going to go ahead and delete it. It's a teddy something. But, you know, it's a problem. Okay, that's not a teddy either. So you see the idea, right? So after we've done that, what that does is the cleaner has now stored a list of the ones that we changed and the list of the ones we deleted. So we can now go ahead and run this cell. And so that's going to go through a list of all of the indexes that we said to delete and it will delete those files. And it'll go through all the ones we said to change and it will move them to the new folder. There we go. Done. So this is like not just something for image models. It's just it's actually a really powerful technique that almost nobody knows about and uses, which is before you start data cleaning, always build a model to find out what things are difficult to recognize in your data and to find the things that the model can help you find data problems. And then as you see them, you're going to say, okay, I see the kinds of problems we're having and you might find better ways to gather the next data set or you might find ways to kind of automate some of the cleaning and so forth. Okay. So that is data cleaning. And since I only have a four gigabyte GPU, it's very important for me to close and halt because that will free up the memory. So it's important to know on your computer, your normal RAM doesn't really get filled up because if you use up too much RAM, what will happen is that instead your computer will start, it's got swapping, which is basically to save that RAM onto the hard disk to use it later. GPUs can't swap. GPUs, when they run out of RAM, that's it. You're done. So you need to make sure that you close any notebooks that are using the GPU that you're not using and really only use one thing at a time on the GPU, otherwise you'll almost certainly run out of memory. So we've got the first few reds starting to appear. So remember to ask. And in terms of the yellows, it's important to know, as you watch the video, I'm not asking you to run all this code. Okay, the idea is to kind of watch it and then go back and pause, you know, as you go along, or you can just stop, try, stop, try. The approach I really like, and a lot of students really like for watching these videos, is to actually watch the entire thing without touching the keyboard to get a sense of what the video is about, and then go back to the start and watch it again and follow along. That way, at every point, you know what it is you're doing, you know what's going to happen next, that can actually save you some time. It's a bit of an unusual way because obviously, like, real life lectures, you can't do that. You can't rewind the professor and get them to say it again, but it's a good way to do it here. So now that we've cleaned our data, how are we going to put it into production? Well, in the book, we use something called Foila, and it's pretty good. But there's actually something that I think most of you are probably going to find a lot more useful nowadays, which is something called hugging face spaces, and there's a couple of things you can use with that. We're going to look at something called Gradio today. And there isn't a chapter about this in the book, but that doesn't matter because Tanishk Abraham, who's actually one of the TAs in the course, has written a fantastic blog post about it. Really everything we're going to cover today. So there's a link to that from the forum and from the course page. So this is like the equivalent of the chapter of the book, if you like. And I would be remiss if I didn't stop for a moment and call out Tanishk in a big way for two reasons. The first is he is one of the most helpful people in the fast AI community. He's been around quite a few years, incredibly tenacious, thoughtful and patient, and also because I have this fantastic picture of him a few years ago with Conan when he was a famous child prodigy. So now you know what happens to famous child prodigies when they grow up. They became even more famous, fast AI community members and declining experts. So you should definitely check out this video of him telling jokes to Conan. I think he's still only 18 actually. This is probably not that many years ago. So thank you very much, Tanishk, for all your help in the community. And sorry if you're embarrassing you with that picture of you as a nine year old. I'm not really hot. Okay. Now, the thing is for doing radio and hugging face spaces, well, it's easy enough to start. Okay, we start over here on the hugging face spaces page, which we've linked to from the forum and the course. And we're going to put a model in production where we're going to take the model we trained. We are going to basically copy it to this hugging face spaces server and write a user interface for it. So, that let's go create new space. Okay, so you can just go ahead and say, all right. So you obviously sign up. The whole thing's free. Basically everything I'm showing you in this entire course, you can do for free. That's a good news. Okay, so give it a name. Just create something minimal. I always use the Apache license because it means other people can use your work really easily, but you don't have to worry too much about patents. If they say there's a few different products you can use with it. We're going to use radio also free. If you make it public, then you can share it, which is always a good idea when you're a student, particularly to really be building up that portfolio. Okay, so we're done. We've created a space. Now, what do we do next? Well, spaces works through Git. Now most software developers will be very familiar with Git. Some data scientists might not be. And so, gets a very, very useful tool. I'm not going to talk about it in detail. But let's kind of quickly learn about how to use it, right? Now, Git, you can use it through something called GitHub Desktop, which is actually pretty great. And even people who use Git through the console should probably be considering using GitHub Desktop as well, because some things just much faster and easier in it. In fact, I was talking to my friend Hamill today, and I was like, Oh, help, I've accidentally committed this two things by mistake. What's the easiest way to revert it? And he used to work at GitHub, and I thought he was going to have some fancy console command, and he was like, Oh, you should use GitHub Desktop, and you can just click on it. Oh, that's a great idea. So that's useful. But most of the time, we do use Git from the console from the terminal. If you're a Linux user or a Mac user, you've already got a terminal very straightforward, no worries. If you're a Windows user, I've got good news. Nowadays, Windows has a terrific terminal. It's called Windows Terminal. You get it from the Microsoft Store. So in fact, every time you see me using a terminal, I'm actually using that Windows Terminal. It works very well. God knows why I'd wanted to have all these ridiculous colors, but there you go. Now, what do you want to be running inside your terminal? Obviously, if you're in Linux or Mac, you've already got a shell set up. In Windows, you almost certainly want to use Ubuntu. So Windows, believe it or not, can actually run a full Linux environment. And to do it is typing a single line, which is this. So if you go to Google for WSL install, run PowerShell as a administrator, post that command, wait about five minutes, reboot your done. You now have a complete Linux environment. Now, one of the reasons I'm mentioning this is I'm going to show you how to do stuff on your own machine now. And so this is like going to a bit of an extra level of geekery, which some data scientists may be less familiar with. So don't be worried about the terminal. You're going to think you're going to find it really helpful and much less scary than you expect. And I particularly say like for me, I choose to use Windows and that's because I get all the nice Windows GUI apps and I can draw on my screen and do presentations and I have a complete Linux environment as well. And that Linux environment uses my GPU and everything. So for me, my first choice is to use Windows. My second choice by not very much really like it would be to use Linux. Mac is a little bit harder, but it's still usable. So some things are a little bit trickier on Mac, but you should be fine. Okay. So whatever you've got at this point, you've now got a terminal available. And so in your terminal, one of the really nice things about using a terminal is you don't have to follow lots of instructions about click here, click here, click here. You just copy and paste things. So I'm just going to go ahead and you just copy this. And you go over to your terminal and you paste it in and you run it. And after you do that, you'll find that you've now got that directory. And so that new directory initially is empty. And they tell you, okay, go ahead and create a file with this in it. Okay. So how do you create a file with that in it when we're in here in our Linux environment, on Windows or in the terminal or Mac or whatever. Well, all you do in Windows, if you just type explorer.exe. It'll open up Explorer here. Or better still on either Mac or Linux or Windows. So yeah, so regardless of what type of computer on, you can just type code. And it will pop up, official studio code and open up your folder. And so then you can just go ahead and if you haven't used VS code before, it's really well worth taking a few minutes to read some tutorials. It's a really great IDE. And so you can go ahead and create an app.py file like they tell you to, app.py file containing what they told you to put in it. Here it is here. All right, we're nearly there. So you can now go ahead and save that. And then you need to commit it to a radio. That's a great idea to hugging first bases. So one really easy way is just in Visual Studio itself, you can just click here. And that'll give you a place where you type a message and you hit tick and it'll send it off to hugging first bases for you. You can then go to back to the exact same website you're on before, hugging space bases, JPHO, minimal. And what you'll find now is that it'll take about a minute to build your website. And the website it's building is going to have a radio interface with a text input, a text output, and it's going to run a function called greet on the input. And my function called greet will return hello name. So that's what it's going to do. There it goes. Let's try it. We'll say hello to Tenish. I'm not always remembering how to spell his name. I think it's like that. And there you go. So you can see it's put the output for our input. So not a very exciting app, but we now have to be fair and app running in production. Now, I told you we'd have a deep learning model running in production. So now we have to take the next step, which is to turn this into a deep learning model. All right. So first we're going to need a deep learning model. And there's a few different ways we can get ourselves a deep learning model. But basically we're going to have to train one. So I've got a couple of examples. I've got a caggle example and a clodalab example. Maybe I'll quickly show you both. They're going to do the same thing. And I'm just going to create a dog or a cat classifier. Okay. So here's our caggle model. I'll click on edit so you can actually see what it looks like in edit view. Now, Caggle already has fast AI installed, but I always put this first just to make sure we've got the latest version. And obviously import stuff. So we're going to grab the pets data set, a function to check whether it's a cat. That's our labeling function for our image data loaders. Remember, this is just another way of doing data blocks. It's like a little shorthand. And we create our learner and we fine tune it. So that's all stuff we've seen before. So in Caggle every notebook has an edit view, which is what you just saw and a read of you. And so you can share your notebook if you want to. And then anybody can read the read of you as you see. And so you can see it shows you what happened when I ran it. And so I trained it. It took, you know, so that the GPUs on Caggle are a bit slower than most modern GPUs, but they're still fast enough. I mean, it takes five minutes. And there's one bit at the end here, which you haven't seen before, which is like I learned on export. And I give it a name. Now that's going to create a file containing our trained model. And that's the only thing. Creating this file is the only thing you need a GPU for. So you do that on Caggle or on CoLab. So here's exactly the same thing on CoLab. You can see pip install is cat, and data, image data loaders. So I've got to show batch here as well, just for fun. Create my learner and then export. So while we wait, I might go ahead and just run that. The nice thing about Caggle is once you've run it and saved it, you can then go to the data tab. And here is basically anything you've saved. It's going to appear here. And here it is, model.pickle. Right. So now I can go ahead and download that. And that will then be downloaded to my Downloads folder. And I need to copy it into the same directory that my HuggingFaceBase is absent. Now my HuggingFaceBase's app is currently open in my terminal. In on Mac, you can type open. or in Windows, you can type explorer.exe. And that will bring up your Finder or Explorer in that directory. And so then you can just paste that thing you downloaded into this directory. Something, by the way, in Windows I do, which I find really helpful, is I actually grab my home directory in Linux, and I pin it to my quick access. And that way I can always jump in Windows straight to my Linux files. Not really saying you have to worry about on Mac because it's all kind of integrated. In Windows they're kind of like two separate machines. Okay. So let's do... So I created a Space Core testing, and I downloaded my model.pickle, and I pasted it into testing. So now we need to know how do we do predictions on a saved model? So we've got a notebook for that. Okay, so we've got a notebook for that. And so I'm going to take you through how we use a model that we've trained to make predictions. There's a few funny things with hash pipe, which I'll explain in a moment, just ignore those for now. So we import Fast.io as usual. We import Gradio as we did before. The copy in the exact same is cat definition we had before. That's important. Any external functions that you used in your labeling need to be included here as well, because that learner refers to those functions. Okay, it saves... That learner's saved everything about your model, but it doesn't have the source code to the function, so you need to keep those with you. So let's try running this. So for example, I just grabbed, as you might have seen in my explorer, I just popped a dog picture there. And so we can create a Python image library image from that dog, turn it into a slightly smaller one, so it doesn't overwhelm our whole screen, and there's a picture of a dog. So how do we make predictions of whether that's a dog or a cat? Well, it's very simple. All we do is instead of training a learner, we use load learner. We pass in the file name that we saved, and that returns a learner. This learner is exactly the same as the learner you get when you finish training. So here we are, here's Colab, right? We've just been training a learner. So at the end of that, there's a learner that's been trained. And so we kind of froze it in time. Something called a pickle file, which is a Python concept. It's like a frozen object. We saved it to disk. We transferred it to our computer, and we've now loaded it, and we've now unfurried thought it. Here's our unpickled learner. And we can now do whatever we like with that. So one of the things that the... One of the methods that a learner has is a.predict method. So if I run it, you can see, even on my laptop, it's a completely instant. In fact, we can see how long it took. In Jupyter, things that start with % are called magics. They're special Jupyter things. So for example, there's a thing to see how long something takes. There you go. Okay, so it took 54 milliseconds to figure out that this is not a cat. So it's returning two things. Is it a cat as a string? Is it a cat as a zero or one? And then the probability that it's a dog and the probability that it's a cat. So the probability of zero, false, and one true of it is a cat. So definitely a dog. So we now want to create a Gradio interface which basically has this information. So a Gradio requires us to give it a function that it's going to call. So here's our function. So we're going to call predict. And that returns as we said three things. The prediction is a string, the index of that, and the probabilities of whether it's a dog or a cat. And what Gradio wants is it wants to get back a dictionary containing each of the possible categories, which in this case is dog or cat, and the probability of each one. So if you haven't done much Python before, a dict of a zip may be something you haven't seen, very handy little idiom, well worth checking out. Did I ever have seen map before? Anyway, here it is. One slightly annoying thing about Gradio at the moment is that it doesn't handle PyTorch tensors. You can see here PyTorch is not returning normal numbers. It's returning tensors. It's not even returning NumPy arrays. In fact, Gradio can't handle NumPy either, so you have to change everything just to a normal float. So that's all that this is doing. It's changing each one to a float. So for example, if I now call classify image with our doggy image, we get back a dictionary of a dog. Yes, definitely cat, definitely not. So now we've got all that. We can go ahead and create a Gradio interface. So Gradio interface is something where we say, well, what function do you call to get the output? What is the input? In this case, we say, oh, the input is an image. So check out the Gradio docs. It can be all kinds of things like a webcam picture or a text or all kinds of things. Give it a shape that it's going to put it into. The output is just going to be a label, so we're going to create a very, very simple interface. So we can also provide some examples, and so there's a dog, a cat, and a donno, which I'll do about in a moment, which you'll see here, there's a dog and a cat and a donno. So once they launch it, it says, OK, that's now running on this URL. So if I open that up, you can see now we have just like a subash, we have our own not yet in production, but running on our own box. Classifier. So let's check dog. You can click and upload one or just choose the examples. Yeah, yeah. So it's running on my own laptop, basically instant. And I really have to tell you this story about this guy here. This is the donno. So wait, why is it saying 100? Normally this says like 5050. That's a bummer. This model has messed up my whole story. The last time I trained this model and I ran it on the donno, it said almost exactly 5050. And the way we found this picture is I showed my six year old daughter, she was like, what are you doing dad? It's like uncoating. What are you coding? Oh, you know, dog cat classifier. She checks it out. And her first question is, can I take your keyboard for a moment? And she goes to Google and she's like, what is a dog mixed with a cat called? There's no such thing as a dog mixed with a cat. Anyway, she goes to the images tab and finds this picture and she's like, look, there's a dog mixed with a cat. She said, run it on that dad. Run it on that. And I ran it and it was like 5050. It had no idea if it was a dog or a cat. Now this model I just retrained today. Now it's sure it's a cat. So there you go. I think I used a slightly different training schedule or something or I gave it an extra epoch anyway. So that's a dog cat. But apparently it's a cat. I guess it is a cat. It's probably right. Shouldn't have trained it for as long. Okay, so there's our interface. Now that's actually running. So you actually have to click the stop button to stop it running. So otherwise you won't be able to do anything else near a notebook. Okay. So now we have to turn that into a Python script. So one way to turn it into a Python script would be to copy and paste into a Python script all the things that you need. I would read a copy and paste into a Python script all the parts of this that you need. So for example, we wouldn't need this. It's just to check something out. We wouldn't need this. It was just experimenting. This was just experimenting. We'd need this. So what I did is I went through and I wrote hash pipe export at the top of each cell that contains information that I'm going to need in my final script. And then, so there are the steps, right? And then at the very bottom here, I've imported something called notebook to script from nbdev. And if I run that and pass in the name of this notebook, that creates a file for me called app.py containing that script. So this is a nice easy way to, like, when you're working with stuff that's expecting a script and not a notebook, like hugging first bases does, it's fine to just copy and paste into a text file if you like. But I really like this way of doing it because that way I can do all of my experimentation in a notebook. And when I'm done, I just have to sell at the bottom. I just run and export it. How does that know to call it app.py? That's because there's a special thing at the top default export, default X, which says what Python file name to create. So that's just a little trick that I use. So now we've got an app.py. We need to upload this to Gradio. How do we do that? You just push it to get. So you can either do it with Visual Studio Code or you can type git commit and then git push. And once you've done that, if we change minimal to testing, I think this hopefully might still be running my previous model because I didn't push it. And that way we can see our crazy dog cat. All right. So here it is. You can see it running in production. So now this is something that anybody can, if you set it to public, anybody can go here and check out your model. And so they can upload it. And so here's my doggy. Yep. Definitely a dog cat. Yeah. I think I might have trained this for epoch or two less. So it's less confident. Yeah. Definitely a cat. Dog cat. Hey, dog cat. Hmm. Still thinks it's definitely a cat. Oh, well, so be it. Okay. So that is. Okay. So that is an example of getting a simple model in production. There's a couple of questions from the forum from the community. Okay. So one person's asking, what's the difference between a PyTorch model and a fast AI learner? Okay. That's fine. We will get to that shortly. Don't offer a bit less than it might be this lesson or the next lesson. And then somebody else asked, basically it's asking how many epochs do we train for? So as you train a model, your error rate, as you can see, it improves. And so the question is, should I run more? Should I increase the number of epochs? This is doing three epochs, right? Here's my three epochs plus one to get started. Look, it's up to you, right? I mean, this is here saying there's a 1% error. I'm okay with a 1% error. You know, if you want it to be better, then you could use more data augmentation and you could train it for longer. If you train for long enough, as we'll learn about soon in the next, maybe the next lesson, if you train for long enough, your error rate actually starts getting worse. And you'll see, we'll learn a bit more. So basically, yeah, you can train until it's good enough or until you run out of patience or time or run out of compute or until the error rate starts getting worse. Okay. Oh, and then in CoLab, how do you grab your model? All you need to do in CoLab is after you've exported it is if you go into their file browser, you'll actually see it here, right? And you can click download. It's a bit weird. It doesn't like pop up a box saying where do you want to download it to? But instead, this kind of progress circle thing pops up. And so depending on how big it is and so forth, it can take a few minutes. And once that circle fills up, then it'll browse a thing or finally pop up and say, okay, you can save it. Okay. So that's how you actually grab your model. So as you can see, the step where you actually need a GPU, you can use these totally free resources, CoLab, Kaggle. There are other ones we'll talk about in future lessons. And then you can do everything else on your own computer, including the predictions. The predictions are fast, right? So you really don't need to use a GPU for that unless you're doing thousands of them. Okay. Here we go. Now it's asking me to save it. Okay. So now one big issue is we needed to run it on our computer. We needed Python and Jupyter Notebooks running on our computer. So how do you do that? Because this is where often people get in all kinds of trouble. I'm trying to figure out how to get this all working. So the good news is we've actually got something that makes it very, very straightforward. It's called fast set up. There's really only just one part of it you need. So let me show you. It's actually a Git repository on GitHub. GitHub's the place where most Git repositories live. So if you go to GitHub, fast.io, fast set up, you'll see it. And so what you can do is you can now grab this whole repository just by clicking here on code. And if you've got GitHub desktop installed, click on open with GitHub desktop. And as you'll see, it brings this up saying, okay, I'm ready to save this for you. So I'll click clone. So it's making a copy of it. There we go. So basically, once you've cloned it, you'll then find there's a file in there called setup conda.sh, which the details don't really matter. It's pretty short. But that's the thing that's going to install Python for you. So at that point, you can just run.slash setup conda and it'll run this installer. Now, if you've got Linux or Mac, you've already got Python on your machine. Don't use that Python. And the reason is because that Python is called the system Python, it's used by your computer to do computer stuff, right? It's actually needed. You don't want to be messing with it. I promise you. It always leads to disaster always. You want your own development version of Python. It's also going to make sure you've got the latest version and all the libraries you want. By far, the best one for you is almost certainly going to be these conda based Python distribution. So if you run setup conda, you'll get the one that we recommend. The one we recommend at the moment is something called mamba forge. So basically, once you run it, you'll find that you've now and you close your terminal and reopen it, you'll find you've now got one extra command, which is called mamba. And mamba lets you install stuff. So once you've run it, you'll be able to go mamba, install fast.io. And that's going to actually, we should probably, I should mention this actually more, bit more detail about how to install it correctly. If we go to docs.fast.io installing. Yeah, okay. We actually want to do conda install minus C first chain first. So this is copy and paste. Oh, sorry, not actually. And then the other thing I'll say is instead of using conda, replace conda with mamba because nowadays it's much faster. So mamba install minus C first chain first. Now, this is going to install everything you need. It's going to install pytorch. It's going to install numpy. It's going to install fast.io and so forth. And it's obviously, I've already got it. And then the other thing you'll want to do is install nbdev. So you can do exactly the same thing for nbdev. You don't have to. Right? It's just that, but that'll install Jupyter for you amongst other things. And so at that point, you can now use Jupyter. And so the way Jupyter works is, we can see it over here. This is my, I'll go ahead and close it so we can start again. So basically to use Jupyter, you just type Jupyter notebook. And when you run it, it'll say, okay, we're now running a server for you. And so if you click on that hyperlink, it'll pop up this. Okay, which is exactly what you see me use all the time. Okay. So that hopefully is enough to kind of get you started with Python and with Jupyter notebook. The other way people tend to install software is using something called pip instead of mamba. Pretty much anything you can do with mamba, you can also do with pip. But if you've got a GPU, pip isn't going to install things generally so that it works on your GPU. You have to install lots of other stuff, which is annoying. So that's why I kind of tell people to use mamba, but you can use pip otherwise. Still a little bit of red. Please let us know how we can help you gain. Okay, so let's see how we're going with our steps. I forgot I had these steps here to remind myself. We created a space tick. We created a basic interface tick. Okay, we got get set up. We got Conda and set up or mamba. So mamba and Conda are the same thing. Mamba is just a much faster version. And we'll keep some notes on the course website because at the moment they're actually working on including the speedups from mamba into Conda. So at some point, maybe it'll be fine to use Conda again. At the moment Conda is way too slow. Okay, we've done docs versus cats. No problem. Yeah, so we could also look at pet grades. Yeah, we'll be able to look at that. Okay, we've used an exported learner. No problem, we used to envy dev. No problem. Okay, try the API. All right, this is interesting. So I think we can all agree hopefully that this is pretty cool that we can provide to anybody who wants to use it for free, a real working model. And you know, with Gradyo, there's actually, you know, a really small amount of flexibility around like how you can make your website look, you know, using these various different widgets. It's not amazingly flexible, but it's flexible enough to kind of, it's really just for prototyping, right? So Gradyo has lots of widgets and things that you can use. The other main platform at the moment that hugging first basis supports is called Streamlit. Streamlit is more flexible. I would say than Gradyo, not quite as easy to get started with, but you know, it's kind of that nice in between, I guess. So also a very good thing. Again, mainly if you're kind of building prototypes, but at some point you're going to want to build more than a prototype. You want to build an app, right? And one of the things I really like about Gradyo in hugging face spaces is there's a button down here, view the API. So we can actually create any app we want. And the key point is that the thing that does the actual model predictions for us is going to be handled by hugging face spaces, Gradyo, right? And then we can write a JavaScript application that then talks to that. Now there's going to be two reactions here. Anybody who's done some front end engineering is going to be like, oh, great. I can now literally create anything in the world because I just write any code and I can do it. And I'll be excited. And a lot of data scientists might be going, oh, I have no idea how to use JavaScript. It's not in my inventory. So this is again where I'm going to say, look, don't be too afraid of JavaScript. I mean, obviously one option here is just to kind of say, hey, I've got a model, throw it over to the wall to your mate who does no JavaScript and say, please create a JavaScript interface for me. But let me just give you a sense of like how really not hard this actually is. So there's a endpoint. There's now a URL that's running with our model on it. And if you pass it some data and image some image data to this URL, it's going to return back the dictionary. So it's going to do exactly the same thing that this UI does, but as an API as a function we can call. And so it's got like examples here of how to call it. So for example, I can actually let me show you the API as an example using that minimal interface we had because it's just going to be a bit simpler. So if I click curl and I copy that, copy that and paste. So you can see there, oh, that's not a great example passing in hello world. So if I pass in tenish again, let's see how I'm going with his name tenish. Okay, so he returns back hello to niche. So this is how these APIs work, right? So we can use JavaScript to call the API and we've got some examples. So I've created a website and here is my website, tiny pets. And on this website, as you can see, it's not the most amazingly beautiful thing, but it's a website. It's a start, right? And up here I've got some examples. Here you go, single file, click, choose file, click. And in this example, I'm actually doing full pet classification. So I actually trained a model to classify breed, which we'll talk about more next week, rather than just dog versus cat. So let's pick a particular breed and we run it. Oh, and there it is. Now, not very amazing, right? But the fact is that this is now a JavaScript app means we have no restrictions about what we can do. And let's take a look at that HTML. That's it. It easily fits in a screen, right? And the basic steps are not crazy, right? It's basically we create an import for our photo. We add an event listener that says when you change the photo, call the read function. The read function says create a file reader, read the file. And when you finished loading, call loaded, and then loaded says fetch that. Now that path there is that path there, right? Except we're doing the full pets one. So this is basically just copied and pasted from there, from their sample. And then grab the JSON and then grab from the data, the first thing, the conferences, the label, and then set the HTML. So as you can see, it's like, okay, if you haven't used JavaScript before, these are all new things, right? But they're not, it's not harder than Python, right? It's just another language to learn. And so from here, you can start to build up, right? So for example, we've created a multi file version. So with the multi file version, let me see, multi file, choose. So we can now click a few. So we've got a new fee, a rag doll, a basset hound, and some kind of cat. I'm not much for cat person. So we chose four files and bang, all being classified. Apparently it's a bengal, I wouldn't know. Here's our new found. So there's the multi file version. And if you look at the code, it's not much more, right? It's now just doing, it's getting all the files and mapping them to read and now appending each one. So not much more codable. And as you might have seen on our site here, there's a few more examples, which is some of the community during the week has created their own versions. So this one here is, I think this is, yeah, this is from one of the radio guys. They call it get to know your pet. So if I choose a pet, I kind of, I really like this because it actually combines two models. So first of all, it says, oh, it's a basset hound. And then it lets me type in and ask things about it. So I can say, oh, what kind of tail does it have? Search. And so that's now going to call an NLP model, which asks about this. Oh, it's a curved saber tail. There we go. What maintenance does it need? So again, like here, you can kind of see how, oh, a basset hound's ears must be cleaned and sorted out frequently. So this is like combining models. So you can see this is something that you couldn't do with just a kind of a ready to go interface. And so the next thing I wanted to point out is how did we create the website? I showed you how to create an HTML file. But like, how do you create those and how do you make a website out of them? Well, watch this. Let's here's a, here's the source code to our most basic version. Okay. So I could just save this. There we go. Okay. So we can open that with Visual Studio Code. And what we could actually do is we could, here it just is an explorer or Mac and Finder. I could just double click on it. And here it is. It's a working app. So you can see I don't need any software installed on my computer to use a JavaScript app, right? It's a single file. I just run it in a browser. A browser is our complete execution environment. It's got a debugger. It's got the whole thing. So here you can, you know, here you can see it's, it's just calling out to this external hugging faces end point. So I can do it all sitting here on my computer. So once I've got my HTML file that's working fine on my computer in VS Code, how do I then put it on the web so that other people can use it? Again, the whole thing's free. There's a really cool thing called GitHub Pages, which basically will host your website for you. And because it's just JavaScript, it'll, it'll all work just fine. The easiest way to create a GitHub Pages site, in my opinion, is to use something called Fast Pages, which is a fast AI thing. And basically all you do is you follow the setup process. So first it does, let's just go through it. So it says, generate a copy by clicking on this link. So I click the link. All right. Okay. Give it a name. I try to make everything public. I always think it's good, good practice. You don't have to create repo, generating. Okay. And then there's basically two more steps. It takes about five minutes. We don't have five minutes. I'll show you the one that I've already built, which is fast AI slash tiny pets. And so once it's done, you'll basically end up with this empty site, which again, you just go code, open with GitHub desktop, or open with Visual Studio, whatever. So open with GitHub desktop, or you can copy and paste this to your terminal. And so any one of those is going to get you this whole thing on your computer. You can save your HTML files there, push it back up to GitHub. And what you'll find is we'll, we'll, fast pages will show you the link to the website that is created for you. Now the website that's created for you, you can make it look however you want using something called a theme. So you'll see it's created a file called config.yaml, where you can pick a theme. So in this case, I picked a theme called a limbic, for no particular reason. So GitHub pages uses them in called jackle. And so any jackle theme will, will basically work. So I picked out this theme. And so as a result, when I now save things into this repo, they will automatically appear in this website. And the files automatically appear up here in this list. So if you look at my index, that's the home page, the entire file is just this. The only slightly weird thing is at the top of every GitHub pages file, you have to have three dashes, title and layout and three dashes. It's called front meta. And so once you do that and save it, it will appear in your website. So something else I did then is like, okay, well, that's all very well that Fast.i has created this website, but I don't really like what it looks like. I would have created a different version. No worries. You can go to Fast.i tiny pets and click fork. And when you click fork, it's going to create your own copy. So I did that under my personal account, which is JPH00. And look, I've got my own version of it. And now I can make changes here. So I made a few changes. One change I made was I went to config.yaml and I changed the theme to pages themes hacker. So once you fork, one thing you have to do, which normally fast pages does for you is you do have to go to settings and click pages and actually enable GitHub pages. So you basically have to, by default, it's turned off. So here you'll just have to turn it on. So use the master branch route save. And then it'll say no worries. It's ready to be published. And so I changed the config.yaml file to point at a different theme. And so if you look at now the JPH is tiny pets. It's different. Okay. So it's got the same info, but it's much more hackarish because JPH00 is a serious hacker, as you can tell from his website. So anyway, look, it's a very brief taste of this kind of world of JavaScript and websites and so forth. But I wanted to give you a sense of like, you know, you don't need any money. You don't need any IDEs. You don't really need much code to get started with writing your own web apps. And thanks to hugging face spaces, you know, they'll even host your model for you. And all you need to do is just have the magic string with a thing to call. Okay. So signing out hacker, Jeremy Howard. Thanks very much for watching. And in the next lesson, we're going to be digging into some natural language processing. We're going to be doing some of the same stuff, but we're going to be doing it with language rather than pictures. And we're going to be diving under the hood to see how these models actually work. We're going to learn about things like stochastic gradient descent. And we might even be having to brush off a little bit of calculus. I hope I haven't put you off by saying the C word. We'll see you next time. Thanks all. Okay.
