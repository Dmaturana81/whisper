WEBVTT

00:00.000 --> 00:05.000
 Hi everybody, welcome to lesson two. Thanks for coming back.

00:05.000 --> 00:13.000
 A slight change of environment here. We had a bit of an administrative issue at our university, somebody booked our room.

00:13.000 --> 00:23.000
 I'm doing this from the study at home. Sorry about the lack of decorations behind me.

00:23.000 --> 00:40.000
 I'm actually really, really pumped about this lesson. It feels like going back to what things were like in the very early days, because we're doing some really new, really cool stuff.

00:40.000 --> 00:46.000
 Which, you know, stuff that hasn't really been in courses like this before, so I'm super, super excited.

00:46.000 --> 00:57.000
 So thanks a lot for coming back after lesson one, and I hope it's worth you coming back. I think you're going to love it. I am really excited about this.

00:57.000 --> 01:10.000
 Now remember that the course goes with the book, so be sure that you're following, I mean not following along in the book, because we're covering similar things in different directions, but like read the book as well.

01:10.000 --> 01:20.000
 And remember the book is entirely available for free as well. You can go to the fast.io fast book repo to see the notebooks or through course.fast.ai.

01:20.000 --> 01:29.000
 You can read it there through example through through collab.

01:29.000 --> 01:46.000
 And also remember that the book, I mean the book's got a lot of stuff that we didn't cover in the course, like, you know, stuff I find pretty interesting about the history of neural networks, some of which has some really interesting personal stories actually, as you'll read here.

01:46.000 --> 01:58.000
 And at the end of each chapter, there is a quiz. And remember, it's not a bad idea before you watch the video to read the quiz. So if you want to read the chapter two quiz, you know, and then come back.

01:58.000 --> 02:07.000
 That's not a bad idea. And then make sure that you can do the quiz after you've watched the video and you've read chapter two of the book.

02:07.000 --> 02:19.000
 Something I didn't mention last week is there's also a very cool thing that Radak, who I mentioned last week, has written called AI quizzes.com, which is a site specifically for quizzes about the book.

02:19.000 --> 02:31.000
 And it actually uses repetitive space learning techniques to make sure that you never forget. So do check out AI quizzes.com. It's all brand new questions. They're different to the ones in the book.

02:31.000 --> 02:39.000
 And they're really nicely curated and put together. So check out AI quizzes.com as well.

02:39.000 --> 02:55.000
 And remember as well as course.fast.ai, there's also forums.fast.ai. So course.fast.ai is where you want to go to get links to all the notebooks and Kaggle stuff and all that stuff.

02:55.000 --> 03:10.000
 You'll also find on forums.fast.ai, every lesson has an official topic with all the information you'll need. Generally, there'll be a bit more info on the forums. We try to keep the course lean and mean.

03:10.000 --> 03:23.000
 And the forums are a bit more detailed. So if you find, in this case, you'd want to look at the lesson two official topic, but here's a lesson one official topic so far.

03:23.000 --> 03:35.000
 So from the lesson one official topic already after just a few days since I recorded it, we haven't even launched the course. So it's just the people doing it live.

03:35.000 --> 03:48.000
 There's already a lot of replies. And that can get pretty overwhelming. So be aware that there's a button at the bottom of my post that says, summarize this topic.

03:48.000 --> 03:58.000
 And if you hit that, then you'll just see the most upvoted replies. And that's a really good way to just make sure that you hit on the main stuff.

03:58.000 --> 04:09.000
 So there's the button. And here's what it looks like after you hit it, you'll just get the upvoted stuff from fast.ai legends like Sanjarm and Tenishk.

04:09.000 --> 04:14.000
 So hopefully you'll find that a useful way to use the forum.

04:14.000 --> 04:23.000
 So one of the cool things about this week is I, as promised, put up the show us what you've made post.

04:23.000 --> 04:34.000
 And already a lot of people have posted. I took the screenshot a few days ago. It's way above 39 replies already, if I remember correctly.

04:34.000 --> 04:47.000
 I had a lot of trouble deciding which ones to share because they're all so good. So I've actually decided to kind of, you know, went the easy route and I just picked the first.

04:47.000 --> 04:58.000
 So I'm just going to show you the first ones that were posted because they're also good. So the very, very first one to be posted is a damaged car, classifier.

04:58.000 --> 05:09.000
 So that worked out pretty well, it looks like. And I really liked what Matt, the creator said about this is that, you know, wow, it's a bit uncomfortable to run this code.

05:09.000 --> 05:15.000
 I don't really understand yet, but I'm just doing it. And so I'm like, yeah, good on you, Matt, for just doing it.

05:15.000 --> 05:20.000
 That's the way to get started. It's all going to make sense, don't worry.

05:20.000 --> 05:31.000
 It's very nice to see that the next one posted was actually a blog post in fast pages. Very nice to see. So just describing some stuff, some experiments that they ran over the week.

05:31.000 --> 05:33.000
 And what did they find?

05:33.000 --> 05:42.000
 Next one was the amazing beard detector, which if I understand correctly was mainly because it's very easy to get from bird to beard by just changing one letter to two.

05:42.000 --> 05:48.000
 And this is doing a very good job of finding gentlemen with beards. So very nice.

05:48.000 --> 05:59.000
 And then this one is another level again. It's a whole in production web app to classify food, which is kind of like extra credit.

05:59.000 --> 06:06.000
 Apparently we're up to 80 replies now in that thread. Thank you, Sun Yung.

06:06.000 --> 06:10.000
 Very cool.

06:10.000 --> 06:23.000
 So, you know, obviously, so this was actually created by a subash who's been doing the courses for a few years now, I believe.

06:23.000 --> 06:30.000
 And so, you know, one day you too might be able to create your very own web app and put it in production.

06:30.000 --> 06:37.000
 And when I say one day, more specifically, today, I'm actually going to show you how to do this right now.

06:37.000 --> 06:45.000
 So it's actually quite lucky coincidence that the best put this up there because it's exactly the topic that we're going to pick today.

06:45.000 --> 06:51.000
 So how do we go about putting a model in production?

06:51.000 --> 07:08.000
 Step one is, well, you've kind of done step one, right? Step one is step one, two, three, four, it's figure out what problem you want to solve, figure out how to find the data for it, gather some data, and so forth.

07:08.000 --> 07:13.000
 So what's the kind of first step after you've got your data?

07:13.000 --> 07:23.000
 The next step is data cleaning. And if you go to chapter two of the book, which I'm going to go ahead and open up now.

07:23.000 --> 07:27.000
 So here is the book.

07:27.000 --> 07:34.000
 So you can open it in co lab directly from the course, or if you've ploned it to your computer or whatever, you can do it there.

07:34.000 --> 07:40.000
 So remember, course.fast.ai will run you through exactly how to run these notebooks.

07:40.000 --> 07:44.000
 And so you can see chapter two is all about putting stuff in production.

07:44.000 --> 07:46.000
 And so here is chapter two.

07:46.000 --> 07:53.000
 All right. And so remember, we hit shift enter to run cells, okay, to execute them.

07:53.000 --> 07:59.000
 And so we're going to go to the part of the book where we start cleaning the data.

07:59.000 --> 08:05.000
 So I'll click on navigate and we'll go down here, gathering data.

08:05.000 --> 08:08.000
 There we are.

08:08.000 --> 08:20.000
 So we could do a quick bit of revision first. Now, by the way, I will mention a lot of people ask me what are the little tricks I use for getting around Jupyter notebook so quickly and easily.

08:20.000 --> 08:25.000
 One of the really nice ones as you'll see is this navigate menu, which actually doesn't appear by default.

08:25.000 --> 08:37.000
 So if you install something called Jupyter notebook extensions, Jupyter notebook extensions.

08:37.000 --> 08:46.000
 And so you just you just pip install them, follow the instructions.

08:46.000 --> 08:48.000
 And then restart Jupyter.

08:48.000 --> 09:00.000
 Obviously, this color already has a table of contents, by the way, so this is just if you're using something local, for example, then you'll see here that this nb extension scene will appear.

09:00.000 --> 09:05.000
 And if you click on table of contents to, that gets you this handy navigation bar.

09:05.000 --> 09:11.000
 The other thing I really like is this one here called collapsible headings.

09:11.000 --> 09:19.000
 And that's the one which gives me these nice little things here to close and open up.

09:19.000 --> 09:26.000
 And actually, that's not even the best part. The best part for me is if I hit right arrow, it goes to the end of a section.

09:26.000 --> 09:29.000
 And if I hit left arrow, it goes to the start of a section.

09:29.000 --> 09:35.000
 So it's like if I want to move around sections, it just press up left down right, down right, very handy.

09:35.000 --> 09:38.000
 And if you hit left again, when you're here, it'll close it up.

09:38.000 --> 09:40.000
 Hit right again here, open it up.

09:40.000 --> 09:41.000
 So that's collapsible headings.

09:41.000 --> 09:43.000
 Anyway, a couple of really handy things.

09:43.000 --> 09:48.000
 And we'll be talking a lot more about getting your notebook set up today in a moment.

09:48.000 --> 09:57.000
 Okay, so one thing you'll notice is in the book, we use the Bing API for searching images.

09:57.000 --> 10:05.000
 I've just kind of had and replaced Bing with DDG because the Bing API requires getting an SDK key,

10:05.000 --> 10:13.000
 which honestly, it's like the hardest thing in deep learning is figuring out the Bing Azure website and getting that sorted out.

10:13.000 --> 10:14.000
 DDG doesn't.

10:14.000 --> 10:19.000
 So it's basically exactly the same.

10:19.000 --> 10:25.000
 And you can, I'll share this notebook as well on the course website and the forum.

10:25.000 --> 10:30.000
 But all I've basically done is I've replaced Bing with DDG and got rid of the key.

10:30.000 --> 10:35.000
 So then just like we did last week, we can search for things.

10:35.000 --> 10:45.000
 And so in the book, we did a bear detector because at the time I wrote it, my then toddler was very interested in me helping identify teddy bears.

10:45.000 --> 10:50.000
 And I certainly didn't want to accidentally cuddling a grizzly bear.

10:50.000 --> 10:56.000
 So we show how here how we can search for grizzly bears just like last week.

10:56.000 --> 11:02.000
 Something that loops through grizzly bears, black bears and teddy bears just like last week.

11:02.000 --> 11:06.000
 Get rid of the ones that failed just like last week.

11:06.000 --> 11:19.000
 And one thing a few people have asked on the forum is how do I find out more information about basically any Python or fast AI or PyTorch thing.

11:19.000 --> 11:23.000
 There's a few tips here in the book.

11:23.000 --> 11:31.000
 One is that if you put a double question mark next to any function name, you'll actually get the whole source code for it.

11:31.000 --> 11:43.000
 And by the same token, if you put a single question mark, you'll get a brief little bit of information.

11:43.000 --> 12:01.000
 If you've got a nbdev installed, I think it's nbdev you need, then you can type doc and that will give you, perhaps most importantly, a link straight to the documentation.

12:01.000 --> 12:05.000
 Where you can find out more information.

12:05.000 --> 12:09.000
 And generally there will be examples as well.

12:09.000 --> 12:15.000
 And also a link here to the source code if you want to run, let's do that with a control.

12:15.000 --> 12:19.000
 Okay, a link to the source code and that way you can jump around.

12:19.000 --> 12:25.000
 Notice that in github in the source code you can click on things and jump to their definition.

12:25.000 --> 12:36.000
 So it's kind of a nice way of skipping around to understand exactly what's going on.

12:36.000 --> 12:42.000
 Okay, so lots of correct ways of getting help.

12:42.000 --> 12:46.000
 But what I promised you is that we're going to now clean the data.

12:46.000 --> 12:51.000
 So I'm going to tell you something that you might find really surprising.

12:51.000 --> 12:55.000
 Before you clean the data, you train a model.

12:55.000 --> 13:05.000
 Now I know that's going to sound really backwards to what you've probably heard a thousand times, which is that first you build, you train your, you clean your data and then you train your model.

13:05.000 --> 13:08.000
 But I'm going to show you something really amazing.

13:08.000 --> 13:10.000
 First we're going to train a model.

13:10.000 --> 13:11.000
 And you'll see why in a moment.

13:11.000 --> 13:16.000
 So the train a model, just like before, we use a data block to grab our data loaders.

13:16.000 --> 13:25.000
 There's lots of information here in the book about what's going on here.

13:25.000 --> 13:27.000
 There we go.

13:27.000 --> 13:33.000
 And so then we can call show batch to see them as per usual.

13:33.000 --> 13:39.000
 There's a little sidebar here in the book I'll quickly mention, which is about the different ways we can resize.

13:39.000 --> 13:41.000
 I think we briefly mentioned it last week.

13:41.000 --> 13:44.000
 We can squish.

13:44.000 --> 13:45.000
 Last week I used a string.

13:45.000 --> 13:48.000
 You can use a string or this kind of enum like thing that we have.

13:48.000 --> 13:53.000
 You can see with a squish, you can end up with some very thin bears.

13:53.000 --> 13:54.000
 Right?

13:54.000 --> 13:56.000
 So this is the real site that's the shape of the bear.

13:56.000 --> 13:57.000
 Here it's become thin.

13:57.000 --> 14:00.000
 But you can see now we've got all of its cubs.

14:00.000 --> 14:01.000
 Is it called cubs?

14:01.000 --> 14:02.000
 Yeah, bear cubs.

14:02.000 --> 14:05.000
 So it's squished to make sure we can see the whole picture.

14:05.000 --> 14:06.000
 Same one here.

14:06.000 --> 14:07.000
 This one was out of the picture.

14:07.000 --> 14:08.000
 We squished it.

14:08.000 --> 14:10.000
 This guy now looks weirdly thin.

14:10.000 --> 14:11.000
 We can see the whole thing.

14:11.000 --> 14:12.000
 So that's squishing.

14:12.000 --> 14:14.000
 Or else this one here is cropping.

14:14.000 --> 14:16.000
 It's cropped out just the center of the image.

14:16.000 --> 14:19.000
 So we get a better aspect ratio, but we lose some stuff.

14:19.000 --> 14:21.000
 This is so we can get square images.

14:21.000 --> 14:24.000
 And the other approach is we can use pad.

14:24.000 --> 14:26.000
 And so you can pad with various different things.

14:26.000 --> 14:31.000
 If you pad with zeros, which is black, you can see here now we've got the whole image and the correct aspect.

14:31.000 --> 14:33.000
 And the correct aspect ratio.

14:33.000 --> 14:35.000
 So that's another way we can do it.

14:35.000 --> 14:41.000
 And you know, different situations result in different quality models.

14:41.000 --> 14:42.000
 You can try them all.

14:42.000 --> 14:44.000
 It doesn't normally make too big a difference.

14:44.000 --> 14:47.000
 I wouldn't worry about it too much.

14:47.000 --> 14:52.000
 I tell you one though that is very interesting is random resized crop.

14:52.000 --> 14:58.000
 So instead of saying resize, we can say random resized crop.

14:58.000 --> 15:04.000
 And if we do that, you'll see we get a different bit of an image every time.

15:04.000 --> 15:11.000
 So during the week this week, somebody asked on the forum, I'm trying to, this is a really just idea.

15:11.000 --> 15:13.000
 It turned out worked slightly.

15:13.000 --> 15:22.000
 Was they wanted to recognize pictures of French and German texts.

15:22.000 --> 15:26.000
 So obviously this is not the normal way you would do that, but just for a bit of an experiment.

15:26.000 --> 15:28.000
 And I love experiments.

15:28.000 --> 15:30.000
 So they had very big scans of documents.

15:30.000 --> 15:34.000
 And they wanted to figure out whether it was French or German just by looking at images.

15:34.000 --> 15:36.000
 And they said the pictures were too big.

15:36.000 --> 15:37.000
 What should I do?

15:37.000 --> 15:41.000
 I said use random resized crop and that way you would grab different bits of the image.

15:41.000 --> 15:49.000
 And this is very nice because you could run lots and lots of epochs and get slightly different pictures each time.

15:49.000 --> 15:51.000
 So this is a very good technique.

15:51.000 --> 15:57.000
 And this idea of getting different pictures each time from the same image is called data augmentation.

15:57.000 --> 16:06.000
 And again, I'm not going to go into too much detail about data augmentation because it's in the book.

16:06.000 --> 16:14.000
 But I'll just quickly point out here that if you use this thing called aug transforms, so augmentation transforms.

16:14.000 --> 16:17.000
 And here I have multiplied them by two.

16:17.000 --> 16:19.000
 So I've made them super big so you can see them more easily.

16:19.000 --> 16:28.000
 You can see that these teddies are getting turned and squished and warped and recolored and saturated.

16:28.000 --> 16:31.000
 All this stuff to make every picture different.

16:31.000 --> 16:42.000
 And generally speaking, if you're training for more than about five or ten epochs, which you'll probably want to do most of the time unless you've got a super easy problem to solve,

16:42.000 --> 16:48.000
 you'll probably want to use random resized crop and these orb transforms.

16:48.000 --> 16:51.000
 But don't put the molecules to just leave that empty.

16:51.000 --> 16:57.000
 I'm just putting it there so you can see them more clearly.

16:57.000 --> 17:11.000
 So I've got an interesting question here from Alex in our audience, which is, is this copying the image multiple times during something like this or something like this?

17:11.000 --> 17:16.000
 And the answer is no, we're not copying the image.

17:16.000 --> 17:21.000
 What happens is that image, so each epoch, every image gets red.

17:21.000 --> 17:29.000
 And what happens here is though is kind of in memory, in RAM, the image is being warped.

17:29.000 --> 17:32.000
 It's being recropping it and recoloring it and so forth.

17:32.000 --> 17:37.000
 So it's a real time process that's happening during model training.

17:37.000 --> 17:45.000
 So there's no copies being stored on your computer, but effectively it's almost like there's infinitely slightly different copies because that's what the model is.

17:45.000 --> 17:50.000
 So I hope that makes sense, Alex and everybody else.

17:50.000 --> 17:53.000
 That's a great question.

17:53.000 --> 17:58.000
 Okay, so we've got, we're going to use random resized crop.

17:58.000 --> 18:04.000
 We're going to use augmentation transforms so that we get a dirty loaders from that.

18:04.000 --> 18:06.000
 And then we can go ahead and train our model.

18:06.000 --> 18:07.000
 It takes about a minute.

18:07.000 --> 18:12.000
 In this case, we only did four epochs of fine tuning.

18:12.000 --> 18:18.000
 We'll talk about why there's five here later in the course, but four main epochs of fine tuning.

18:18.000 --> 18:24.000
 So we probably didn't really need random resized crop and aug transforms because there's so few epochs.

18:24.000 --> 18:28.000
 But, you know, if you want to run more epochs, this is a good approach.

18:28.000 --> 18:31.000
 Under 3% error, that's good.

18:31.000 --> 18:36.000
 Okay, so remember I said we're going to train a model before we clean.

18:36.000 --> 18:41.000
 Okay, so let's go ahead and train it.

18:41.000 --> 18:56.000
 So while that's training, that's running on my laptop, which only has a four gigabyte GPU, it's pretty basic, but it's enough to get started.

18:56.000 --> 18:59.000
 While that's training, we'll take a look at the next one.

18:59.000 --> 19:03.000
 So the first thing we're going to look at is the confusion matrix.

19:03.000 --> 19:09.000
 And the confusion matrix is something that it only is meaningful for when your labels are categories, right?

19:09.000 --> 19:13.000
 And what it says is how, what category errors are you making?

19:13.000 --> 19:24.000
 And so this is showing that the model that we've got at this point, there was two times when there was actually a grizzly bear, and it thought it was a black bear.

19:24.000 --> 19:32.000
 And there was two times when there was actually a black bear and it thought it was a grizzly bear, and there was no times that it got Teddy's wrong, which makes sense, right?

19:32.000 --> 19:39.000
 Because Teddy's too look quite different to both.

19:39.000 --> 19:45.000
 In a lot of situations, when you look at this, it'll kind of give you a real sense of like, okay, well what are the hard ones, right?

19:45.000 --> 20:01.000
 So for example, if you use the PETs dataset that we quite often play within the book and of course, this classification matrix for different breeds of PET, you know, really shows you which ones are difficult to identify, and I've actually gone in and like

20:01.000 --> 20:11.000
 read Wikipedia pages and PET breeding reports about how to identify these particular types because they're so difficult and even experts find it difficult.

20:11.000 --> 20:21.000
 And one of the things I've learned from during the course actually is black bears and grizzly bears are much harder to pick apart than I had realized, so I'm not even going to try.

20:21.000 --> 20:33.000
 But I'll show you the really interesting thing we can do with this model is that now we've created this classification interpretation object, which we use for confusion metrics.

20:33.000 --> 20:42.000
 We can say plot top losses.

20:42.000 --> 21:03.000
 And this is very interesting. What it does is it tells us the places where the loss is the highest. Now if you remember from the last lesson, the loss is that measurement of how good our model is that we take after each time we run through an item of data.

21:03.000 --> 21:20.000
 A loss will be bad if we predict wrongly, and we're very confident about that prediction. So here's an example where we predicted is the order here prediction actual loss probability, where we predicted grizzly, and it was actually a black.

21:20.000 --> 21:26.000
 And we were 96% sure our model was that it's a grizzly.

21:26.000 --> 21:39.000
 Now, I don't know enough about bears to know whether the model made a mistake or whether this actually is a picture of a grizzly bear. But so an expert would obviously go back and check those out.

21:39.000 --> 21:48.000
 Now, you'll notice a couple here. It's got grizzly grizzly teddy teddy. They're actually correct.

21:48.000 --> 22:00.000
 Right. So why is this loss bad when it was correct? And the reason is because it wasn't very confident. It was only 60% confident. Right. So here's a teddy. It's only 72% confident.

22:00.000 --> 22:07.000
 Right. So you can have a bad loss either by being wrong and confident or being right and uncomfortable.

22:07.000 --> 22:24.000
 Now, the reason that's really helpful is that now we can use something called the fast AI image classifier cleaner to clean up the ones that are wrongly labeled in our data set.

22:24.000 --> 22:38.000
 So when we use the image classifier cleaner, it actually runs our models. That's why we pass it learn. Right. And I mentioned that I don't know much about black bears and grizzly bears, but I do know a lot about teddy bears.

22:38.000 --> 22:48.000
 So I'll pick teddy bears. And if I click teddy bears, it's now showing me all the things in the training set. You can pick training or valid that were marked as teddy bears.

22:48.000 --> 23:01.000
 And here's what's really important. They're ordered by loss. So they're ordered by confidence. Right. So I can scroll through just the first few and check there. Correct. Right. And oh, here's a mistake.

23:01.000 --> 23:09.000
 Right. So when I find one that was wrongly gathered, I can either put it if it's in the wrong category. I can choose the correct category.

23:09.000 --> 23:16.000
 Or if it shouldn't be there at all, I click delete. So here I'll go ahead and click delete. Right. So I can see some reasons that some of these are hard.

23:16.000 --> 23:26.000
 Like, for example, here's two teddy bears, which is just, I guess, confusing. So it doesn't see that often. This one here is a bit weird looking. It looks almost like a one bat.

23:26.000 --> 23:37.000
 This is an awful lot of teddy bears. This one maybe is just a bit hard to see from the background, but these otherwise they look fine.

23:37.000 --> 23:44.000
 Fine. So we just looked through the first few. And if you don't see any problem or problems in the first few, you're probably fine. So that's cleaned up our training set.

23:44.000 --> 23:50.000
 Let's clean up our validation set as well.

23:50.000 --> 23:59.000
 So here's that one it had trouble with. I don't know why it had trouble with that one, but so be it. And we'll have a quick scroll through.

23:59.000 --> 24:06.000
 Okay. I'm not really sure that's a bear. So I'm just going to go ahead and delete it. It's a teddy something.

24:06.000 --> 24:15.000
 But, you know, it's a problem. Okay, that's not a teddy either.

24:15.000 --> 24:26.000
 So you see the idea, right? So after we've done that, what that does is the cleaner has now stored a list of the ones that we changed and the list of the ones we deleted.

24:26.000 --> 24:37.000
 So we can now go ahead and run this cell. And so that's going to go through a list of all of the indexes that we said to delete and it will delete those files.

24:37.000 --> 24:45.000
 And it'll go through all the ones we said to change and it will move them to the new folder. There we go. Done.

24:45.000 --> 25:02.000
 So this is like not just something for image models. It's just it's actually a really powerful technique that almost nobody knows about and uses, which is before you start data cleaning, always build a model to find out what things are difficult to recognize in your

25:02.000 --> 25:14.000
 data and to find the things that the model can help you find data problems. And then as you see them, you're going to say, okay, I see the kinds of problems we're having and you might find better ways to gather the next data set or you might

25:14.000 --> 25:18.000
 find ways to kind of automate some of the cleaning and so forth.

25:18.000 --> 25:34.000
 Okay. So that is data cleaning. And since I only have a four gigabyte GPU, it's very important for me to close and halt because that will free up the memory.

25:34.000 --> 25:54.000
 So it's important to know on your computer, your normal RAM doesn't really get filled up because if you use up too much RAM, what will happen is that instead your computer will start, it's got swapping, which is basically to save that RAM

25:54.000 --> 26:15.000
 onto the hard disk to use it later. GPUs can't swap. GPUs, when they run out of RAM, that's it. You're done. So you need to make sure that you close any notebooks that are using the GPU that you're not using and really only use one thing at a time on the GPU, otherwise you'll almost certainly run out of memory.

26:15.000 --> 26:29.000
 So we've got the first few reds starting to appear. So remember to ask. And in terms of the yellows, it's important to know, as you watch the video, I'm not asking you to run all this code.

26:29.000 --> 26:40.000
 Okay, the idea is to kind of watch it and then go back and pause, you know, as you go along, or you can just stop, try, stop, try.

26:40.000 --> 26:58.000
 The approach I really like, and a lot of students really like for watching these videos, is to actually watch the entire thing without touching the keyboard to get a sense of what the video is about, and then go back to the start and watch it again and follow along.

26:58.000 --> 27:11.000
 That way, at every point, you know what it is you're doing, you know what's going to happen next, that can actually save you some time. It's a bit of an unusual way because obviously, like, real life lectures, you can't do that.

27:11.000 --> 27:18.000
 You can't rewind the professor and get them to say it again, but it's a good way to do it here.

27:18.000 --> 27:29.000
 So now that we've cleaned our data, how are we going to put it into production? Well, in the book, we use something called Foila, and it's pretty good.

27:29.000 --> 27:40.000
 But there's actually something that I think most of you are probably going to find a lot more useful nowadays, which is something called hugging face spaces, and there's a couple of things you can use with that.

27:40.000 --> 27:56.000
 We're going to look at something called Gradio today. And there isn't a chapter about this in the book, but that doesn't matter because Tanishk Abraham, who's actually one of the TAs in the course, has written a fantastic blog post about it.

27:56.000 --> 27:58.000
 Really everything we're going to cover today.

27:58.000 --> 28:03.000
 So there's a link to that from the forum and from the course page.

28:03.000 --> 28:14.000
 So this is like the equivalent of the chapter of the book, if you like. And I would be remiss if I didn't stop for a moment and call out Tanishk in a big way for two reasons.

28:14.000 --> 28:19.000
 The first is he is one of the most helpful people in the fast AI community.

28:19.000 --> 28:30.000
 He's been around quite a few years, incredibly tenacious, thoughtful and patient, and also because I have this fantastic picture of him a few years ago with Conan

28:30.000 --> 28:41.000
 when he was a famous child prodigy. So now you know what happens to famous child prodigies when they grow up. They became even more famous, fast AI community members and declining experts.

28:41.000 --> 28:45.000
 So you should definitely check out this video of him telling jokes to Conan.

28:45.000 --> 28:50.000
 I think he's still only 18 actually. This is probably not that many years ago.

28:50.000 --> 28:54.000
 So thank you very much, Tanishk, for all your help in the community.

28:54.000 --> 29:01.000
 And sorry if you're embarrassing you with that picture of you as a nine year old. I'm not really hot. Okay.

29:01.000 --> 29:07.000
 Now, the thing is for doing radio and hugging face spaces, well, it's easy enough to start.

29:07.000 --> 29:14.000
 Okay, we start over here on the hugging face spaces page, which we've linked to from the forum and the course.

29:14.000 --> 29:20.000
 And we're going to put a model in production where we're going to take the model we trained.

29:20.000 --> 29:30.000
 We are going to basically copy it to this hugging face spaces server and write a user interface for it.

29:30.000 --> 29:34.000
 So, that let's go create new space.

29:34.000 --> 29:39.000
 Okay, so you can just go ahead and say, all right. So you obviously sign up. The whole thing's free.

29:39.000 --> 29:46.000
 Basically everything I'm showing you in this entire course, you can do for free. That's a good news.

29:46.000 --> 29:51.000
 Okay, so give it a name. Just create something minimal.

29:51.000 --> 29:58.000
 I always use the Apache license because it means other people can use your work really easily, but you don't have to worry too much about patents.

29:58.000 --> 30:04.000
 If they say there's a few different products you can use with it. We're going to use radio also free.

30:04.000 --> 30:12.000
 If you make it public, then you can share it, which is always a good idea when you're a student, particularly to really be building up that portfolio.

30:12.000 --> 30:16.000
 Okay, so we're done. We've created a space.

30:16.000 --> 30:23.000
 Now, what do we do next? Well, spaces works through Git.

30:23.000 --> 30:29.000
 Now most software developers will be very familiar with Git. Some data scientists might not be.

30:29.000 --> 30:35.000
 And so, gets a very, very useful tool. I'm not going to talk about it in detail.

30:35.000 --> 30:41.000
 But let's kind of quickly learn about how to use it, right?

30:41.000 --> 30:48.000
 Now, Git, you can use it through something called GitHub Desktop, which is actually pretty great.

30:48.000 --> 30:59.000
 And even people who use Git through the console should probably be considering using GitHub Desktop as well, because some things just much faster and easier in it.

30:59.000 --> 31:02.000
 In fact, I was talking to my friend Hamill today, and I was like,

31:02.000 --> 31:07.000
 Oh, help, I've accidentally committed this two things by mistake. What's the easiest way to revert it?

31:07.000 --> 31:12.000
 And he used to work at GitHub, and I thought he was going to have some fancy console command, and he was like,

31:12.000 --> 31:16.000
 Oh, you should use GitHub Desktop, and you can just click on it.

31:16.000 --> 31:25.000
 Oh, that's a great idea. So that's useful. But most of the time, we do use Git from the console from the terminal.

31:25.000 --> 31:30.000
 If you're a Linux user or a Mac user, you've already got a terminal very straightforward, no worries.

31:30.000 --> 31:35.000
 If you're a Windows user, I've got good news. Nowadays, Windows has a terrific terminal.

31:35.000 --> 31:39.000
 It's called Windows Terminal. You get it from the Microsoft Store.

31:39.000 --> 31:46.000
 So in fact, every time you see me using a terminal, I'm actually using that Windows Terminal.

31:46.000 --> 31:53.000
 It works very well. God knows why I'd wanted to have all these ridiculous colors, but there you go.

31:53.000 --> 31:57.000
 Now, what do you want to be running inside your terminal?

31:57.000 --> 32:01.000
 Obviously, if you're in Linux or Mac, you've already got a shell set up.

32:01.000 --> 32:06.000
 In Windows, you almost certainly want to use Ubuntu.

32:06.000 --> 32:11.000
 So Windows, believe it or not, can actually run a full Linux environment.

32:11.000 --> 32:17.000
 And to do it is typing a single line, which is this.

32:17.000 --> 32:23.000
 So if you go to Google for WSL install, run PowerShell as a administrator,

32:23.000 --> 32:31.000
 post that command, wait about five minutes, reboot your done.

32:31.000 --> 32:33.000
 You now have a complete Linux environment.

32:33.000 --> 32:41.000
 Now, one of the reasons I'm mentioning this is I'm going to show you how to do stuff on your own machine now.

32:41.000 --> 32:50.000
 And so this is like going to a bit of an extra level of geekery, which some data scientists may be less familiar with.

32:50.000 --> 32:53.000
 So don't be worried about the terminal.

32:53.000 --> 32:59.000
 You're going to think you're going to find it really helpful and much less scary than you expect.

32:59.000 --> 33:09.000
 And I particularly say like for me, I choose to use Windows and that's because I get all the nice Windows GUI apps

33:09.000 --> 33:15.000
 and I can draw on my screen and do presentations and I have a complete Linux environment as well.

33:15.000 --> 33:18.000
 And that Linux environment uses my GPU and everything.

33:18.000 --> 33:22.000
 So for me, my first choice is to use Windows.

33:22.000 --> 33:26.000
 My second choice by not very much really like it would be to use Linux.

33:26.000 --> 33:34.000
 Mac is a little bit harder, but it's still usable.

33:34.000 --> 33:38.000
 So some things are a little bit trickier on Mac, but you should be fine.

33:38.000 --> 33:39.000
 Okay.

33:39.000 --> 33:45.000
 So whatever you've got at this point, you've now got a terminal available.

33:45.000 --> 33:52.000
 And so in your terminal, one of the really nice things about using a terminal is you don't have to follow lots of instructions about click here, click here, click here.

33:52.000 --> 33:53.000
 You just copy and paste things.

33:53.000 --> 33:55.000
 So I'm just going to go ahead and you just copy this.

33:55.000 --> 34:00.000
 And you go over to your terminal and you paste it in and you run it.

34:00.000 --> 34:05.000
 And after you do that, you'll find that you've now got that directory.

34:05.000 --> 34:10.000
 And so that new directory initially is empty.

34:10.000 --> 34:16.000
 And they tell you, okay, go ahead and create a file with this in it.

34:16.000 --> 34:17.000
 Okay.

34:17.000 --> 34:27.000
 So how do you create a file with that in it when we're in here in our Linux environment, on Windows or in the terminal or Mac or whatever.

34:27.000 --> 34:32.000
 Well, all you do in Windows, if you just type explorer.exe.

34:32.000 --> 34:34.000
 It'll open up Explorer here.

34:34.000 --> 34:42.000
 Or better still on either Mac or Linux or Windows.

34:42.000 --> 34:50.000
 So yeah, so regardless of what type of computer on, you can just type code.

34:50.000 --> 34:56.000
 And it will pop up, official studio code and open up your folder.

34:56.000 --> 35:03.000
 And so then you can just go ahead and if you haven't used VS code before, it's really well worth

35:03.000 --> 35:06.000
 taking a few minutes to read some tutorials.

35:06.000 --> 35:09.000
 It's a really great IDE.

35:09.000 --> 35:19.000
 And so you can go ahead and create an app.py file like they tell you to, app.py file containing what they told you to put in it.

35:19.000 --> 35:23.000
 Here it is here.

35:23.000 --> 35:26.000
 All right, we're nearly there.

35:26.000 --> 35:34.000
 So you can now go ahead and save that.

35:34.000 --> 35:37.000
 And then you need to commit it to a radio.

35:37.000 --> 35:40.000
 That's a great idea to hugging first bases.

35:40.000 --> 35:45.000
 So one really easy way is just in Visual Studio itself, you can just click here.

35:45.000 --> 35:53.000
 And that'll give you a place where you type a message and you hit tick and it'll send it off to hugging first bases for you.

35:53.000 --> 36:02.000
 You can then go to back to the exact same website you're on before, hugging space bases, JPHO, minimal.

36:02.000 --> 36:10.000
 And what you'll find now is that it'll take about a minute to build your website.

36:10.000 --> 36:31.000
 And the website it's building is going to have a radio interface with a text input, a text output, and it's going to run a function called greet on the input.

36:31.000 --> 36:36.000
 And my function called greet will return hello name.

36:36.000 --> 36:40.000
 So that's what it's going to do.

36:40.000 --> 36:43.000
 There it goes. Let's try it.

36:43.000 --> 36:45.000
 We'll say hello to Tenish.

36:45.000 --> 36:50.000
 I'm not always remembering how to spell his name. I think it's like that.

36:50.000 --> 36:54.000
 And there you go. So you can see it's put the output for our input.

36:54.000 --> 37:00.000
 So not a very exciting app, but we now have to be fair and app running in production.

37:00.000 --> 37:06.000
 Now, I told you we'd have a deep learning model running in production.

37:06.000 --> 37:11.000
 So now we have to take the next step, which is to turn this into a deep learning model.

37:11.000 --> 37:17.000
 All right. So first we're going to need a deep learning model.

37:17.000 --> 37:22.000
 And there's a few different ways we can get ourselves a deep learning model.

37:22.000 --> 37:25.000
 But basically we're going to have to train one.

37:25.000 --> 37:32.000
 So I've got a couple of examples. I've got a caggle example and a clodalab example.

37:32.000 --> 37:35.000
 Maybe I'll quickly show you both. They're going to do the same thing.

37:35.000 --> 37:39.000
 And I'm just going to create a dog or a cat classifier.

37:39.000 --> 37:43.000
 Okay. So here's our caggle model.

37:43.000 --> 37:52.000
 I'll click on edit so you can actually see what it looks like in edit view.

37:52.000 --> 37:58.000
 Now, Caggle already has fast AI installed, but I always put this first just to make sure we've got the latest version.

37:58.000 --> 38:03.000
 And obviously import stuff. So we're going to grab the pets data set,

38:03.000 --> 38:06.000
 a function to check whether it's a cat.

38:06.000 --> 38:09.000
 That's our labeling function for our image data loaders.

38:09.000 --> 38:13.000
 Remember, this is just another way of doing data blocks. It's like a little shorthand.

38:13.000 --> 38:17.000
 And we create our learner and we fine tune it.

38:17.000 --> 38:22.000
 So that's all stuff we've seen before.

38:22.000 --> 38:27.000
 So in Caggle every notebook has an edit view, which is what you just saw and a read of you.

38:27.000 --> 38:32.000
 And so you can share your notebook if you want to.

38:32.000 --> 38:37.000
 And then anybody can read the read of you as you see.

38:37.000 --> 38:42.000
 And so you can see it shows you what happened when I ran it.

38:42.000 --> 38:49.000
 And so I trained it. It took, you know, so that the GPUs on Caggle are a bit slower than most modern GPUs,

38:49.000 --> 38:54.000
 but they're still fast enough. I mean, it takes five minutes.

38:54.000 --> 39:00.000
 And there's one bit at the end here, which you haven't seen before, which is like I learned on export.

39:00.000 --> 39:02.000
 And I give it a name.

39:02.000 --> 39:08.000
 Now that's going to create a file containing our trained model.

39:08.000 --> 39:13.000
 And that's the only thing. Creating this file is the only thing you need a GPU for.

39:13.000 --> 39:19.000
 So you do that on Caggle or on CoLab. So here's exactly the same thing on CoLab.

39:19.000 --> 39:24.000
 You can see pip install is cat, and data, image data loaders.

39:24.000 --> 39:28.000
 So I've got to show batch here as well, just for fun.

39:28.000 --> 39:31.000
 Create my learner and then export.

39:31.000 --> 39:37.000
 So while we wait, I might go ahead and just run that.

39:37.000 --> 39:44.000
 The nice thing about Caggle is once you've run it and saved it, you can then go to the data tab.

39:44.000 --> 39:48.000
 And here is basically anything you've saved. It's going to appear here.

39:48.000 --> 39:51.000
 And here it is, model.pickle.

39:51.000 --> 39:56.000
 Right. So now I can go ahead and download that.

39:56.000 --> 40:02.000
 And that will then be downloaded to my Downloads folder.

40:02.000 --> 40:07.000
 And I need to copy it into the same directory that my HuggingFaceBase is absent.

40:07.000 --> 40:13.000
 Now my HuggingFaceBase's app is currently open in my terminal.

40:13.000 --> 40:21.000
 In on Mac, you can type open. or in Windows, you can type explorer.exe.

40:21.000 --> 40:29.000
 And that will bring up your Finder or Explorer in that directory.

40:29.000 --> 40:36.000
 And so then you can just paste that thing you downloaded into this directory.

40:36.000 --> 40:39.000
 Something, by the way, in Windows I do, which I find really helpful,

40:39.000 --> 40:46.000
 is I actually grab my home directory in Linux, and I pin it to my quick access.

40:46.000 --> 40:52.000
 And that way I can always jump in Windows straight to my Linux files.

40:52.000 --> 40:56.000
 Not really saying you have to worry about on Mac because it's all kind of integrated.

40:56.000 --> 41:01.000
 In Windows they're kind of like two separate machines.

41:01.000 --> 41:07.000
 Okay. So let's do...

41:07.000 --> 41:12.000
 So I created a Space Core testing, and I downloaded my model.pickle,

41:12.000 --> 41:15.000
 and I pasted it into testing.

41:15.000 --> 41:23.000
 So now we need to know how do we do predictions on a saved model?

41:23.000 --> 41:27.000
 So we've got a notebook for that.

41:27.000 --> 41:30.000
 Okay, so we've got a notebook for that.

41:30.000 --> 41:36.000
 And so I'm going to take you through how we use a model that we've trained to make predictions.

41:36.000 --> 41:41.000
 There's a few funny things with hash pipe, which I'll explain in a moment,

41:41.000 --> 41:43.000
 just ignore those for now.

41:43.000 --> 41:46.000
 So we import Fast.io as usual.

41:46.000 --> 41:49.000
 We import Gradio as we did before.

41:49.000 --> 41:53.000
 The copy in the exact same is cat definition we had before.

41:53.000 --> 41:54.000
 That's important.

41:54.000 --> 42:00.000
 Any external functions that you used in your labeling need to be included here as well,

42:00.000 --> 42:04.000
 because that learner refers to those functions.

42:04.000 --> 42:05.000
 Okay, it saves...

42:05.000 --> 42:07.000
 That learner's saved everything about your model,

42:07.000 --> 42:12.000
 but it doesn't have the source code to the function, so you need to keep those with you.

42:12.000 --> 42:14.000
 So let's try running this.

42:14.000 --> 42:22.000
 So for example, I just grabbed, as you might have seen in my explorer,

42:22.000 --> 42:27.000
 I just popped a dog picture there.

42:27.000 --> 42:33.000
 And so we can create a Python image library image from that dog,

42:33.000 --> 42:36.000
 turn it into a slightly smaller one, so it doesn't overwhelm our whole screen,

42:36.000 --> 42:38.000
 and there's a picture of a dog.

42:38.000 --> 42:41.000
 So how do we make predictions of whether that's a dog or a cat?

42:41.000 --> 42:45.000
 Well, it's very simple. All we do is instead of training a learner,

42:45.000 --> 42:47.000
 we use load learner.

42:47.000 --> 42:52.000
 We pass in the file name that we saved, and that returns a learner.

42:52.000 --> 42:58.000
 This learner is exactly the same as the learner you get when you finish training.

42:58.000 --> 43:00.000
 So here we are, here's Colab, right?

43:00.000 --> 43:02.000
 We've just been training a learner.

43:02.000 --> 43:05.000
 So at the end of that, there's a learner that's been trained.

43:05.000 --> 43:09.000
 And so we kind of froze it in time.

43:09.000 --> 43:13.000
 Something called a pickle file, which is a Python concept.

43:13.000 --> 43:15.000
 It's like a frozen object.

43:15.000 --> 43:17.000
 We saved it to disk.

43:17.000 --> 43:20.000
 We transferred it to our computer, and we've now loaded it,

43:20.000 --> 43:23.000
 and we've now unfurried thought it.

43:23.000 --> 43:25.000
 Here's our unpickled learner.

43:25.000 --> 43:27.000
 And we can now do whatever we like with that.

43:27.000 --> 43:31.000
 So one of the things that the...

43:31.000 --> 43:35.000
 One of the methods that a learner has is a.predict method.

43:35.000 --> 43:38.000
 So if I run it, you can see, even on my laptop,

43:38.000 --> 43:40.000
 it's a completely instant.

43:40.000 --> 43:42.000
 In fact, we can see how long it took.

43:42.000 --> 43:47.000
 In Jupyter, things that start with % are called magics.

43:47.000 --> 43:49.000
 They're special Jupyter things.

43:49.000 --> 43:52.000
 So for example, there's a thing to see how long something takes.

43:52.000 --> 43:53.000
 There you go.

43:53.000 --> 44:02.000
 Okay, so it took 54 milliseconds to figure out that this is not a cat.

44:02.000 --> 44:03.000
 So it's returning two things.

44:03.000 --> 44:07.000
 Is it a cat as a string?

44:07.000 --> 44:09.000
 Is it a cat as a zero or one?

44:09.000 --> 44:15.000
 And then the probability that it's a dog and the probability that it's a cat.

44:15.000 --> 44:20.000
 So the probability of zero, false, and one true of it is a cat.

44:20.000 --> 44:22.000
 So definitely a dog.

44:22.000 --> 44:28.000
 So we now want to create a Gradio interface which basically has this information.

44:28.000 --> 44:33.000
 So a Gradio requires us to give it a function that it's going to call.

44:33.000 --> 44:35.000
 So here's our function.

44:35.000 --> 44:37.000
 So we're going to call predict.

44:37.000 --> 44:39.000
 And that returns as we said three things.

44:39.000 --> 44:47.000
 The prediction is a string, the index of that, and the probabilities of whether it's a dog or a cat.

44:47.000 --> 44:54.000
 And what Gradio wants is it wants to get back a dictionary containing each of the possible categories,

44:54.000 --> 44:59.000
 which in this case is dog or cat, and the probability of each one.

44:59.000 --> 45:05.000
 So if you haven't done much Python before, a dict of a zip may be something you haven't seen,

45:05.000 --> 45:08.000
 very handy little idiom, well worth checking out.

45:08.000 --> 45:10.000
 Did I ever have seen map before?

45:10.000 --> 45:13.000
 Anyway, here it is.

45:13.000 --> 45:21.000
 One slightly annoying thing about Gradio at the moment is that it doesn't handle PyTorch tensors.

45:21.000 --> 45:24.000
 You can see here PyTorch is not returning normal numbers.

45:24.000 --> 45:25.000
 It's returning tensors.

45:25.000 --> 45:27.000
 It's not even returning NumPy arrays.

45:27.000 --> 45:31.000
 In fact, Gradio can't handle NumPy either, so you have to change everything just to a normal float.

45:31.000 --> 45:33.000
 So that's all that this is doing.

45:33.000 --> 45:35.000
 It's changing each one to a float.

45:35.000 --> 45:42.000
 So for example, if I now call classify image with our doggy image, we get back a dictionary of a dog.

45:42.000 --> 45:45.000
 Yes, definitely cat, definitely not.

45:45.000 --> 45:47.000
 So now we've got all that.

45:47.000 --> 45:51.000
 We can go ahead and create a Gradio interface.

45:51.000 --> 45:57.000
 So Gradio interface is something where we say, well, what function do you call to get the output?

45:57.000 --> 45:58.000
 What is the input?

45:58.000 --> 46:01.000
 In this case, we say, oh, the input is an image.

46:01.000 --> 46:02.000
 So check out the Gradio docs.

46:02.000 --> 46:08.000
 It can be all kinds of things like a webcam picture or a text or all kinds of things.

46:08.000 --> 46:11.000
 Give it a shape that it's going to put it into.

46:11.000 --> 46:17.000
 The output is just going to be a label, so we're going to create a very, very simple interface.

46:17.000 --> 46:22.000
 So we can also provide some examples, and so there's a dog, a cat, and a donno, which I'll

46:22.000 --> 46:27.000
 do about in a moment, which you'll see here, there's a dog and a cat and a donno.

46:27.000 --> 46:31.000
 So once they launch it, it says, OK, that's now running on this URL.

46:31.000 --> 46:40.000
 So if I open that up, you can see now we have just like a subash, we have our own not yet

46:40.000 --> 46:43.000
 in production, but running on our own box.

46:43.000 --> 46:44.000
 Classifier.

46:44.000 --> 46:46.000
 So let's check dog.

46:46.000 --> 46:49.000
 You can click and upload one or just choose the examples.

46:49.000 --> 46:50.000
 Yeah, yeah.

46:50.000 --> 46:55.520
 So it's running on my own laptop, basically instant.

46:55.520 --> 47:00.280
 And I really have to tell you this story about this guy here.

47:00.280 --> 47:01.280
 This is the donno.

47:01.280 --> 47:04.920
 So wait, why is it saying 100?

47:04.920 --> 47:05.920
 Normally this says like 5050.

47:05.920 --> 47:07.560
 That's a bummer.

47:07.560 --> 47:09.760
 This model has messed up my whole story.

47:09.760 --> 47:18.440
 The last time I trained this model and I ran it on the donno, it said almost exactly 5050.

47:18.440 --> 47:23.760
 And the way we found this picture is I showed my six year old daughter, she was like, what

47:23.760 --> 47:24.760
 are you doing dad?

47:24.760 --> 47:25.760
 It's like uncoating.

47:25.760 --> 47:26.760
 What are you coding?

47:26.760 --> 47:28.400
 Oh, you know, dog cat classifier.

47:28.400 --> 47:29.400
 She checks it out.

47:29.400 --> 47:32.480
 And her first question is, can I take your keyboard for a moment?

47:32.480 --> 47:37.600
 And she goes to Google and she's like, what is a dog mixed with a cat called?

47:37.600 --> 47:40.400
 There's no such thing as a dog mixed with a cat.

47:40.400 --> 47:44.920
 Anyway, she goes to the images tab and finds this picture and she's like, look, there's

47:44.920 --> 47:46.640
 a dog mixed with a cat.

47:46.640 --> 47:48.800
 She said, run it on that dad.

47:48.800 --> 47:49.800
 Run it on that.

47:49.800 --> 47:52.200
 And I ran it and it was like 5050.

47:52.200 --> 47:55.520
 It had no idea if it was a dog or a cat.

47:55.520 --> 47:57.680
 Now this model I just retrained today.

47:57.680 --> 47:59.560
 Now it's sure it's a cat.

47:59.560 --> 48:00.560
 So there you go.

48:00.560 --> 48:03.600
 I think I used a slightly different training schedule or something or I gave it an extra

48:03.600 --> 48:06.160
 epoch anyway.

48:06.160 --> 48:08.720
 So that's a dog cat.

48:08.720 --> 48:10.400
 But apparently it's a cat.

48:10.400 --> 48:12.720
 I guess it is a cat.

48:12.720 --> 48:13.720
 It's probably right.

48:13.720 --> 48:16.240
 Shouldn't have trained it for as long.

48:16.240 --> 48:17.960
 Okay, so there's our interface.

48:17.960 --> 48:19.320
 Now that's actually running.

48:19.320 --> 48:21.800
 So you actually have to click the stop button to stop it running.

48:21.800 --> 48:25.120
 So otherwise you won't be able to do anything else near a notebook.

48:25.120 --> 48:29.040
 Okay.

48:29.040 --> 48:33.880
 So now we have to turn that into a Python script.

48:33.880 --> 48:39.000
 So one way to turn it into a Python script would be to copy and paste into a Python script

48:39.000 --> 48:40.920
 all the things that you need.

48:40.920 --> 48:46.000
 I would read a copy and paste into a Python script all the parts of this that you need.

48:46.000 --> 48:47.960
 So for example, we wouldn't need this.

48:47.960 --> 48:49.160
 It's just to check something out.

48:49.160 --> 48:50.160
 We wouldn't need this.

48:50.160 --> 48:51.960
 It was just experimenting.

48:51.960 --> 48:53.440
 This was just experimenting.

48:53.440 --> 48:55.240
 We'd need this.

48:55.240 --> 49:02.640
 So what I did is I went through and I wrote hash pipe export at the top of each cell that

49:02.640 --> 49:07.200
 contains information that I'm going to need in my final script.

49:07.200 --> 49:10.280
 And then, so there are the steps, right?

49:10.280 --> 49:15.520
 And then at the very bottom here, I've imported something called notebook to script from

49:15.520 --> 49:16.980
 nbdev.

49:16.980 --> 49:25.840
 And if I run that and pass in the name of this notebook, that creates a file for me called

49:25.840 --> 49:31.520
 app.py containing that script.

49:31.520 --> 49:35.200
 So this is a nice easy way to, like, when you're working with stuff that's expecting

49:35.200 --> 49:40.720
 a script and not a notebook, like hugging first bases does, it's fine to just copy and

49:40.720 --> 49:42.480
 paste into a text file if you like.

49:42.480 --> 49:46.880
 But I really like this way of doing it because that way I can do all of my experimentation

49:46.880 --> 49:48.800
 in a notebook.

49:48.800 --> 49:51.240
 And when I'm done, I just have to sell at the bottom.

49:51.240 --> 49:54.240
 I just run and export it.

49:54.240 --> 49:56.600
 How does that know to call it app.py?

49:56.600 --> 50:01.480
 That's because there's a special thing at the top default export, default X, which says

50:01.480 --> 50:04.120
 what Python file name to create.

50:04.120 --> 50:09.000
 So that's just a little trick that I use.

50:09.000 --> 50:12.600
 So now we've got an app.py.

50:12.600 --> 50:16.240
 We need to upload this to Gradio.

50:16.240 --> 50:18.200
 How do we do that?

50:18.200 --> 50:19.640
 You just push it to get.

50:19.640 --> 50:28.720
 So you can either do it with Visual Studio Code or you can type git commit and then git

50:28.720 --> 50:29.720
 push.

50:29.720 --> 50:41.960
 And once you've done that, if we change minimal to testing, I think this hopefully might still

50:41.960 --> 50:44.000
 be running my previous model because I didn't push it.

50:44.000 --> 50:47.440
 And that way we can see our crazy dog cat.

50:47.440 --> 50:48.440
 All right.

50:48.440 --> 50:49.440
 So here it is.

50:49.440 --> 50:51.560
 You can see it running in production.

50:51.560 --> 50:55.000
 So now this is something that anybody can, if you set it to public, anybody can go here

50:55.000 --> 50:56.640
 and check out your model.

50:56.640 --> 50:58.480
 And so they can upload it.

50:58.480 --> 51:00.480
 And so here's my doggy.

51:00.480 --> 51:01.480
 Yep.

51:01.480 --> 51:03.480
 Definitely a dog cat.

51:03.480 --> 51:04.480
 Yeah.

51:04.480 --> 51:07.400
 I think I might have trained this for epoch or two less.

51:07.400 --> 51:08.560
 So it's less confident.

51:08.560 --> 51:09.560
 Yeah.

51:09.560 --> 51:11.360
 Definitely a cat.

51:11.360 --> 51:13.360
 Dog cat.

51:13.360 --> 51:17.360
 Hey, dog cat.

51:17.360 --> 51:18.360
 Hmm.

51:18.360 --> 51:23.000
 Still thinks it's definitely a cat.

51:23.000 --> 51:25.880
 Oh, well, so be it.

51:25.880 --> 51:27.440
 Okay.

51:27.440 --> 51:32.440
 So that is.

51:32.440 --> 51:34.040
 Okay.

51:34.040 --> 51:43.360
 So that is an example of getting a simple model in production.

51:43.360 --> 51:47.760
 There's a couple of questions from the forum from the community.

51:47.760 --> 51:49.760
 Okay.

51:49.760 --> 51:57.400
 So one person's asking, what's the difference between a PyTorch model and a fast AI learner?

51:57.400 --> 51:58.400
 Okay.

51:58.400 --> 51:59.400
 That's fine.

51:59.400 --> 52:00.400
 We will get to that shortly.

52:00.400 --> 52:10.360
 Don't offer a bit less than it might be this lesson or the next lesson.

52:10.360 --> 52:14.920
 And then somebody else asked, basically it's asking how many epochs do we train for?

52:14.920 --> 52:22.320
 So as you train a model, your error rate, as you can see, it improves.

52:22.320 --> 52:24.360
 And so the question is, should I run more?

52:24.360 --> 52:26.640
 Should I increase the number of epochs?

52:26.640 --> 52:28.400
 This is doing three epochs, right?

52:28.400 --> 52:31.560
 Here's my three epochs plus one to get started.

52:31.560 --> 52:34.320
 Look, it's up to you, right?

52:34.320 --> 52:38.040
 I mean, this is here saying there's a 1% error.

52:38.040 --> 52:39.480
 I'm okay with a 1% error.

52:39.480 --> 52:43.280
 You know, if you want it to be better, then you could use more data augmentation and you

52:43.280 --> 52:46.280
 could train it for longer.

52:46.280 --> 52:53.240
 If you train for long enough, as we'll learn about soon in the next, maybe the next lesson,

52:53.240 --> 52:57.480
 if you train for long enough, your error rate actually starts getting worse.

52:57.480 --> 52:59.640
 And you'll see, we'll learn a bit more.

52:59.640 --> 53:04.840
 So basically, yeah, you can train until it's good enough or until you run out of patience

53:04.840 --> 53:12.560
 or time or run out of compute or until the error rate starts getting worse.

53:12.560 --> 53:14.520
 Okay.

53:14.520 --> 53:21.200
 Oh, and then in CoLab, how do you grab your model?

53:21.200 --> 53:30.880
 All you need to do in CoLab is after you've exported it is if you go into their file browser,

53:30.880 --> 53:33.120
 you'll actually see it here, right?

53:33.120 --> 53:36.480
 And you can click download.

53:36.480 --> 53:39.680
 It's a bit weird.

53:39.680 --> 53:42.960
 It doesn't like pop up a box saying where do you want to download it to?

53:42.960 --> 53:47.040
 But instead, this kind of progress circle thing pops up.

53:47.040 --> 53:51.360
 And so depending on how big it is and so forth, it can take a few minutes.

53:51.360 --> 53:55.400
 And once that circle fills up, then it'll browse a thing or finally pop up and say,

53:55.400 --> 53:56.560
 okay, you can save it.

53:56.560 --> 53:57.560
 Okay.

53:57.560 --> 53:59.400
 So that's how you actually grab your model.

53:59.400 --> 54:03.800
 So as you can see, the step where you actually need a GPU, you can use these totally free

54:03.800 --> 54:06.000
 resources, CoLab, Kaggle.

54:06.000 --> 54:10.480
 There are other ones we'll talk about in future lessons.

54:10.480 --> 54:13.600
 And then you can do everything else on your own computer, including the predictions.

54:13.600 --> 54:15.480
 The predictions are fast, right?

54:15.480 --> 54:20.080
 So you really don't need to use a GPU for that unless you're doing thousands of them.

54:20.080 --> 54:21.080
 Okay.

54:21.080 --> 54:22.080
 Here we go.

54:22.080 --> 54:24.600
 Now it's asking me to save it.

54:24.600 --> 54:25.600
 Okay.

54:25.600 --> 54:33.040
 So now one big issue is we needed to run it on our computer.

54:33.040 --> 54:36.920
 We needed Python and Jupyter Notebooks running on our computer.

54:36.920 --> 54:42.040
 So how do you do that?

54:42.040 --> 54:46.600
 Because this is where often people get in all kinds of trouble.

54:46.600 --> 54:49.560
 I'm trying to figure out how to get this all working.

54:49.560 --> 54:53.480
 So the good news is we've actually got something that makes it very, very straightforward.

54:53.480 --> 54:55.640
 It's called fast set up.

54:55.640 --> 54:58.040
 There's really only just one part of it you need.

54:58.040 --> 55:00.160
 So let me show you.

55:00.160 --> 55:03.120
 It's actually a Git repository on GitHub.

55:03.120 --> 55:06.920
 GitHub's the place where most Git repositories live.

55:06.920 --> 55:10.560
 So if you go to GitHub, fast.io, fast set up, you'll see it.

55:10.560 --> 55:17.360
 And so what you can do is you can now grab this whole repository just by clicking here

55:17.360 --> 55:18.760
 on code.

55:18.760 --> 55:26.240
 And if you've got GitHub desktop installed, click on open with GitHub desktop.

55:26.240 --> 55:29.600
 And as you'll see, it brings this up saying, okay, I'm ready to save this for you.

55:29.600 --> 55:30.600
 So I'll click clone.

55:30.600 --> 55:33.440
 So it's making a copy of it.

55:33.440 --> 55:36.640
 There we go.

55:36.640 --> 55:50.000
 So basically, once you've cloned it, you'll then find there's a file in there called setup

55:50.000 --> 55:55.920
 conda.sh, which the details don't really matter.

55:55.920 --> 55:56.920
 It's pretty short.

55:56.920 --> 55:59.920
 But that's the thing that's going to install Python for you.

55:59.920 --> 56:05.840
 So at that point, you can just run.slash setup conda and it'll run this installer.

56:05.840 --> 56:13.040
 Now, if you've got Linux or Mac, you've already got Python on your machine.

56:13.040 --> 56:14.520
 Don't use that Python.

56:14.520 --> 56:19.400
 And the reason is because that Python is called the system Python, it's used by your computer

56:19.400 --> 56:21.160
 to do computer stuff, right?

56:21.160 --> 56:22.720
 It's actually needed.

56:22.720 --> 56:24.800
 You don't want to be messing with it.

56:24.800 --> 56:28.200
 I promise you.

56:28.200 --> 56:31.960
 It always leads to disaster always.

56:31.960 --> 56:34.400
 You want your own development version of Python.

56:34.400 --> 56:39.040
 It's also going to make sure you've got the latest version and all the libraries you want.

56:39.040 --> 56:47.240
 By far, the best one for you is almost certainly going to be these conda based Python distribution.

56:47.240 --> 56:52.320
 So if you run setup conda, you'll get the one that we recommend.

56:52.320 --> 56:57.640
 The one we recommend at the moment is something called mamba forge.

56:57.640 --> 57:02.240
 So basically, once you run it, you'll find that you've now and you close your terminal

57:02.240 --> 57:07.600
 and reopen it, you'll find you've now got one extra command, which is called mamba.

57:07.600 --> 57:11.240
 And mamba lets you install stuff.

57:11.240 --> 57:18.040
 So once you've run it, you'll be able to go mamba, install fast.io.

57:18.040 --> 57:23.520
 And that's going to actually, we should probably, I should mention this actually more, bit

57:23.520 --> 57:26.920
 more detail about how to install it correctly.

57:26.920 --> 57:32.600
 If we go to docs.fast.io installing.

57:32.600 --> 57:33.600
 Yeah, okay.

57:33.600 --> 57:37.320
 We actually want to do conda install minus C first chain first.

57:37.320 --> 57:38.960
 So this is copy and paste.

57:38.960 --> 57:41.920
 Oh, sorry, not actually.

57:41.920 --> 57:45.760
 And then the other thing I'll say is instead of using conda, replace conda with mamba because

57:45.760 --> 57:47.480
 nowadays it's much faster.

57:47.480 --> 57:51.920
 So mamba install minus C first chain first.

57:51.920 --> 57:56.880
 Now, this is going to install everything you need.

57:56.880 --> 57:58.960
 It's going to install pytorch.

57:58.960 --> 58:00.440
 It's going to install numpy.

58:00.440 --> 58:06.680
 It's going to install fast.io and so forth.

58:06.680 --> 58:11.480
 And it's obviously, I've already got it.

58:11.480 --> 58:15.880
 And then the other thing you'll want to do is install nbdev.

58:15.880 --> 58:21.320
 So you can do exactly the same thing for nbdev.

58:21.320 --> 58:22.320
 You don't have to.

58:22.320 --> 58:23.320
 Right?

58:23.320 --> 58:26.440
 It's just that, but that'll install Jupyter for you amongst other things.

58:26.440 --> 58:33.080
 And so at that point, you can now use Jupyter.

58:33.080 --> 58:38.360
 And so the way Jupyter works is, we can see it over here.

58:38.360 --> 58:42.920
 This is my, I'll go ahead and close it so we can start again.

58:42.920 --> 58:51.640
 So basically to use Jupyter, you just type Jupyter notebook.

58:51.640 --> 58:55.400
 And when you run it, it'll say, okay, we're now running a server for you.

58:55.400 --> 59:02.440
 And so if you click on that hyperlink, it'll pop up this.

59:02.440 --> 59:06.040
 Okay, which is exactly what you see me use all the time.

59:06.040 --> 59:08.040
 Okay.

59:08.040 --> 59:18.000
 So that hopefully is enough to kind of get you started with Python and with Jupyter notebook.

59:18.000 --> 59:24.920
 The other way people tend to install software is using something called pip instead of mamba.

59:24.920 --> 59:29.560
 Pretty much anything you can do with mamba, you can also do with pip.

59:29.560 --> 59:34.440
 But if you've got a GPU, pip isn't going to install things generally so that it works

59:34.440 --> 59:35.440
 on your GPU.

59:35.440 --> 59:38.480
 You have to install lots of other stuff, which is annoying.

59:38.480 --> 59:44.600
 So that's why I kind of tell people to use mamba, but you can use pip otherwise.

59:44.600 --> 59:47.880
 Still a little bit of red.

59:47.880 --> 59:54.760
 Please let us know how we can help you gain.

59:54.760 --> 59:56.920
 Okay, so let's see how we're going with our steps.

59:56.920 --> 59:59.120
 I forgot I had these steps here to remind myself.

59:59.120 --> 1:00:01.200
 We created a space tick.

1:00:01.200 --> 1:00:03.280
 We created a basic interface tick.

1:00:03.280 --> 1:00:05.480
 Okay, we got get set up.

1:00:05.480 --> 1:00:07.880
 We got Conda and set up or mamba.

1:00:07.880 --> 1:00:10.680
 So mamba and Conda are the same thing.

1:00:10.680 --> 1:00:12.960
 Mamba is just a much faster version.

1:00:12.960 --> 1:00:17.680
 And we'll keep some notes on the course website because at the moment they're actually working

1:00:17.680 --> 1:00:20.600
 on including the speedups from mamba into Conda.

1:00:20.600 --> 1:00:23.600
 So at some point, maybe it'll be fine to use Conda again.

1:00:23.600 --> 1:00:26.680
 At the moment Conda is way too slow.

1:00:26.680 --> 1:00:29.280
 Okay, we've done docs versus cats.

1:00:29.280 --> 1:00:33.120
 No problem.

1:00:33.120 --> 1:00:40.520
 Yeah, so we could also look at pet grades.

1:00:40.520 --> 1:00:43.520
 Yeah, we'll be able to look at that.

1:00:43.520 --> 1:00:45.040
 Okay, we've used an exported learner.

1:00:45.040 --> 1:00:46.760
 No problem, we used to envy dev.

1:00:46.760 --> 1:00:47.760
 No problem.

1:00:47.760 --> 1:00:48.760
 Okay, try the API.

1:00:48.760 --> 1:00:50.560
 All right, this is interesting.

1:00:50.560 --> 1:00:58.400
 So I think we can all agree hopefully that this is pretty cool that we can provide to

1:00:58.400 --> 1:01:04.800
 anybody who wants to use it for free, a real working model.

1:01:04.800 --> 1:01:14.880
 And you know, with Gradyo, there's actually, you know, a really small amount of flexibility

1:01:14.880 --> 1:01:19.240
 around like how you can make your website look, you know, using these various different

1:01:19.240 --> 1:01:23.240
 widgets.

1:01:23.240 --> 1:01:29.160
 It's not amazingly flexible, but it's flexible enough to kind of, it's really just for prototyping,

1:01:29.160 --> 1:01:30.160
 right?

1:01:30.160 --> 1:01:36.520
 So Gradyo has lots of widgets and things that you can use.

1:01:36.520 --> 1:01:44.360
 The other main platform at the moment that hugging first basis supports is called Streamlit.

1:01:44.360 --> 1:01:47.960
 Streamlit is more flexible.

1:01:47.960 --> 1:01:54.560
 I would say than Gradyo, not quite as easy to get started with, but you know, it's kind

1:01:54.560 --> 1:01:56.400
 of that nice in between, I guess.

1:01:56.400 --> 1:01:57.960
 So also a very good thing.

1:01:57.960 --> 1:02:02.400
 Again, mainly if you're kind of building prototypes, but at some point you're going

1:02:02.400 --> 1:02:04.320
 to want to build more than a prototype.

1:02:04.320 --> 1:02:07.280
 You want to build an app, right?

1:02:07.280 --> 1:02:11.920
 And one of the things I really like about Gradyo in hugging face spaces is there's a

1:02:11.920 --> 1:02:15.560
 button down here, view the API.

1:02:15.560 --> 1:02:23.360
 So we can actually create any app we want.

1:02:23.360 --> 1:02:30.720
 And the key point is that the thing that does the actual model predictions for us is going

1:02:30.720 --> 1:02:35.760
 to be handled by hugging face spaces, Gradyo, right?

1:02:35.760 --> 1:02:41.680
 And then we can write a JavaScript application that then talks to that.

1:02:41.680 --> 1:02:45.920
 Now there's going to be two reactions here.

1:02:45.920 --> 1:02:49.480
 Anybody who's done some front end engineering is going to be like, oh, great.

1:02:49.480 --> 1:02:55.040
 I can now literally create anything in the world because I just write any code and I

1:02:55.040 --> 1:02:56.040
 can do it.

1:02:56.040 --> 1:02:57.560
 And I'll be excited.

1:02:57.560 --> 1:03:03.520
 And a lot of data scientists might be going, oh, I have no idea how to use JavaScript.

1:03:03.520 --> 1:03:07.600
 It's not in my inventory.

1:03:07.600 --> 1:03:10.400
 So this is again where I'm going to say, look, don't be too afraid of JavaScript.

1:03:10.400 --> 1:03:14.360
 I mean, obviously one option here is just to kind of say, hey, I've got a model, throw

1:03:14.360 --> 1:03:18.920
 it over to the wall to your mate who does no JavaScript and say, please create a JavaScript

1:03:18.920 --> 1:03:20.320
 interface for me.

1:03:20.320 --> 1:03:27.440
 But let me just give you a sense of like how really not hard this actually is.

1:03:27.440 --> 1:03:31.200
 So there's a endpoint.

1:03:31.200 --> 1:03:36.080
 There's now a URL that's running with our model on it.

1:03:36.080 --> 1:03:44.720
 And if you pass it some data and image some image data to this URL, it's going to return

1:03:44.720 --> 1:03:47.160
 back the dictionary.

1:03:47.160 --> 1:03:56.560
 So it's going to do exactly the same thing that this UI does, but as an API as a function

1:03:56.560 --> 1:03:58.680
 we can call.

1:03:58.680 --> 1:04:01.720
 And so it's got like examples here of how to call it.

1:04:01.720 --> 1:04:08.960
 So for example, I can actually let me show you the API as an example using that minimal

1:04:08.960 --> 1:04:13.240
 interface we had because it's just going to be a bit simpler.

1:04:13.240 --> 1:04:25.600
 So if I click curl and I copy that, copy that and paste.

1:04:25.600 --> 1:04:28.800
 So you can see there, oh, that's not a great example passing in hello world.

1:04:28.800 --> 1:04:34.320
 So if I pass in tenish again, let's see how I'm going with his name tenish.

1:04:34.320 --> 1:04:40.440
 Okay, so he returns back hello to niche.

1:04:40.440 --> 1:04:43.960
 So this is how these APIs work, right?

1:04:43.960 --> 1:04:56.400
 So we can use JavaScript to call the API and we've got some examples.

1:04:56.400 --> 1:05:04.920
 So I've created a website and here is my website, tiny pets.

1:05:04.920 --> 1:05:09.120
 And on this website, as you can see, it's not the most amazingly beautiful thing, but

1:05:09.120 --> 1:05:10.520
 it's a website.

1:05:10.520 --> 1:05:11.720
 It's a start, right?

1:05:11.720 --> 1:05:13.760
 And up here I've got some examples.

1:05:13.760 --> 1:05:23.040
 Here you go, single file, click, choose file, click.

1:05:23.040 --> 1:05:27.160
 And in this example, I'm actually doing full pet classification.

1:05:27.160 --> 1:05:32.440
 So I actually trained a model to classify breed, which we'll talk about more next week,

1:05:32.440 --> 1:05:33.920
 rather than just dog versus cat.

1:05:33.920 --> 1:05:39.440
 So let's pick a particular breed and we run it.

1:05:39.440 --> 1:05:43.120
 Oh, and there it is.

1:05:43.120 --> 1:05:47.800
 Now, not very amazing, right?

1:05:47.800 --> 1:05:53.480
 But the fact is that this is now a JavaScript app means we have no restrictions about what

1:05:53.480 --> 1:05:54.720
 we can do.

1:05:54.720 --> 1:06:00.000
 And let's take a look at that HTML.

1:06:00.000 --> 1:06:01.240
 That's it.

1:06:01.240 --> 1:06:04.400
 It easily fits in a screen, right?

1:06:04.400 --> 1:06:09.440
 And the basic steps are not crazy, right?

1:06:09.440 --> 1:06:15.280
 It's basically we create an import for our photo.

1:06:15.280 --> 1:06:19.840
 We add an event listener that says when you change the photo, call the read function.

1:06:19.840 --> 1:06:27.800
 The read function says create a file reader, read the file.

1:06:27.800 --> 1:06:33.880
 And when you finished loading, call loaded, and then loaded says fetch that.

1:06:33.880 --> 1:06:40.800
 Now that path there is that path there, right?

1:06:40.800 --> 1:06:44.760
 Except we're doing the full pets one.

1:06:44.760 --> 1:06:53.880
 So this is basically just copied and pasted from there, from their sample.

1:06:53.880 --> 1:07:01.640
 And then grab the JSON and then grab from the data, the first thing, the conferences,

1:07:01.640 --> 1:07:05.720
 the label, and then set the HTML.

1:07:05.720 --> 1:07:08.680
 So as you can see, it's like, okay, if you haven't used JavaScript before, these are

1:07:08.680 --> 1:07:09.960
 all new things, right?

1:07:09.960 --> 1:07:12.560
 But they're not, it's not harder than Python, right?

1:07:12.560 --> 1:07:16.640
 It's just another language to learn.

1:07:16.640 --> 1:07:20.680
 And so from here, you can start to build up, right?

1:07:20.680 --> 1:07:26.560
 So for example, we've created a multi file version.

1:07:26.560 --> 1:07:30.880
 So with the multi file version, let me see, multi file, choose.

1:07:30.880 --> 1:07:35.960
 So we can now click a few.

1:07:35.960 --> 1:07:40.880
 So we've got a new fee, a rag doll, a basset hound, and some kind of cat.

1:07:40.880 --> 1:07:42.800
 I'm not much for cat person.

1:07:42.800 --> 1:07:48.600
 So we chose four files and bang, all being classified.

1:07:48.600 --> 1:07:51.640
 Apparently it's a bengal, I wouldn't know.

1:07:51.640 --> 1:07:53.160
 Here's our new found.

1:07:53.160 --> 1:07:54.680
 So there's the multi file version.

1:07:54.680 --> 1:07:58.080
 And if you look at the code, it's not much more, right?

1:07:58.080 --> 1:08:04.240
 It's now just doing, it's getting all the files and mapping them to read and now appending

1:08:04.240 --> 1:08:05.240
 each one.

1:08:05.240 --> 1:08:10.120
 So not much more codable.

1:08:10.120 --> 1:08:16.200
 And as you might have seen on our site here, there's a few more examples, which is some

1:08:16.200 --> 1:08:21.640
 of the community during the week has created their own versions.

1:08:21.640 --> 1:08:30.920
 So this one here is, I think this is, yeah, this is from one of the radio guys.

1:08:30.920 --> 1:08:33.840
 They call it get to know your pet.

1:08:33.840 --> 1:08:38.640
 So if I choose a pet, I kind of, I really like this because it actually combines two

1:08:38.640 --> 1:08:39.640
 models.

1:08:39.640 --> 1:08:42.280
 So first of all, it says, oh, it's a basset hound.

1:08:42.280 --> 1:08:44.520
 And then it lets me type in and ask things about it.

1:08:44.520 --> 1:08:51.560
 So I can say, oh, what kind of tail does it have?

1:08:51.560 --> 1:08:53.000
 Search.

1:08:53.000 --> 1:08:59.240
 And so that's now going to call an NLP model, which asks about this.

1:08:59.240 --> 1:09:03.000
 Oh, it's a curved saber tail.

1:09:03.000 --> 1:09:04.840
 There we go.

1:09:04.840 --> 1:09:11.800
 What maintenance does it need?

1:09:11.800 --> 1:09:16.760
 So again, like here, you can kind of see how, oh, a basset hound's ears must be cleaned

1:09:16.760 --> 1:09:19.120
 and sorted out frequently.

1:09:19.120 --> 1:09:20.680
 So this is like combining models.

1:09:20.680 --> 1:09:25.920
 So you can see this is something that you couldn't do with just a kind of a ready to

1:09:25.920 --> 1:09:29.600
 go interface.

1:09:29.600 --> 1:09:36.240
 And so the next thing I wanted to point out is how did we create the website?

1:09:36.240 --> 1:09:39.240
 I showed you how to create an HTML file.

1:09:39.240 --> 1:09:43.640
 But like, how do you create those and how do you make a website out of them?

1:09:43.640 --> 1:09:45.360
 Well, watch this.

1:09:45.360 --> 1:09:55.600
 Let's here's a, here's the source code to our most basic version.

1:09:55.600 --> 1:09:56.600
 Okay.

1:09:56.600 --> 1:10:00.840
 So I could just save this.

1:10:00.840 --> 1:10:07.640
 There we go.

1:10:07.640 --> 1:10:09.960
 Okay.

1:10:09.960 --> 1:10:20.440
 So we can open that with Visual Studio Code.

1:10:20.440 --> 1:10:25.120
 And what we could actually do is we could, here it just is an explorer or Mac and Finder.

1:10:25.120 --> 1:10:28.560
 I could just double click on it.

1:10:28.560 --> 1:10:29.560
 And here it is.

1:10:29.560 --> 1:10:32.640
 It's a working app.

1:10:32.640 --> 1:10:37.680
 So you can see I don't need any software installed on my computer to use a JavaScript

1:10:37.680 --> 1:10:38.680
 app, right?

1:10:38.680 --> 1:10:39.880
 It's a single file.

1:10:39.880 --> 1:10:41.400
 I just run it in a browser.

1:10:41.400 --> 1:10:44.760
 A browser is our complete execution environment.

1:10:44.760 --> 1:10:46.080
 It's got a debugger.

1:10:46.080 --> 1:10:47.080
 It's got the whole thing.

1:10:47.080 --> 1:10:51.440
 So here you can, you know, here you can see it's, it's just calling out to this external

1:10:51.440 --> 1:10:52.440
 hugging faces end point.

1:10:52.440 --> 1:10:55.000
 So I can do it all sitting here on my computer.

1:10:55.000 --> 1:11:02.760
 So once I've got my HTML file that's working fine on my computer in VS Code, how do I

1:11:02.760 --> 1:11:06.400
 then put it on the web so that other people can use it?

1:11:06.400 --> 1:11:09.040
 Again, the whole thing's free.

1:11:09.040 --> 1:11:14.440
 There's a really cool thing called GitHub Pages, which basically will host your website

1:11:14.440 --> 1:11:15.520
 for you.

1:11:15.520 --> 1:11:23.200
 And because it's just JavaScript, it'll, it'll all work just fine.

1:11:23.200 --> 1:11:28.120
 The easiest way to create a GitHub Pages site, in my opinion, is to use something called

1:11:28.120 --> 1:11:33.440
 Fast Pages, which is a fast AI thing.

1:11:33.440 --> 1:11:43.640
 And basically all you do is you follow the setup process.

1:11:43.640 --> 1:11:45.840
 So first it does, let's just go through it.

1:11:45.840 --> 1:11:48.000
 So it says, generate a copy by clicking on this link.

1:11:48.000 --> 1:11:49.840
 So I click the link.

1:11:49.840 --> 1:11:51.840
 All right.

1:11:51.840 --> 1:11:53.720
 Okay.

1:11:53.720 --> 1:11:57.040
 Give it a name.

1:11:57.040 --> 1:12:01.760
 I try to make everything public.

1:12:01.760 --> 1:12:04.000
 I always think it's good, good practice.

1:12:04.000 --> 1:12:09.840
 You don't have to create repo, generating.

1:12:09.840 --> 1:12:10.840
 Okay.

1:12:10.840 --> 1:12:12.640
 And then there's basically two more steps.

1:12:12.640 --> 1:12:13.640
 It takes about five minutes.

1:12:13.640 --> 1:12:14.640
 We don't have five minutes.

1:12:14.640 --> 1:12:24.560
 I'll show you the one that I've already built, which is fast AI slash tiny pets.

1:12:24.560 --> 1:12:30.040
 And so once it's done, you'll basically end up with this empty site, which again, you

1:12:30.040 --> 1:12:36.160
 just go code, open with GitHub desktop, or open with Visual Studio, whatever.

1:12:36.160 --> 1:12:40.720
 So open with GitHub desktop, or you can copy and paste this to your terminal.

1:12:40.720 --> 1:12:44.160
 And so any one of those is going to get you this whole thing on your computer.

1:12:44.160 --> 1:12:49.400
 You can save your HTML files there, push it back up to GitHub.

1:12:49.400 --> 1:12:55.360
 And what you'll find is we'll, we'll, fast pages will show you the link to the website

1:12:55.360 --> 1:12:57.120
 that is created for you.

1:12:57.120 --> 1:13:04.040
 Now the website that's created for you, you can make it look however you want using something

1:13:04.040 --> 1:13:05.040
 called a theme.

1:13:05.040 --> 1:13:10.680
 So you'll see it's created a file called config.yaml, where you can pick a theme.

1:13:10.680 --> 1:13:18.400
 So in this case, I picked a theme called a limbic, for no particular reason.

1:13:18.400 --> 1:13:21.760
 So GitHub pages uses them in called jackle.

1:13:21.760 --> 1:13:25.120
 And so any jackle theme will, will basically work.

1:13:25.120 --> 1:13:27.200
 So I picked out this theme.

1:13:27.200 --> 1:13:33.840
 And so as a result, when I now save things into this repo, they will automatically appear

1:13:33.840 --> 1:13:35.680
 in this website.

1:13:35.680 --> 1:13:39.720
 And the files automatically appear up here in this list.

1:13:39.720 --> 1:13:49.000
 So if you look at my index, that's the home page, the entire file is just this.

1:13:49.000 --> 1:13:54.680
 The only slightly weird thing is at the top of every GitHub pages file, you have to have

1:13:54.680 --> 1:13:58.920
 three dashes, title and layout and three dashes.

1:13:58.920 --> 1:14:02.240
 It's called front meta.

1:14:02.240 --> 1:14:09.280
 And so once you do that and save it, it will appear in your website.

1:14:09.280 --> 1:14:14.080
 So something else I did then is like, okay, well, that's all very well that Fast.i has

1:14:14.080 --> 1:14:16.960
 created this website, but I don't really like what it looks like.

1:14:16.960 --> 1:14:19.000
 I would have created a different version.

1:14:19.000 --> 1:14:20.000
 No worries.

1:14:20.000 --> 1:14:24.320
 You can go to Fast.i tiny pets and click fork.

1:14:24.320 --> 1:14:27.800
 And when you click fork, it's going to create your own copy.

1:14:27.800 --> 1:14:34.320
 So I did that under my personal account, which is JPH00.

1:14:34.320 --> 1:14:36.640
 And look, I've got my own version of it.

1:14:36.640 --> 1:14:38.400
 And now I can make changes here.

1:14:38.400 --> 1:14:39.520
 So I made a few changes.

1:14:39.520 --> 1:14:48.040
 One change I made was I went to config.yaml and I changed the theme to pages themes hacker.

1:14:48.040 --> 1:14:52.640
 So once you fork, one thing you have to do, which normally fast pages does for you is

1:14:52.640 --> 1:14:58.960
 you do have to go to settings and click pages and actually enable GitHub pages.

1:14:58.960 --> 1:15:01.520
 So you basically have to, by default, it's turned off.

1:15:01.520 --> 1:15:03.080
 So here you'll just have to turn it on.

1:15:03.080 --> 1:15:06.400
 So use the master branch route save.

1:15:06.400 --> 1:15:07.400
 And then it'll say no worries.

1:15:07.400 --> 1:15:09.520
 It's ready to be published.

1:15:09.520 --> 1:15:12.720
 And so I changed the config.yaml file to point at a different theme.

1:15:12.720 --> 1:15:17.680
 And so if you look at now the JPH is tiny pets.

1:15:17.680 --> 1:15:18.680
 It's different.

1:15:18.680 --> 1:15:19.680
 Okay.

1:15:19.680 --> 1:15:25.520
 So it's got the same info, but it's much more hackarish because JPH00 is a serious hacker,

1:15:25.520 --> 1:15:30.160
 as you can tell from his website.

1:15:30.160 --> 1:15:37.520
 So anyway, look, it's a very brief taste of this kind of world of JavaScript and websites

1:15:37.520 --> 1:15:38.720
 and so forth.

1:15:38.720 --> 1:15:45.680
 But I wanted to give you a sense of like, you know, you don't need any money.

1:15:45.680 --> 1:15:49.240
 You don't need any IDEs.

1:15:49.240 --> 1:15:56.920
 You don't really need much code to get started with writing your own web apps.

1:15:56.920 --> 1:16:01.400
 And thanks to hugging face spaces, you know, they'll even host your model for you.

1:16:01.400 --> 1:16:06.000
 And all you need to do is just have the magic string with a thing to call.

1:16:06.000 --> 1:16:07.440
 Okay.

1:16:07.440 --> 1:16:12.160
 So signing out hacker, Jeremy Howard.

1:16:12.160 --> 1:16:14.440
 Thanks very much for watching.

1:16:14.440 --> 1:16:18.200
 And in the next lesson, we're going to be digging into some natural language processing.

1:16:18.200 --> 1:16:21.520
 We're going to be doing some of the same stuff, but we're going to be doing it with

1:16:21.520 --> 1:16:23.120
 language rather than pictures.

1:16:23.120 --> 1:16:29.040
 And we're going to be diving under the hood to see how these models actually work.

1:16:29.040 --> 1:16:32.720
 We're going to learn about things like stochastic gradient descent.

1:16:32.720 --> 1:16:36.160
 And we might even be having to brush off a little bit of calculus.

1:16:36.160 --> 1:16:39.080
 I hope I haven't put you off by saying the C word.

1:16:39.080 --> 1:16:40.360
 We'll see you next time.

1:16:40.360 --> 1:16:41.360
 Thanks all.

1:16:41.360 --> 1:17:10.160
 Okay.

