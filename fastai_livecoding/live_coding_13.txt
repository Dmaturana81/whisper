 Just continuing with this. Okay, great. Yeah. Any other new faces today? Ali, have you been here before? I don't remember seeing you. Maybe you've been quiet. I've been here. I don't think I've had the camera on. Okay. Yeah. Thanks me. And Nick is back from his tour of tropical islands. Hi, Nick. Yes. I'm not sure if I'm going to go to the city. But not so far away, though. Still pretty close. Yeah. Well, where do you're going to go to the island? Easy. By default. Hi, Marie. Nice to see you. Where are you joining us from? Hello. Hi. I'm joining from South. This bit. Uh huh. Yeah. I'm at the children's health. I'm not sure if anybody got anything they wanted to talk about or ask about before we dive in because I've got some good news, which is I've made things much easier in the horrible direction we went last time. All right. Sounds like I should dive in then. I know there was like, as I rather expected and quite fair enough some, some concern on the forum about how. Complicated and weird this all is, which is partly because we're kind of like jumping into stuff we'd normally do in part two and so we haven't quite got the. Yeah, then all the necessary background here. And so, yeah, don't worry if you're feeling a little. At C. It's a good way to like, I don't know, start to see like some stuff you could. Look into after the course is finished. All right. So let me just. Jeremy. Yes. Sorry. Just don't mentioning part two. Are you planning a part two this year? Planning would be too strong a word, but as much as I ever plan anything thinking about. Yes, I would absolutely like to do a part two this year. Awesome. And the fact that you're asking that question means that you are not up to date on our discord. So you should definitely join our discord channel because we've actually been talking about doing a. Conference or an conference to go with part two at the end of the year in Queensland. And a lot of folks from. Places that are not in Australia are saying they would be up for coming coming here for that. You know, partly a kind of a social thing. And also trying to do it all in a very covert safe way of kind of outdoor and masked and. People tested ahead of time and stuff. Yeah, so that's. Yeah, so nothing's planned like we don't have dates or a syllabus or anything like that, but we absolutely hope to have something awesome. Maybe towards the end of the year. Where we can get to get to know each other a bit better and get to know. Fast AI and learning a bit better. Jeremy. Yes. Can I ask you? Are you going to continue this work for next week because I know that the class going to be soon next Tuesday. Yeah, I think so. Like the fact that I'm doing it this week is. Interesting because yeah, like. I. It has been I've got less time to actually work on the course, but. I also feel like the stuff we're doing, perhaps the stuff I can do use in the next lesson, depending on where we get to so. Yeah, so I think we'll do it next week. We'll see how things go if I get really behind then maybe not, but then I certainly plan to like. Continue the during them after the last class. You know, until. I don't know. We all know everything, I guess. And then we'll stop at which point there'll be more things to know so yeah. Okay. We don't have to stop necessarily. You know, there's so much to learn. The problem is that it's obviously a burden on your time, but it's. I enjoy it. I enjoy it. Like my issue is what about where we get to the point where there's nothing left to learn. Radek, what do we do then? You know, but is that such a point? Oh, they must, you know, this. But then we don't do it in a different language, right? We start doing it all in our or jubilee. See, plus that would keep us busy. I think this is my fifth year of doing fast AI courses. I'm trying to complete the part one. You see more static. All right. Let me see. So. Multi task. All right. I am just so happy about how this worked out, to be honest. Although spoiler alert, it didn't turn out to help our score. The score was about the same. I was so happy about how the whole process turned out. I kind of want to show you how I got there as well as where we ended up. And yeah, as soon as I kind of like turned off zoom last time and I went for a walk and then as soon as I went to that, I was like, oh, no, of course I know how we should do this. Really, so there's quite a few that, you know, we can make this much, much simpler. So let me explain what we're going to try to do. We are going to try to. Predict two things, the disease and the variety for each image. And the first thing will be to create a. Pair of data loaders that look like this to each image, they will have connected to things to them. The disease. And the type of race. So this is going to be step one. Right. So let me kind of show you how I got to that step. So that step one that I talk was to first of all try to replicate what we've already had before. Right. So, Patty's ball. But before I used image data loaders, which is like a, that's the highest level, least flexible function. You know, we can do all the data processing in a single line of code, but only if we want to do something really standard and trying to predict two things is not standard enough for it. Right. So we now need to go one layer down. And. There's like a lot of really good tutorials on Docs. Fast to AI. And because it's been ages since I've done any of this, I'd forgotten entirely how fast I work. So I use them very heavily to remind myself of what's going on. But for example, there is a data block tutorial. This pets tutorial is is great. It like it goes through all the layers of like different ways of doing things with fast AI pre processing. This Siamese tutorial is another really good one. So these are some of the things I looked at. And the other thing that I looked at was the actual API docs. So if I click here and data block. This is actually probably what I found the most useful in the end. There's lots of great examples in the documentation. So yeah, I, you know, as a kind of like, you know, how it is you come back to something a couple of years after you built it and you're now kind of the customer of your documentation. And so my experience as a customer of my documentation was I was really delighted by it. So I can definitely suggest checking all that out. So, you know, what you can do is before we were using image data loaders from folder. So if we just do the double question mark trick, we can see the source code for it. You know, and it's the normal size of fast AI things. It's very small. And you can see that actually all the work's being done by data block. So data block is the like, still, you know, still high level API, but not not as high level. It's actually very flexible. And so we're going to step step one that I did was to replicate exactly what we had before, but using data blocks. And for this, there's actually, you know, so many good examples in the tutorials and in the book, you've seen them all before. We don't need to talk about it too much. You know, we can basically say, okay, for the data block, the input will be an image. The output will be a category. This is just to do disease prediction. The labeling function will be the parent folder. There, legal, do a random split, the item and batch transforms, we can copy and paste from what we had before. And that creates a data block. So data loaders is then a data block dot data loaders, and you then have to pass in a source. So the source is basically at a. Anything that you can. Ederate through or index into to grab the things that will be passed to these to these blocks and this function. So for this, it's going to be a path. And then we also need to get items. And so the, well, when we get a path, we're going to pass that path into the. Get image files function because that's the thing that returns a list of all of the images in a path. And let's see if that works. How do you know that in the, okay, so the block, you have an image block category block. How do you know that, like, how do you, how do you know that the get image files is going to be able to feed both those blocks. So I guess the short answer would be, you know, to read the documentation about those blocks to see what they take and what they do. Or any of the tutorials that use them, as you can see, they used all over the place, right? So start with this tutorial or this tutorial or this tutorial. So any of those would show you what it does. Yeah, the actual, let's say this, this is not good documentation. I'd really never bother to look at this because it's basically all of those. We should fix that. I guess because there's so many tutorials. I mean, as you can see, like, I guess the reason I never really wrote jocks right is it's literally a single line of code. So that's like, yeah, so maybe look at the code is actually interesting in this case. So an image block is something which calls. Class.create where a class is. image that's going to call pil image.create. So to find out what's actually going to be called by it, you can go. Pil image.create. And you can see it's going to get passed to file name, which can be a path or a string or various other things. So get image files, then obviously you can either run it to see what it comes out with or let's do that so we could just run get image files. Passing in the thing it's going to be given, which is the path. And so as you can see, it's a bunch of paths. And so we could pass one of those. I'll be that and it's going to be passed into this function. So we've now just replicated exactly what's happening in the code. Yeah, but for this I generally just look at the tutorials which tell you what to do. Could you have two different get items that feed different blocks. We're going to come to that. Okay. Okay. Park Park that. So. Yeah, so also a bunch of transform like it gets transformed later after reading. Right. Yeah, we got the batch transform. Yeah. But in the in the block. Because right now we have a image or something and it needs to become a sensor. Right. Yeah, that's right. It gets changed from an answer to a float tensor later on. That's right. Yeah. That's a, yeah, that's a fairly subtle thing, but that's right. The. We stick that in something image equals. And we look at like NP dot array image. It's actually stored as bytes or you would hate as they call it in PyTorch. So, yes, the. This is going to add a batch transform that's going to turn that into a float tensor, which we can see. That's going to look like we could run it here. I expect. To float tensor. The transformation that we're applying is 224, which is like a square image. Correct. A 224 by 224. This one here. Yes. Yeah. So this is doing data augmentation of lots of different kinds. So. Let's. Copy. Paste. And if we show the data augmentation, looking at the docs is particularly important because you can see examples of the. Or notations of does, so it tells you a list of all the augmentations and how you can change them and here's some examples of what they look like. And augmentations would happen after the into float tensor. Yes, that's. Some data augmentation that operate on the entire batch and some operation. Yeah, that's right. So the ones in batch transforms operate on a whole batch and the ones in item transforms operate on a single item. And so batch transforms. And so they operate because they operate on a batch before you get there, everything has to be the same shape. So it can be turned into a batch. So this resize resizes everything to the same shape. And then this does these various different types of data augmentation. And one of the key pieces of data augmentation it does is to randomly zoom into a subset of the image as you can see. And these various examples here. And the data looking guy. Can you also use it with data frames where you would be reading your images from a different. We're going to do that. We're going to do that in a moment. Yes. So yeah, I'm kind of like skipping over quite a bit of this because. Super well covered in the tutorials so I don't want to like say stuff that you can very easily read rest of stuff and better show you isn't as well covered in the tutorials and it's kind of new. But yeah, feel free to keep asking questions about anything you see. So basically, yeah, so all we've done is we've just this is just the same thing that we have in lesson one. I just and it's doing exactly the same thing as my image data load is not from folder but just 10 and 10. And so that this is what I did just to show you through my process with step one was to get this working and then I passed that into a learner and I. So let's go copy. And. And I want this to order run as fast as possible. So I would use the fastest. Do you when you make this data loader thing do you try to make sure that the shape that it's outputting is what you need for your model or that's later. Well, I generally use models have all which don't care what size they get. So yeah, that's one of my that's one of my tricks. So resident 18 is happy with any size. So actually for my testing, I'm going to bring this back down to 128. So it's super fast. And so I just want to get the maximum iteration speed here. And so now I can call learn dot. One cycle. And let's do one epoch. Okay, so this is going to run in under 20 seconds, which is kind of what you want. Right. You want something that you can test in under about 20 seconds so that way you can just quickly try things and make sure that end to end. It's working. So the error rate is down to 30%. So that's, that's a good sign. I guess one correlated question is, okay, I understand the input size. But what about the output size of your data block like, you know that this is what you need for that model. You know, let's say the model doesn't care the model's happy with any size. I mean, the targets, or whatever. You hear about the labels. I mean, labels don't have sizes. The labels are strings. Or just to this the shape of that like, hey, like is it. You know, because maybe different models are kind of kind of predict different types of stuff. Potentially, I don't know. Like, some might have shape of the. I suspect the thing you're kind of asking is the thing that we're going to be covering in a moment. So maybe put that on hold and then tell me if it makes sense. Okay. I have a question. On the data block. And you randomly select the amount of records or the amount of the batch size that you're going to process. I don't randomly pick the batch size. No, the batch size is actually selected in the data letters call. And it's 64 64. So, what is the guarantee that that every single one of the images in this particular case will be selected or there's no way to know. Is there any way to know that every single one will be. Yes. I mean, well, I'll be there. Yes, except that we're randomly selecting 20% of the validation set. But every single, every single one will go through the learner of the of the 80% that are in there. Everyone will go through our learner because we randomly shuffle them. And then we iterate through the whole lot. In a single epoch. The model is guaranteed to see every example that this train just wants. Yeah. And that's what this one means. That's what one epoch means is look at everything once. And so if we put to there or look at everything twice, but each time it randomly shuffles it so it doesn't in a different random order. I'll have a quick question. What I guess this is by torch data loader stuff. But what actually happens for the last batch? The last batch, it depends. And this is actually not the high torch data loader. It's actually fast day is data loader. So we have our own data loader. Although in the next version, we're likely to replace it with the first day one. So it depends what drop last is if drop last is true, then it deletes the last batch. And if it's false, that includes the last batch. And the reason that's interesting is that the last batch may not be. Of size 64. Yeah. For the validation set, it always keeps the last batch. And it's super important to shuffle the transit the first day I does it for you. But if you will, you know, mess around with the data loaders or do something yourself. If you don't suffer the transit, you might get very poor training performance. Yeah. When we used to use care us I used to mess all this stuff up all the time. Yeah, trying to get all those details right. It's really annoying. Just to make sure on something you said, you said in next iteration, you're going to replace it with the pie torch data lures. Yeah, probably. Yeah. You said fast. I've said I've confused. Oh, did I. That is confusing. Thanks. Okay. So that was my step one is to just get it working exactly like before. And then I ran, then I ran it with. In the background on the same architecture for the same epochs to make sure I got about the same error rate and I did. So then I was happy that, okay, I'm matching what we had before. So then step two was to try to make it so that the data block spits out three things, which would be one image and two categories. The category of disease and the category of rice type. So to get it to spit out an image and two categories, hopefully you wouldn't be surprised to hear that we just. Do that. We say we want three blocks an image and two categories. Now, this variety, we did some way of getting that given an image ID. And actually the way I did it was a bit ugly. And since then I thought of a better way of doing it, which is what I think we should do is we should create a dict that maps from image ID to variety. And then our function will just be to look that up. Right. So let's call this image to variety. Equals. Okay, and it's going to be a dict, a dict comprehension. So we're going to loop through. The rows in. D F dot. Data items. Now I always forget what these differences are. Column name, comma series pair. Returning a tuple with the column name. Okay, that's not what I want. Okay, get a rose. Yeah, get a rose. Index comma series. Okay, cool. I think like this, it a tuples is the fastest one. But you know, this is not very big. So let's keep it simple. Okay, so this is going to iterate over rows and return. Index class series. Okay, so we don't really care about the index. And another thing we could do is make the image ID the index and then you could actually jump straight into it. But I think I'd rather not use pandas features. I'd rather use more pure Python. Things because I think that'll make the explanation a little clearer. So we're going to look through. It's going to give us the index and the row. And so what we want is the key will be the rose image ID. And the value will be the rose variety. Okay, that looks good. So then there's a couple of ways we could turn this into a function. And I'm just going to show you a little neat trick, which is when you go like the let's pick out something. Let's see, we're going to grab this one. When you go like this. Behind the scenes that square bracket thing is actually calling a special magic method in Python called done to get item. Which is a function. This is the cool thing about Python. It's so dynamic and flexible like all the syntax sugar is like behind the scenes just calling functions. Basically, that's exactly the same thing. Right. And so that means that this function here image to variety done to get item is a function that converts a file name into a variety. So here's the cool thing. Forget why you can pass it an array. And it's going to call each of those functions. Which I think is rather nice. So another thing I find helpful. Okay, cool. So when I call that, it complains. And it says, Oh, get why it contains two functions, but it should contain one one for each target. It thinks that there's only one target. Why is that? Well, if you think about it, we've said there's three blocks, but we haven't told it how many of those blocks. So for the independent variable and how many of the dependent variable. And so we have to tell it. And the way we do that is to say the number of inputs equals. And so it's one. We have one input. And then the rest will be outputs. So when we do that, it's now happy. Okay. And personally, before I jump to data loaders, I first create data sets. Just to make sure they work. So you can create data sets. So you can create data sets. And so, all right. So we've got an error. Okay. So here's the problem. It tried to look up our function. And then we have a problem. And then we have a problem. And then we have a problem. And then we have a problem. And then we have a problem. It tried to look up our function. And in fact, it's not indexed. It's not passing in. The string of the name. It's actually passing in. The path. And so that's why we got a key error. This path does not exist as a key in this dictionary, which is quite true. Right? It doesn't. So what I think we should do is fix this up. So that we've got train images, bacterial leaf streak. Okay. Get files. Function. The output of that is being passed to the get. Or get items is being passed to get. Right. So get image files. Yeah. So we haven't kind of gone into the details of exactly what's going on behind the scenes. So we're going to do that. Okay. Let's do that in a moment. Okay. I kind of like the way you're wanting to jump into the nitty gritty. But it's a little bit. I'm trying to do more top down. Right. So I'm going to get to your bottom up. We'll meet in the middle. Okay. Okay. Okay. By the way, your video is not on. That's fine. I just don't know if it's intentional. I always like to see people when they're. You know, seeable. Hello. We're not going to use this trick after all. We're going to create a function called. Called get variety. Actually, no, but yeah, let's create a function called get variety. And so it's going to get past. A path. Okay. And so we're going to return. Image to variety. And we're going to return image to variety. With the name. Of the file. So the name of the file. Is the string. Wait. We need image to variety. The dunder thing. Oh, yeah. I'll just grab record. Actually, yes. Yes. Okay. Oh, and then we need to use that. Okay. Yeah. Okay. Okay. So dss. Um. It contains a dot train data set. Okay. And it also contains a dot valid data set. Okay. And so we can look at the zero thing in the training data set, which is a single thing. Right. So we can have a look now. There's image and y one and y two. And so then we can look at the image, for example. Okay. So what's happened here is that get image files returned a list of paths. The first one got passed to image block, which as we saw earlier got passed to pio image dot create. And here it is. Um, and that path name also got passed to a function called parent label. In fact, let's do it. Right. So let's say file name equals get image files. And then the thing that we passed in training path. And it's just get the zero one. Okay. And so. There it is. Right. So, um. It ended up calling pio image dot create. With that file name. Okay. It also called parent label with that file name. Okay. And it also called get variety with that file name. Jeremy, can we look at get variety one more time? I'm just curious how you build the path. I didn't. I removed the path. I called dot. Okay. Okay. Yeah. I see. Yeah. Yeah. And my original version of this, I did it the other way round of like building back up the path and then realize that that was kind of stupid. So, um, yeah, it's unique. So that works. One question. Okay. Okay. This could be to, you know, low level, but just let me know. Can you have multiple get items? Is this the right place to ask that or that's. Yeah, so it wouldn't make sense to have multiple get items, right? Like, right. It returns a single thing, but it could be anything you like, right? It could be. It could return a top hole or a list or an object or whatever. Right. And so, or a dict. And then get why and get X. Now, then the things responsible for pulling out the bit that you need to pass to your blocks. Now, we don't, we don't need to get X because image blocks. Just take parts directly. So if I needed something a bit more like, I need it wanted to put more things and get image file, like have it admitted to pull. Then would I have to like make my own image walk to ignore. No, not your image block. You would write your own function, just like get image files. That returns the list of all of the objects you want, whichever the information you need. Okay. And then like, it almost never happens. I don't think that's ever happened to me because like nearly like nearly always there's like a row of a database table or a path or something has all the information you need to like go out and get the stuff with your get X's and get wise. And that's like the central piece of information for each row. And based on this information, you can read in text can read an images. Yeah, but you know, specific to that one. Actually, let me show you my hacky version. This is the version that uses a data frame. So this is. So the version that uses data frame. Yes. Is it, is it right to think. Yeah, that's interesting. Let me just do this and then we'll get a come to your question. Okay. So in this data blog, I started out with a data frame. Like so. Right. And so by passing into data blocked up data load as I passed in the data frame. It's going to get it's going to get each row. Right. And so then get why. Becomes call read or one, which is just a function, which I mean, it let's look at it. It's doesn't do much. It. Let's see what it does. So it's got it's it's done as an object because you can do things like add in a prefix path and a suffix path and you can split it with a label delimiter and whatever. But basically. You know, all it's basically doing. Okay. And it like checks what kind of thing you're passing in. But basically all it does is it calls. Get at your to grab the column. And we. Or reader for on that, like reading data. Sorry. Is this call reader function specifically for data frames? I mean, it can work with anything basically that that you're so what it's doing here is it's yeah, it's saying grab that column. But it's really, you know, I've only really used it for data frames, but you could use it for anything. But yeah, so basically here get why it's saying, okay, well, let's return the index one field and the index two field. You know, and. What's up with the eggs. Yeah, so, so because now we're being passed. So you can't pass a row of a database table to P. Oh, image dot create. So get X is this function. Which basically is going, oh, it's going to be in the training path slash disease name slash. Image name. And then there's a special case for the test set because the test set things are not stored. In sub folders according to label because we don't know the label. So it's just directly in the test path. That's the, as I said, this was more hacky. I don't. This is a. This really helps. So like, I get X is kind of like get why you can have a list in there. Yeah, you can have it. Yeah, it's totally flexible. And I mean, seriously, how more like this, like we have so many examples of all of these. Patterns in the docs in the tutorials. So like this exact pattern. Let's take a look at one right. Docs. Last day. So tutorials. Do data block tutorial right here. Look, model label. So here's one. And yeah, you can see here. This is even splitting based on columns in the database table. And here's the call reader using the prefix and here's a call reader using a label delimiter. And here's the examples coming out. Yeah. So there's some. Yeah, lots of examples. You can you can check out. To see how to do all this. Yeah, so I think I'm at a point now where I actually do want to go into the weeds. So Hamill, you're now after this totally free to ask any super weedy questions. The most basic kind of data block is called the transform block. And the transform block. Basically. It's going to store a bunch of things you pass in. It's going to store things called type transforms. It's going to store things called item transforms. It's going to store things called batch transforms. And also it always adds one thing, which is to tensor because pytorch is tensors. If you look at the image block. We saw that that's defined as a transform block. Where the type transforms is this and the batch transforms is this. So now's a good time to talk about how this all works, what this does. So if I pass in here transform block. And don't pass any transforms. It won't do anything. So if I. Let's get rid of like. Pretty much everything. So if I do that. Okay. Here is the world simplest data block. Okay. So if we. All that. As you can see, all it does is it takes the output of get image file zero. And turns it into a tuple containing one thing, which is the thing itself. If we have two transform blocks. It returns a tuple with two things in it. So, and the reason it's returning tuples is because this is what we want. When we train, we have batches, right, containing. Inputs and outputs potentially multiple inputs and potentially multiple outputs. Right. So that's why. You know, indexing into this gives you back. A tuple. My question. Yes. The block. The blocks can either be a list or a tuple. I don't know. Probably. Yeah. Okay. There's no idea. Okay. Okay. So then we can like. Do stuff to. The first thing in the tuple. So, get X equals. So, let's get a lambda. Oh, oh, oh, oh. Name. Hey, what are you doing? Oh. Something to do with lambda, right? Does name have to be call? No. Maybe it's notebook restart time. Oh, that's. Oh, I wonder if something happened to my. GPU server. I mean, something has happened to my GPU server. Oh, it looks like it's back. Oh, okay. It just recognized it just appeared. That's wild. Okay. I'm very. I don't know what just happened. It doesn't really matter. What are you, what are you doing right now? I'm just looking at the logs. See if anything just happened. Okay. All right. Okay. So, you see what happened here is. We, you know, got the first thing from image files, which was this and. Get X got its name. So we could also do. Get why. It equals land. Parents say. Okay. So, you know, it first went like. First, the, the thing went to the transform block. The items yet. So whatever. Get items got went to transform blocks. And then it went to get X and get why. Well, transform block doesn't do anything. Right. So, yeah, so it's basically. But the number of them you have is the number of like pipelines. It's going to, it's going to create. So if we created another one. But generally, if you have like an image block, it would do something. We're going to get to that. Yeah. So here, look, we've never. We're not quite there yet. Right. So let's get to that. And it's not quite the mental model you've got, I think. Now that I've got three transform blocks. I only have things to. Create two of them. So it's, it's sad. Right. And so we could. Put them here. For instance. And that's one is the Y in the first two or the X. Correct. Unless we say number of inputs. Equals one. Right. In which case now. We get X is just going to have to return one thing. It's going to be one function. And get why will be two things. Okay. So. You could. You know, you could even put it here instead, right? So you could say, oh, well, this is actually. We could put it here. Item transforms equals. And so the stuff, the transform block is stuff that is applied. But that transform. Why is that not working? It's like surprising to me. Okay. It's to be a type transform. Okay. Type transform. So it's now converted to. The type it's meant to be. So, so, Radik, you were asking about image block. I'm just, you know, curious. I want the pieces. Let me show you. Let me show you. So let's do it manually. So image block is just this. Okay. So let's not use image block. Let's instead. Why didn't the item transform work? Let's figure that out later. Yeah. I'll just be figuring out what's going on here and then we'll debug it. Okay. So now we've got three transform blocks, two of them which do nothing. The first one of which is going to call something.create. That was PIL image.create. So transform blocks don't, if you look at the code of them, transform blocks. Don't do anything at all. Right. They actually, they only store things. There's no, there's no done to call. There's no forward. There's nothing. Transform blocks don't do anything. They just store stuff. The data block is a thing that then going to go through and say, okay, for each thing, call its type transforms and then call to tensor and then call its item transforms and then a data load of time, call its batch transforms. So does that help answer your question? Hammel, it's not that a transform block doesn't get called. It just stores the list of things that will get called at each of these times. The first thing that gets called is type transforms. Wait, is that right? You think? That's not correct. The first thing that gets called is get X and get Y. And then the result of that is passed into type transforms. And so get X and get Y. So get X would be responsible for making sure that you have a path that you can pass to PIL image.create. That's the order. So this whole path of what happens, you know, sequence that legend. That listen data block, exactly. Now the data block code is frankly hairy and it could do with some, you know, simplifying and documenting and refactoring. It's not long. It's about 50 or 60 lines of code. In fact, it's almost all here. But basically, when you call dot data sets, really all it's doing is it creates a data sets object passing in all of the type transforms to it. And the answer to your question, Hammer, why didn't the item transforms get done is because item transforms actually get done by the data load or not by the data sets. So data sets only use the type transforms. And basically the only reason there's like quite a bit of code in here is we try to kind of make sure that if two different things have like the same type transforms, we kind of merge them together in a sensible way. So this is stuff to try to make sure this all just works. The type transforms are separate from the items transforms because of some optimization you can do with the type transforms. Because the type transforms are happening earlier, they're happening before data loaders time. So data loaders are the things that are going to take tenses. Right? So, or at least things that can be converted into tenses. So, yeah, so type transforms are the things that are going to create your data sets for you. And they're going to spit out things which need to be convertible into tenses. And then data loaders has item transforms, which are things like reshaping everything to the same size and batch transforms, which are things like data augmentation. But you can have an item transform around on the GPU or not. Right? It depends on the ordering. I don't think an item transforms generally going to run on the GPU because it's not a batch yet. I mean, maybe it's theoretically possible, but that would be pretty weird because you, yeah, you really would need things to be in a batch of things that you can be optimizing it effectively. And everything you buy transforms will run on the GPU. Assuming that you're using a GPU, I mean, there is a, this is, okay, this is some part of the code base we're not looking at today, but if there is a, I can't remember it. I think it might be a callback, which sticks things on the GPU. So it just depends on whether things are before or after that callback. Yeah, that's, that's probably a bit of a distraction. So let's skip that for now. To, to kind of revise the difference between data set and data loader. Is it best to revisit the PyTorch documentation and kind of? Yeah, pretty much. We have our own implementation of them, but our implementation of data loader is a superset of PyTorch's and PyTorch's data set is like, literally, it's an abstract class, it doesn't do anything at all. It's just a, so a data set is something that you can index into. And it returns a single tuple of your independent independent variables. That's what a data set's defined as a PyTorch. And therefore, that's what we do as well. A data loader is, is, you can't index into it. The only thing you can do is, is iterate through it. You can grab the next one and it gives you a mini batch. Which is a tensor. So that's, but yeah, this is a, that's a PyTorch concept. I guess I'm trying to understand the type transform thing, why it has to be done in the data set before the data loader. It doesn't have to be, but it's, it's like, we want data sets. Like data sets are a very convenient thing to have to have something you can like. Go into and grab items, you know, numbered x, y or z. That's, that's the basic foundation of the PyTorch data model. You know, is that there's things you can. I'm asking the type transform aspect of it. Yeah. So you need, you need something that converts the output of get image files. Into what you want in your data set. And that thing needs a name and the name we gave it was type transforms. Okay. I think I think I understand. Okay. Like you, this is not the only way you could do this. Right. But it's, it's, it's our way that's really nice because we now have this thing that you can say like, Oh, Hamill, can you show me the 14th image and it's label? And you can say, yes, no problem, Jeremy. You can type dss.train. Bracket 13. And, and there it is. Right. So, um, yeah, so that's just a convenient thing, basically. I guess a question around that is that if we did not have type transforms, then it would just be one more step in the item transforms, right? Yeah, I think so. You're just separating the sets out. Yeah. Your data sets would always just return a single thing or maybe the three, two things that get X and get Y results. And then your data loader would have to do more work, basically. Exactly. Yeah, which would be as perfectly okay way to do things as far as I can tell. And I think it would be a little harder to debug and work with and. Keep things decoupled. Yeah. I think it's a reasonable comment. Is it like anything you want to do upfront? That is like kind of uniform across your whole data set, maybe put it in the type of transform that you don't need to. Change at training time. Basically, like anything that you want to be able to like. Index into it and look at that thing. Really, you know. If you're not sure where to put it. I'd say just check it somewhere and don't worry about it. You know, like, like, you know, we kind of put. The rule is that, you know, you need something that. Can be turned into a tensor. Like that's, that's the way fast AI does it. So you need to make sure that your type transform. When you're working with our say I return something that is a tensor or going to be turned into a tensor. Which PIL image can be. For example. Okay. I think I understand it's kind of like a you want to just you want to make sure it's like a convenient thing that you understand to look at. Yeah. Okay. Yeah. Okay. So then like. Okay. So I can remove all that. That is that this is the definition of image block. So let's replace it with the word image block. Okay. And then. Let's change. Okay. Okay. Okay. So let's pop a.name here. Here's kind of something we want as our label right. That's one of our labels. And then the other label we wanted. Was the. Function call get variety. Right. Now we can't this breaks our rule. This can't be turned into a tensor. Because it's string. So what do we do about that? You might remember from a previous lesson we learned that what we do is we replace strings with integers. Where that integer is a look up into a vocabulary. It's a list of all of the possible options. So if we change this to category block. That is exactly what category block will do. Right. And so. Category block. It's got to type transform categories, which I'm not going to go into because it's not particularly exciting. But if you look up the documentation for categories, you can see how it does that. So basically internally now you'll find that the vocab is stored for these things. So if we look at this at the high level, get items. By the way, just about here's a vocab. Right. It's got two things. It's got the vocab for the diseases and the vocab for the varieties. Yeah. Sorry about it. Okay. So get items, it gets us the rows or the examples or whatever allows us to, and the core. And then from get items, we use get why or get eggs to transform it somehow. So that we can pass it into those blocks. Into type transforms are things that you can get triggered. Right. So they're doing a little bit something similar to get why, but like our building on what you can find us. Correct. Exactly. Because because these are like very general things. Right. And so I didn't want you guys to have to write your own every time. So these, these, these basically say, this is, I will work if you can pass me a path to an image. And this says I will work if you pass me a string. And so get X and get why then are responsible for ensuring that you pass them a path. And pass this one string and get image files is already returning paths. So we don't need to get X. This guy, but it's not returning strings. So we do need to get why for these guys. Okay. So I'm going to finish. I'm going to run a slightly over time. But let's have a look at. So this is exactly. Okay. So this is exactly the same as what we just had. Right. And so then we also then add the two things, which is the item transforms and the batch transforms. Some other time, we will talk about how it is that how come this is not being applied to the categories. It's only being applied to the images. For those of you interested in skipping ahead, the secret is using fast calls type dispatch functionality. Anyway, so that's. That's why we're getting these three different things image. We've got Y1. So it's turning me if we had an image, if we had an image block in our. Or our wives for our target. Yes. I think possible. Correct. Oh, wow. And there's a, there's a, have a look at the Siamese tutorial on the first day adopts because that has two images. Yeah. And like if you think about it, anytime we do segmentation, that's exactly what's happening. Right. The data augmentation is happening to X and Y. And this is like really. Unusual. I don't know of any other libraries that have this kind of totally transparent ability to do. Bounding boxes, segmentation, point clouds, whatever is dependent variables and have it all happen in unison very, very automatically. But at least it didn't used to be. Maybe there is now. Okay. So. So now I can create data loaders from that. And thanks to the magic of. Fast AI. This is so cool. Check this out. It's actually auto, auto labeling it with each of our categories. So thanks to stuff we'll discuss later. Basically, this stuff called. Type dispatch. Fast AI does a lot of things automatically, even though I don't think I've ever like explicitly coded this to work. It just does because of how the API is designed. So we now have something which can create batches of. Pictures and two different dependent variables. Each one of which has a category. And so. What we will get to next time is. It actually turns out well briefly mention it now actually. All that stuff I did last time about messing around with like multiple different heads and all that is actually totally unnecessary. All we need to do when we create our vision learner. Is tell it we don't have we don't want 10 outputs, but we are on 20 outputs. So normally it automatically figures out how many outputs you want by how many levels are in your category called dependent variable. But in this case we've got something custom right which is we've got a tuple of outputs. So we have to tell it we want 20 outputs that's going to make the final matrix that it multiplies by have 20 outputs. Now then you basically need to tell it what loss function. To use. And so if you look it up it turns out we used to use a loss function for this called cross entropy loss flat. So we're going to call that exact loss function on the first 10 items and we're going to compare that to the. Disease probabilities and then the second 10. We're going to compare to the variety probabilities and we'll do the same thing for having an error rate. Which just looks at the first 10 in the area of disease and the same thing for variety look at the second 10. The variety and so basically then if you train that. It's going to print out the disease and the variety error and the loss function will be the loss function on both. Both the two halves and interestingly. For this single model. This 2.3% disease error is the best I'd have got for this architecture. So at least for you for this single model case this was better than. Training. Something that only predicts disease. Anyway, we can talk about that more later because yeah we kind of spent more time. A quick question. Yeah. The last layer it's it's it's a flat 20. 20 output layered. Does this mean at inference time that we would have to do the soft max plus. What would it be? I can't remember. I had all that for you automatically. Yeah. Yeah. Great. All right. And by the way in the inference functions you'll see there's like always a. I think all the options is to like whether to do code and whether to put the final activation function on ocean stuff like that. Actually, now I think about it in this case because we used to custom loss function. I think that would have broken its ability to do it automatically. So yeah, okay, I'm going to say actually you would need to. Because like at least for the Kaggle competition I just needed the. Which disease had the highest prediction and whether it's soft max or not. It's going to be the same because that's a. Monotonic function. So depends whether you actually need probabilities or not. In my case, but in the. Yeah. Yeah, but you would really look at the first 10 or the second. I guess the first one. Yeah. So you can see it because otherwise. Yeah. So I was using TTA. Right. To do test plan and augmentation and I stacked up and I did an ensemble of TTA. And then I just did an arg max on the. Yeah. Yeah. All right. Yeah. In the architecture. You selected for resnet 18, 128. Is there any programmatic way to find out the size of or the input size of the. Models that you are trying to use. These models handle any input size. All right. All right. All right. All the resnets and all the com of next and or any input size. All right. Thank you. It's already the transfer model. That also tripped me up in the beginning, but there's a lot of interesting stuff there that might take a whole lecture to understand. All right. Thanks. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.
