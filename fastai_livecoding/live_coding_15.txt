 So you've got a new patty submission. Let's take a look. Kaggle competition. By the way, it's really beautiful to see over the last link or two all these fast AI people just pop up at the top of that leaderboard. It's so cool. Okay, fast AI fast AI fast AI fast AI. Who's this person? Is this fast AI? At least the top five. Yeah, like most of the top five or top tenor are following you in these walkthroughs. You've all got the same score though. Somebody's got to like, you know, Koreans got something secret source. Well, I've got a few ideas I can show you guys today if you want to try and take it a bit further, which I bet you do. Anybody have any comments or questions in the meantime? All right. Chair screen. And that's the right screen. And I'll move you guys under the other screen. And now I can see. Yeah. All right. So So, Addy, leaderboard. There we are. Where's Radik? Not here. Sarata? I see. I'm one thing that I guess it would be nice if it wasn't so sort of, I don't know, a little bit in this because I set this up in in paper space and then started running it and then I went to bed because it was taking so long. And I just have a fear that if my browser sleeps or goes to sleep that it'll just basically stop the session. Even though there's more hours and processor in the workstation is running, I wasn't sure. I mean, it shouldn't. But what happens is a queue's up for when your browser comes back. But the problem is there is some limit to how much it or queue. So although it'll run, if you've hit that limit, you won't see all the outputs, which is nearly just as bad. So, you know, there's a few things you can do. The most obvious one would be to use NVDev to export the notebook to a script and then run the script in Tmux. Because then you can close it down, come back, reattach Tmux and there it is. Okay. That would be interesting. Now something, yeah, so maybe we'll look at that sometime. Yeah, something I don't... Well, does paper space gradient let you have... doesn't let your SSH in with a suitable IP? I'm not sure. If you've got your own GPU at home, you know, or on AWS or GCP or whatever, then what I do is I run XRDP on it, which is a remote desktop server, and then I can connect to it like so and run Firefox. And so this is my... Yeah, this is my server's screen, you know, remote desktoping in. So if I now go in and run something... Hattie, I remember from last time. Okay, so I can set this running and then I can close it down, go to sleep, come back the next day, reconnect to that screen, and it's still been running. So like that's the preferred way to do it. But I... Yeah, as I say, I don't know if it's possible on paper space gradient. You can do it. Sorry, I got on. Machines seem to have a limit of six hours. Do I have seen so far? If you subscribe to their pro or whatever, you can bump it up or get rid of it altogether. So... It's this tab here, machine tab, you can change the auto shutdown. Okay, looks like a week's a maximum. Oh, no, there's a no limit there as well. So... When you're paying, but I mean, you know, it's... I think it's like eight bucks a month. Yeah, eight bucks a month. You may as well. Yeah, I've got the pride that I don't have on the... when you pick a free machine. Oh, yeah. Yeah, right. Free P5000. Point. Maximum six hours. Yep. So, Jeremy, sorry, interrupt. Paper space in their support channels, they talk about you can assign a public IP to a machine and then SSH to it. So you could SSH and then T marks to a gradient machine though. Well, good question. I don't know about that. Look, I'm not sure that it would be. So... Bandstupptions. No, it's not. And... So they also have this thing called Core, right? Which are more like AWS or Google servers, which absolutely lets you do a static IP. And you don't even need... I don't even know if you need a static IP necessarily, but you could use a dynamic IP. We'll work just as well. Bit cheaper. The thing is though, I reckon they're pretty expensive. Yeah, Core. Product. So that... These are very basic GPUs. So that's not bad. 45 cents an hour. I guess they're not too terrible. Or if you want to Tx. Oh no, I guess they're the same price really. 56 cents. All right, I'll take that back. I guess the thing I found expensive was this CPU pricing for running it all the time. So, Jeremy, with this RDP solution that you showed, how does that work? Do you have any... Oh, just a moment, Reddit, close here. Okay, so how does it work? I didn't get to what computer you're RDP into. I'm RDP into my own GPU machine. But it could just as well be a AWS machine or GCP machine. This is basically the same as VNC, if you've come across VNC before. RDP is the kind of Microsoft version of that. I like it generally quite a lot better. And much to my surprise, the Mac client RDP is better than the Windows client RDP. Even shows you a little mini screenshot, you know, with the screen. So yeah, this is now finished training. No, not nearly finished. Halfway through training, whatever. What's this tricky to set up? Because you're running in X server. No, not even slightly tricky to set up. So yeah, you just... It's called XRDP, since it's RDP for X Windows. And you just go App to install. Yeah, I hate installing this kind of thing. It drives me crazy, but this is it. You just pseudo App to install. So you just go to the console, pseudo Ad user, pseudo system CTO restart. And then you might also want to run pseudo system CTO enable, which will cause it to automatically start when you start your computer. And I don't think I... Oh, you know, if you've got a firewall, you'll have to let it in. So it's port 3389. Basically, this line of code. And I think I did have a firewall. So I also ran this. Yeah, that was it. It just used my username and password that I had on the machine. It's crazy. Yeah, so... Come, very surprisingly, not annoying. And then I think I just installed Microsoft remote desktop from the Mac App Store. Or on Windows, I think it comes with Windows. So that was easy. Yeah, nobody seems to talk about it. My article, I'm going to talk about the NC, which is also fine, but tends to... I find it a bit slower and a little bit more awkward. All right. I mean, one weird thing, I guess, is... I guess my machine, and this is pretty common, I haven't set up really to be a graphical workstation. I always use it from the console. So I actually don't really have much of a window manager here. I can't even like... Oh, no, I can do a little bit. I don't know what the hell window manager is even using, but often you'll find like there is no window manager or whatever running. But you know, a bit of Googling will show you how to have to install whatever... KDA your stuff. Okay. Since we're on the installation topic, could I ask a question? So I think I kind of brought it up a little bit, but I can't launch Fast AI. A machine that runs Fast AI. And PyTorch. A PyTorch one would work. So what suggestions would you have about... So that means that your prerun.sh file has got a problem. So maybe commented out from my PyTorch just started out. Yeah, open up your PyTorch machine, moosh prerun.sh to prerun.back or something. Or just open it and see, you're like, it might be obvious what's wrong with it. Yeah, I couldn't see anything. Yeah. Yeah, I'll try to... What is that? It's not working. What's like, what's not working? It says error when I try to start it up. It just says error. And I tried to reach out to the paper space. Support a couple of times. Maybe it's a two abstract questions. The new response. Yeah. I'll try that. Thank you. Oh, people are putting stuff in the text chat. Please try to say things, variable chat, if you can, because it's way nicer for me. And I don't have to check not for Windows. I know it's not possible for everybody. But... Okay. So, sorry, Jeremy. There is a way to SSH into a gradient machine, but you have to trigger the virtual machine to be built from command line. So you have to initiate the job. And there's a paper space type of GitHub repo. And is there any reason to do that? Like, that sounds complicated. Like, would you just run a... It's way more effort than it's worth from what I'd say. Just run a call, just run a paper space core machine, if you want to, I guess. Yeah, exactly. So you can do it. It's just, why would you? I mean, so for paper space, the issue around the notebook closing, I would like start running something, close the notebook, and then reopen it, just to see what happens. You know. And... You know, let's try it here, right? So... Now, what was that thing we learned the other day? It was a shift T. And go to the other one. Oh, that was my one. Okay, I gotta learn how to... Hey, Jeremy. Yeah. Yeah. Can you... Using iterm too, because you can do Tmux minus CC, and you'll get native windows in Tmux instead of the little sort of terminal ones. Sounds interesting. Let me try that. Yeah, I'm addicted to the vats also. Minus capital capital... Minus capital CC. Unknown option C, preserved before the A. Yeah, so it'll be Tmux minus capital capital. Yeah, here you go. Oh. Okay. And what are the benefits of this approach? They're native windows. You can click and drag them and move them around, pop them out. Yeah, all that stuff. Same thing. How many you can click and drag Tmux windows as well? See. Okay, this is all the same as... Like, you've got to have mouse mode on for them to work. So like the shortcuts... You use like command shift D will split pains. You don't have to go into, I think, is it colon or something and command something? It's just like less than me. No, you just use control B. Maybe it's exactly the same. Yeah. I mean, you have the same... No, control B doesn't work anymore. So what about Tmux shortcuts? I'm not going to work anymore. How do I do... Yeah, I think they're different. They're different. Escape, I think. If you go back to the original window that launched it, it'll have a... Okay. Okay. Yeah, I'm not convinced it's going to help my workflow, but I think, yeah, for people who are more familiar with Tmux shortcuts, that could be cool. Thanks for the tip. It's going on down here. It's a bit good. The... The trick to get mouse support working, so for example, my scroll wheel, as you can see, works nicely in this normal Tmux window, is to have a.tmux.conf file that contains set option minus g mouse on. And then you can also increase your history limit. And yeah, that's how come I can scroll. I think the thing like, you know, or our thing I like about Tmux is it's very integrated with my kind of the normal way of doing things in in Unix, you know. So for example, if I want to search through my previous session, I could just hit question mark to search up, and I could search for make file. For example, and I hit N just like I would in VM. Hit slash to look forwards. You know, it's like my terminal works the same way as VM or whatever, which I, yeah, which I really like. And I think, yeah, that way I don't have to know like, oh, the items that a shortcut sends some other set of shortcuts. It's just this kind of like general, unique, see way of doing things, I guess. And of course, they'll also all work on the purpose based terminal as well. Yeah, so let's try this. So if we start running this. Yes. Okay, close that. Leave it for a few seconds. And you can see here it says in my console, starting buffering. So it's remembering things that were sent to me. So if I click now back here, there we go. It's, let's see. Hmm. That didn't seem to work. You know, that's interesting. Okay, so let's try something different. So I don't think you can just close it and reopen it. All right, let's try something else. What if we fake a network disconnection by closing SSH? Okay, so now, all right, connections failed. So I'll leave that window open. And then we reconnect. And Oh, okay, so that worked. So there's some of our answer. But yeah, I think there's something though, if you leave it long enough, it says I've stopped listening for events because there's been too many until see there's some configuration option you can change to make it bigger. Should probably be a useful thing to know about. Let me just go and turn this alarm off. Yeah. Sorry for that. I I daughter likes to be permanently entertained. So any gaps in her home schooling schedule. She wants to be amused. She doesn't like the fact that I'm doing this and Rachel's a crossfit. Okay, so we had a look the other day at Progressive Resizing. And so this is where I got to. I think like Progressive Resizing, one interesting thing you can do is like you can go crazy, like you can go extra lunch. And you know, we start out with some teeny tiny images and train for a while. And then combine that with with gradient accumulation to then go up to big images, but don't have to train so long. So this I think this is a good trick for probably particularly for code competitions on Kaggle where you've got serious resource constraints, you know, or just wanting to do more with less time. So I think on Kaggle, you would have needed accumulation level of four rather than two to make this fit because they've got 16 gig cards. We also got a 24 gig card. So then something else that then we started talking about was weighted models. That's weird. What happened to my weighted model? Did I move it to course 22? Well, that's fine. So the question I think we had just today was about unbalanced data sets and would it be a good idea to balance our data set. So let's start with a nice small model. If you use as a base case, something we've done before. So let's use this one. So actually there's no point copying progressive, I guess. Let's copy small models. Okay. Rename and so this is going to be for weighted. I might as well do the resizing. I don't know if I needed it on my machine, but since we'll be putting it on Kaggle, I might as well. Okay, so that's going to be our base case. So for weighting, we can df.label.value counts. So there's our level of unbalancedness. So it's not too bad. There's a lot of normals, a lot of blasts, not many of these bacterial thingies. Nick, I don't know if you're around. I mean, I can see you are around. I don't know if you're able to talk, but if you are, you might be able to tell us about what you found, because I know you've been looking at these, which of these are hard to kind of visually see the difference between? Yeah, yeah, for sure. I'm sorry, I dropped out earlier because we had a power cut here, but I'm back now. So are you intentionally video lists or is that? I am not intentionally video lists, but that's the break at the moment. Sorry about that. But yeah, like one thing that I did, just to, I guess get a better handle on the dataset was going through them and having a different type. So I found it really hard to pick even what the difference was between a normal image and say like downy mildew or whatever. It could be quite hard to pick out. And so one thing I thought it would be fun to do was to almost like segment or mask the images, playing with the color channels to see if they would come out a bit better. And then when I did that, I was able to take kind of, I guess, the yellow, dead bits or disease parts, and I could see them better when they were like in bright red. And the thing is that so many of these, like when I found like when I've trained them, I find that there is a handful of images, really like 20 to 25 images that are very difficult to classify. And it tends to be these actually from these imbalanced classes, where it tends to categorize them as blast when it's not. And I think. These are bacterial ones. Yeah, in fact, let me just pull up in one of my own notebooks. You want to maybe share your screen? Yeah, let me see if I like. Where do you look at this? Are you able to see? But it helped to make these bigger. Are you able to see the disease in these? Because I don't know what I'm looking for. How do we make this bigger? Probably there's like a figure size in that plot, there is that map plot lib. Is it like a fix size? Big size? Yes. Big size equals, I don't know, which way around is it? That way around. 9, 15. We can't hear you, by the way, Nick, I don't know if you lost you. I also tried to look into the image. Do you think the confusion matrix and the most lost to port the L, but it's just too hard. It's beyond my domain. I was planning to do that today, actually. So that's, yeah. I don't know what happened to Nick. Maybe he's having some internet problems again. I wonder if it's just like red spots or something. So, yeah. I mean, it's interesting that Nick said he found these ones difficult. So, yeah, there's basically two reasons to wait different rows differently. One is that some of them are harder and that you want them to be shown more often to give the computer more of a chance to learn them. And the other is some are less common and same thing. So, one possible waiting for these would be to take their reciprocal. And so then normal is going to be shown less often if we wait all the normal ones by this amount and all the bacterial, panicle, blight ones, this amount, you're going to get more of these. So that's like one approach we could use. I feel like that might be overkill. So I'd be inclined to kind of like not do it quite that much. So like another approach would be to take the square root maybe, one over the square root, kind of like that. So then these are going to be shown about twice as often as these. So maybe like let's start with trying this as a set of waiting. So, Jeremy, if I could ask a question at this point. So the waiting and when you talk about waiting such that images are shown more or less often. Although in cases where it's very imbalanced, whether that could lead to some classes being overfitted to because the model learns about the images themselves. I came across in looking at classification. And whether there was a way to, I read about how to deal with imbalances and I've seen some recommendations to try to wait when calculating the losses rather than resampling the input. So I just wondered whether it was possible. I mean they're different, right? So in the end you want it to be able to recognize the features of the images you care about. And there's no substitute for like having them see the images enough times to recognize them. However, when it does that, it is then going to, because it sees the rare cases more often, it's going to think that those rare cases are more probable than they actually are. So you have to reverse that then when you make predictions. So that's something to be careful of. So I mean, I think it probably just helped to try to take a look at it to see what that looks like. So here's our weights, right? I would be inclined to probably, can we merge things directly? Let's take a look. So if I go df.merge, which is kind of like a way of doing a join in pandas. And the right hand side, yeah, the right hand side can be a series. Cool. So merge on weights. What does that look like? Nope. Why not? And then, okay. Okay. Left, I see. So left, okay. So on left, left on, left on equals label. And right, I think that's called the index. I'm not pandas expert. I don't know if anybody is. There we go. Okay. So that's added these weights here. Given the slightly weird name, but that's okay. Okay. So if we call that weighted df. And so then we could get, take out a little function and move them over here. And I think what we want to do is use data blocks at this point. Often a good idea. And we have a data blocks version. Certainly make one otherwise. Okay. Here's a data block. So let's get a data block. Got an image block and a category block. Get y is parent label. Okay. Item transforms is this. Item transforms is this. Jeremy, I think you're in the wrong book. You should be in weighted. Thank you. Thank you. Thank you. Oh, yes. I had these here, but thank you. Okay. Okay. Okay. And batch transforms. Now we should just use the same ones we had here to make it fair. Okay. Okay. So there's our data block. Oh, we actually use this resizing. So this approach is we're going to use the data block to even the numbers of what's being sampled so that we can more augmentations of the same images for the low representative samples or kind of. So it's nothing to do with the data block. We're going to use things called weighted data loaders and the weighted data loader is going to use these numbers here to as basically like probabilities of how likely it is to pick that row when it grabs a row in a batch. Yeah. I was going to add them all up and and and to each of these divided by the sum. So they'll add to one. The reason I needed data blocks is because the the weighted data loaders method is a method of data block. It's not something we get in the, you know, quick and dirty image data loaders thing. That doesn't have as much flexibility. So now that we've got a data block, we can type that data block dot. Oh, and we'll have to import it import fastai dot callback dot. What was it in again? I don't remember. Fastai weighted data loader. It's a data callback. Oh, okay. So that's it's a it's actually a method of data sets. So we can get a data sets object from a data block like so. And we pass in source. So that would be our list of image files. So we can files equals get image files. In our training set, we pass those in and there's our training set and there's our validation set. So they're data sets. So these are the things that remember we can index into and get a single xy pair. And so weighted data loaders is then something we can pass data sets to and give it weights and a batch size. Okay. And the weights are for the training set. Okay, we're going to have to be bit careful about this. So we should be to go dss dot weighted data loaders. And so the source code is equals weighted to dl, which is here. Okay. White's call and weights. All right. I'm not 100% sure how this is going to work, but let's try it. So our weighted data frame. So this is the weight for each row. Right. And then we've got our files. Yeah, we've got to be a bit careful here, right, because they're in different orders. So we actually need a way to get a list of weights where the two orders are going to match each other. Yeah, we could do it by key lookup. I'm actually thinking of something a little lazy, which is just to sort them both. Okay, so although this seems to only have a what's going on here. Doesn't have them all. Are they not contiguous? Yes. Sort values by image ID. Oh, they are contiguous. So where is image 1001? The sorting must be by folder first, though. Okay. Yes, of course. That's exactly what it is. Thank you. Okay. So we could use a key. That looks hopeful. It says here if the key is a string, use attribute getter. So I think I can just pass in the key name. Ah, that is magic. That is the magic of first call right there. There we go. So that's sorting by name. And we can do the same thing for this one. Like so. And so now this order by the same thing. So that's a good step. So the weights are basically wdf.labely. So that's a pandas series. Yes, to NumPy, we turn it into an array. So I'm just not quite sure whether this has to be just for the training set or is for both. We'll find out in a moment. If I run that, it doesn't like it. Oh, that's interesting. Ah, of course. So the batch transforms actually we didn't end up getting applied because we use.datasets, which doesn't apply batch transforms. So we would need to now apply them here. So that's quite confusing. So presumably, I don't see it here, but I would expect to be able to go batch transforms at this point. Oh, dl quarks. This is all quite awkward, isn't it? So data loader keyword arguments equals batch. So if we were creating a data loader, a weighted data loader, you know what would be a good idea would probably be to look at the data block data loader's source code to see how that does it. Data sets.dataloters. Here we go. After underscore batch is what it is. After underscore batch. Nope. Okay, that's not it. Ah, let's see. Okay, it's calling.dataloters passing in the keyword arguments and okay,.dataloters does not call it after batch. Pretty Kalch. prophet data loaders. It'sSnapout data So it's.datasets. Yeah, so, okay, so datasets.dataloders is this thing here. And that doesn't be called after underscore batch. So... And I think I know why. I think that's because when we looked the other day at data block. We noticed that it like ads. Oh, yes, yes, yes, the image block. It adds int to float tensor as a batch transform. So we wanted to add that as well. So it's getting PIO images. So the fact is getting PIO images means it's never being converted to a tensor. So data block, I don't think there's something that calls to tensor or something at some point. Oh, there is here. Item transforms. So why isn't that getting called? Because... So item transforms, I think, are also done at the data loaders stage. Item transforms. Let's see. Item transforms. Yes, that's also done. Okay. So basically, using datasets instead of data loaders is quite awkward. I think we need to fix this in fast AI because yes, it's not being done for us. But you know what we could do, actually, is what we could do is the same thing that data block does, which is just to use these self.item transforms and self.batch transforms. So if we have a look at our data block, oops, daisy. Okay, I think this is all going to become clear in a moment, hopefully. It's got these item transforms in it. And it's got these batch transforms in it. And so what we actually want to do when we create our data loaders is say that after batch is whatever the data block says the batch transforms are. And after item is whatever the data block says the item transforms are. Okay, that's ugly. So that's something I think we should try to make easier. So hopefully by the time people see this video, this will all be easier. So there's some data loaders. Okay. So my guess is that here is we've given the wrong number of weights. I'm guessing this needs to be weights just for the training set. So the way I would check this is I would type percent debug and that puts us into the Python debugger. And the Python debugger is a very, very cool thing. It's called PDB. And definitely want to know how to use it. H gives you the help. And W shows you where in the stack you are. So you can see this is the line of code I'm about to run. And so I can print out with P self.n. And I can print out with P self.weights. And you don't actually normally need to even say P it just assumes that so I can just say self.weight.shape. And so there's the problem. So it's expecting 8,326 weights, not 10,407 weights. And so that's because, and you know, to be fair, the documentation warned us about this. It's expecting weights just for the training set. Not for both training and validation sets. Okay, no problem. Could you pre determine you split by adding another column in the same dataset there to put the weights in? Yeah, I could do that. But actually, and somebody actually asked about this the other day. This is our training set. And items tells you the file names actually. So we just need to look at each of these up. In the data frame. So what we could do is we could say weights equals. And so we could go through each of those. So that's going to be all of our files. And then we need to look up the image ID. And you know, I think something you could possibly do here is. Set the index. To image ID. Right, which is this kind of pandas idea. And then. We say. Dot location of one. Jpeg. Oh, there it is. And for. Label why. There it is. So. If we copy that over to here. And replace that with O. Oh, oh, dot name. Look at that. Okay. So. Okay, so we don't want to sort values. We want to set index. I should probably take more use make more use of indices in pandas. I guess I still don't have a great sense in my head of quite how they work. So I tend to under use them. Okay, so weights should now be the right length. The training set. Okay, so now. So here. Cool. And then what I've been trying to do is to do a few more. And what I find encouraging here is that we've got a lot of materials. Ground spot. Yeah, you know, this seems like a good mix, right? So then. We should just be able to. Pass those to our learner. Fine tune for five. All right, sorry, that was a bit more awkward than I would have liked and definitely used a whole bunch of concepts which we haven't. Covered before. So don't worry if you're feeling lost about the implementation here. Basically, yeah, just about the sampling works. We've got weights and that's creating. How is that actually sampled from the training set? Is it do we have a X number of rows or number of images that we're trying to create a sample. Yeah, so what happens is it creates it creates batches. So each batch will have 64 things in. And so it's going to grab at random 64 images. And so we're going to get a weighted random sample where each row is weighted by this. This weight. And so an epochs not exactly an epoch anymore. In that it won't necessarily see every image once an epochs an epochs just equal to the total number of rows in the data set is how many rows I've seen. A lot of the less common ones multiple times. And so there's a definite danger of overfitting. The weighted sampling is not done for the validation set. So we should be able to compare these. Let's take a look. So 5.6. Versus 4.6. Now, you know, this is expected. But where this might be interesting would be like. Do all of our training. And then maybe at the very end. Do a few epochs with weighted training. You know, at the point that it's already really good just to show it a few more examples of the. Mass common ones. Or just train it for longer with more data augmentation. But yeah, I mean, you know, you would expect the error rate at this point to be worse, I think, because. The most common. Types, which it's. Particularly what to care about because they're the ones that's going to have mainly in the training set. It hasn't seen very much. So the overall error has gone down. But yeah, I think you like it might be there may well be ways to. To use this. Jerry. Yeah, possibly you could quickly explain where the deficiency was in this. Random weighted API how you would prefer that to look like you said you. Oh, yeah, sure. Fix it up later, but I mean, I think I think the way this ought to look would be that I can say. DLS equals D block. Weighted data loader. Like that. In fact, we could fix it up now. Reusing the existing after batch and after items already and there. Yeah, we could we can. If you're interested. Yeah, I'd love to see how to. Okay. So, you know, the first thing I do before I change the first library is make sure I've got the latest version of it. By doing a get for. Because nobody likes conflicts. All right, it's up to date. So then I would go into the notebooks and. It was in the data callbacks. So call back data. And so here's weighted data loaders. Jeremy, is this a bit of a silly question, but is it a call back or is it just kind of like a transform within the actual data block? Should it be. If you send weights to a data block, then it just does it. Is it a call back? No, it's not a call back. So it's in a strange place. It's not a call back. What it is, it's a data loader actually. And a patch to data sets. So there's a. You know, something I like very much in the first core called patch, which is allows us to add. A method with this name to this class. And I want to add something to the data block class. Like so. And but yeah, I think that the the the doc string is correct. And I would then be inclined to just grab this. Here copy. And paste it. In here. Paste. Okay. And so this would be calling. Yeah, so we're calling the data blocks. So I guess we're going to do the two steps. And a manually, aren't we? So we're just going to go. Create the data sets. Data sets. And so that means we need to be passed in. And then we're going to do the items. And I've been trying to like grab all that. Okay. So this. This thing in data block. It's going to be the weights. It's going to need a batch size. Apparently there's something called verbose. I don't know what that means, but that's fine. The so the data sets is self.data sets passing in the source. And verbose equals verbose. And then we called DSS.data Lotus. And when we did that. Okay. So now we're going to be passing doing DSS.weighted data Lotus. Weighted data Lotus. And that. That's basically. Oops. And then we pass in the weights. Weighted data Lotus gets the weights. And then the batch size. And then the things we added. Any additional keyword arguments. And this will delegate down to. And then the loaders is where the key word arguments get passed to. Okay. So as far as I can tell these same tests. Should all work. We don't need these labels anymore. We've already got a data block. So previously we called data set and item transforms and weights manually. So that is our source. So we could get rid of all this. And we're now going to go data block.weighted data Lotus. And we got to pass in our source. Okay. And we got to pass in our weights. We're called weights. And we don't need that anymore. Okay. Why did I get zero? That's slightly surprising to me. I don't know zero. Yeah. That's fine. Yeah, it gets zero or one. Yeah, because it depends how it. Why is it slightly random? I'm not sure. Something slightly random. But anyway, it's working. So then. Okay. And again, for this one, we shouldn't need to do data sets dot. We should be able to go data block. We're not weighted data Lotus. And we should be able to pass in. Our items. And our weights. And we're going to go to data block. Okay. Let's see. And our source. And our weights. Okay. So let's see how it's different to what this one said. Data sets. Okay. This doesn't use a data block. Okay. Okay. So that's our test. There we go. So what I would then do. Is I would export it. And if. So that that I don't have to like rebuild or reinstall or anything like that. My fast AI library. That's because I have it installed using something called an editable install. So if you haven't seen that before, basically, or maybe you have any one way. When you go pip install minus E dot in a git repo. Basically, that creates like a sim link from your Python library. To this folder. And so fast AI when I import fast AI, it's actually going to import it from this folder. And so now back over here in my weighted thingy. If I do all this. Data block. We should find that there's now a D block dot. Data data loaders. Which I can pass source and weights. And my source is files. And my weights is. Okay, so that's interesting. I wait. Yes, we don't have data sets yet. So that's a very interesting point. So how do we know what our weights are? We don't because they haven't been split. So the. Could you not send them through as one of the blocks in the as a column get from and then use that because then it would be linked quite intimately with the actual row. Well, we don't need to. I think what we need to do is pass in weights. I think we should pass in all the weights. And then this thing here should then be responsible for grabbing the subset for the training set. And that would actually be much more convenient. Which is after all is what we want. So, yes, you should determine the weights based on the distribution across the classes rather than. So we should split the weights based on the splitter. In a training and test set. So then we don't need any of this. So then weights. Actually, we'll simply be. There's our weighted data frame. So basically what I would do here is this will actually will go back to saying this is sort values. And then our weights will be. WTF dot label y. That's actually our weights. As a number. So, silly question, could you not just see the function for weights to the standard data block. And if it doesn't get one, then it does nothing. Potentially, we could. It's. I kind of like this though, because like, yeah, I don't know. It's like. It's we're all one. As a default, then. Could use the one solution for. Yeah, yeah. I just, I don't, I find it's a little bit too coupled for me. I don't love it, but it's, it's, it would be doable. Nicely decoupled. This is so I think this is what I want it to look like. So. So I would look at how the splitters work. So the splitter. Okay, so the splits gets created here in data sets. Cool. And then. I wonder if data sets. Remember's what those splits are. I don't have tags here. Wait, what do you mean, no tags file? Okay, there we go. Data sets. So that's control right square bracket to remind you to jump to a symbol in VIM. I see. And that's actually mainly happening in this inheritance. The superclass is where. This is split stuff here. Yes, splits. I see though. There is a splits. So dss. splits. Oh, okay. Dss. splits. Yeah, so there's the indices of the training and test sets. And so that's the indices of the training set. So the actual weights we want to those ones. So over here. I can say training weights. So we'll change this to data set from training set. And so this will be the weights. At those indices. And that's what we'd use. No, dss. splits. Self is a data block. And it's actually the dss that has the splits. The data block has a function that knows how to split. But the split doesn't happen until you create it. That way you can get different random splits each time if you want them. Thank you for checking though. Okay, so I'll export that. And probably good to have auto load going, but we don't. Okay. Okay. Oh, no, that we did miss itself, but it's not the one you've bought off. This one here. Yeah. Okay. Oh, no. Oh, no. I guess actually if I just comment this out, then we can just run all above without worrying. Okay. Okay. Things are happening. So dls equals that. Okay. That looks pretty good. Okay. So I think we've created our feature. So then the next thing I would do is to be very, very weird if any tests broke, but I would go ahead and run the tests. I would then create an issue for my feature. And so I've got a bunch of tiny little aliases and functions. One's called enhancement, which creates an issue with the enhancement label. So I'll go enhancement. Add data block. We've got weighted data motors. That creates the issue as 3706. So if you were interested, you could take a look at that issue. Not the world's most interesting issue, but there it is. All right. Looks like the tests are basically, oh, no, we've got an issue. There we go. So we've got a test that's failed. Range in this must be introduced or slices. Yes. Right. So I'm glad we checked. So the problem here is that I sliced into my weights on the assumption that this is something I can slice into, which would only be true if it was a tensor or an array. But in this case, actually my weights are not either of those things. So what I do to fix that. There's a question here. Yeah. When you split, you only keep you back the index of the training and validation data set. And how can you know this is the weights because you haven't actually do the calculation and do the inverse or one square. The weights are being passed in as a parameter. And so we calculated the weights up here. Yep. And then we passed them in. Yeah. What's the incorrect type that's coming through in the test. It's not that it's an incorrect type. It's that. See how here I'm indexing into the weights using my splits. This here is a list or an array. You can't index into a Python list with a list. You can only do that with tensors or some play rate. I guess so. Yeah. I mean, what we actually want to do is check whether it's, it's an array type. Is there is a list or something that function. There is, but that's not quite. I think what the opposite, which is, is this the kind of thing that one could expect to be able to do NumPy style indexing on. And I believe the correct way to do that might be to look for this thing. So I would be inclined to say. And they may, they may well already be something in first day. I that knows how to check for this to be honest. Okay. So this, what's this thing? Oh, that's something that's coming to doubt. All right. So I guess I don't have anything which checks for that. So we'll just do it manually. So if weights has the done array attribute. Because I'm pretty sure that tensors have that as well. Yeah, it does. So if it has that attribute, then I think we're good to go. Otherwise, we can use a list comprehension. Oh, you know what we could do. Yeah. Okay. What we'll do is we'll just say if it doesn't have that. I don't know if this is too. To rude to change their. It waits. But I think this is fine. It's making a race. Not a non pi type array. It's going to bounce it from being converted to one anyway. Yeah. I mean, I don't, I mean, I don't see it downside. Passes our test. Passes all of our tests. Okay. So. And that was our only test that failed, which is now passing. So I would now say we've fixed issue 3706. I've got a fixes little function that does that 3706. Okay. And so now if we look at that issue, you'll see that it's been resolved using this commit. Yeah. Before, but what do you commit from the notebook? Do you sort of have it like reset with empty cells or do you run the cells? I can get them basically, however they are, but with unnecessary metadata removed. So there's a hook that automatically runs. This function, which is the thing that removes stuff like the execution count. Unnecessary notebook metadata stuff like that. So the idea is that the notebooks. Want to have all the outputs in place because they get turned into documentation. And we wouldn't want to run them all in continuous integration to create documentation because they can like involve like spending 10 hours training an NLP model, for example. So we don't remove the outputs for that reason. And also because I want people to be able to look at the notebooks in GitHub and see. You know, all the pictures and stuff. All right, I better stop there. Oh, that's interesting. Did I? Okay, I guess I don't have my hook installed. So I'm glad I ran that manually. So you can see exactly what it does, right? Empties out the execution counts and removes the metadata. So. Sorry for another question. I'm just trying to find it. Is that get hook available in the repo or do you do? Yeah, so it's if you go MB dev install. Get hooks, it installs the hook and specifically it's going to. Is that under MBS folder? No, this is part of Nb dev. Oh, okay. Right. So once that package is installed, it's a built in command. And so that then installs a filter here. I'll read more about it. Thanks. And it also. Installs a get hook. To trust the notebooks, which calls Nb dev trust MBs. Anyway, yeah, that's all in the Nb dev docs. And then what's going to happen now on the first day ice on the GitHub side. Is it's now busily running all the tests again. And one of the things that checks is to make sure that the notebooks are clean and that the exports been run and then it checks or the notebooks somewhat in parallel. All right, I better go. See you all. Thanks.
