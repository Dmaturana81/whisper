WEBVTT

00:00.000 --> 00:02.000
 Just continuing with this.

00:02.000 --> 00:04.000
 Okay, great. Yeah.

00:04.000 --> 00:08.000
 Any other new faces today?

00:08.000 --> 00:13.000
 Ali, have you been here before? I don't remember seeing you.

00:13.000 --> 00:17.000
 Maybe you've been quiet. I've been here. I don't think I've had the camera on.

00:17.000 --> 00:19.000
 Okay. Yeah.

00:19.000 --> 00:20.000
 Thanks me.

00:20.000 --> 00:26.000
 And Nick is back from his tour of tropical islands.

00:26.000 --> 00:27.000
 Hi, Nick.

00:27.000 --> 00:28.000
 Yes.

00:28.000 --> 00:31.000
 I'm not sure if I'm going to go to the

00:31.000 --> 00:32.000
 city.

00:32.000 --> 00:34.000
 But not so far away, though.

00:34.000 --> 00:36.000
 Still pretty close.

00:36.000 --> 00:39.000
 Yeah. Well, where do you're going to go to the island? Easy.

00:39.000 --> 00:41.000
 By default.

00:41.000 --> 00:43.000
 Hi, Marie. Nice to see you.

00:43.000 --> 00:45.000
 Where are you joining us from?

00:45.000 --> 00:46.000
 Hello.

00:46.000 --> 00:48.000
 Hi.

00:48.000 --> 00:50.000
 I'm joining from South.

00:50.000 --> 00:52.000
 This bit.

00:52.000 --> 00:53.000
 Uh huh.

00:53.000 --> 00:54.000
 Yeah.

00:54.000 --> 00:55.000
 I'm at the children's health.

00:55.000 --> 01:13.000
 I'm not sure if anybody got anything they wanted to talk about or ask about before we dive in because I've got some good news, which is I've made things much easier in the horrible direction we went last time.

01:13.000 --> 01:18.000
 All right. Sounds like I should dive in then.

01:18.000 --> 01:28.000
 I know there was like, as I rather expected and quite fair enough some, some concern on the forum about how.

01:28.000 --> 01:37.000
 Complicated and weird this all is, which is partly because we're kind of like jumping into stuff we'd normally do in part two and so we haven't quite got the.

01:37.000 --> 01:41.000
 Yeah, then all the necessary background here.

01:41.000 --> 01:45.000
 And so, yeah, don't worry if you're feeling a little.

01:45.000 --> 01:49.000
 At C.

01:49.000 --> 01:53.000
 It's a good way to like, I don't know, start to see like some stuff you could.

01:53.000 --> 01:56.000
 Look into after the course is finished.

01:56.000 --> 02:03.000
 All right. So let me just.

02:03.000 --> 02:04.000
 Jeremy. Yes.

02:04.000 --> 02:08.000
 Sorry. Just don't mentioning part two. Are you planning a part two this year?

02:08.000 --> 02:15.000
 Planning would be too strong a word, but as much as I ever plan anything thinking about.

02:15.000 --> 02:18.000
 Yes, I would absolutely like to do a part two this year.

02:18.000 --> 02:19.000
 Awesome.

02:19.000 --> 02:23.000
 And the fact that you're asking that question means that you are not up to date on our discord.

02:23.000 --> 02:29.000
 So you should definitely join our discord channel because we've actually been talking about doing a.

02:29.000 --> 02:37.000
 Conference or an conference to go with part two at the end of the year in Queensland.

02:37.000 --> 02:41.000
 And a lot of folks from.

02:41.000 --> 02:47.000
 Places that are not in Australia are saying they would be up for coming coming here for that.

02:47.000 --> 02:50.000
 You know, partly a kind of a social thing.

02:50.000 --> 02:58.000
 And also trying to do it all in a very covert safe way of kind of outdoor and masked and.

02:58.000 --> 03:01.000
 People tested ahead of time and stuff.

03:01.000 --> 03:04.000
 Yeah, so that's.

03:04.000 --> 03:14.000
 Yeah, so nothing's planned like we don't have dates or a syllabus or anything like that, but we absolutely hope to have something awesome.

03:14.000 --> 03:16.000
 Maybe towards the end of the year.

03:16.000 --> 03:24.000
 Where we can get to get to know each other a bit better and get to know.

03:24.000 --> 03:27.000
 Fast AI and learning a bit better.

03:27.000 --> 03:28.000
 Jeremy.

03:28.000 --> 03:30.000
 Yes. Can I ask you?

03:30.000 --> 03:38.000
 Are you going to continue this work for next week because I know that the class going to be soon next Tuesday.

03:38.000 --> 03:41.000
 Yeah, I think so.

03:41.000 --> 03:44.000
 Like the fact that I'm doing it this week is.

03:44.000 --> 03:47.000
 Interesting because yeah, like.

03:47.000 --> 03:49.000
 I.

03:49.000 --> 03:54.000
 It has been I've got less time to actually work on the course, but.

03:54.000 --> 04:02.000
 I also feel like the stuff we're doing, perhaps the stuff I can do use in the next lesson, depending on where we get to so.

04:02.000 --> 04:10.000
 Yeah, so I think we'll do it next week. We'll see how things go if I get really behind then maybe not, but then I certainly plan to like.

04:10.000 --> 04:14.000
 Continue the during them after the last class.

04:14.000 --> 04:16.000
 You know, until.

04:16.000 --> 04:19.000
 I don't know. We all know everything, I guess.

04:19.000 --> 04:24.000
 And then we'll stop at which point there'll be more things to know so yeah.

04:24.000 --> 04:25.000
 Okay.

04:25.000 --> 04:29.000
 We don't have to stop necessarily. You know, there's so much to learn.

04:29.000 --> 04:34.000
 The problem is that it's obviously a burden on your time, but it's.

04:34.000 --> 04:36.000
 I enjoy it.

04:36.000 --> 04:40.000
 I enjoy it. Like my issue is what about where we get to the point where there's nothing left to learn.

04:40.000 --> 04:42.000
 Radek, what do we do then? You know,

04:42.000 --> 04:45.000
 but is that such a point?

04:45.000 --> 04:49.000
 Oh, they must, you know, this.

04:49.000 --> 04:55.000
 But then we don't do it in a different language, right? We start doing it all in our or jubilee.

04:55.000 --> 04:58.000
 See, plus that would keep us busy.

04:58.000 --> 05:02.000
 I think this is my fifth year of doing fast AI courses.

05:02.000 --> 05:06.000
 I'm trying to complete the part one.

05:06.000 --> 05:09.000
 You see more static.

05:09.000 --> 05:15.000
 All right. Let me see. So.

05:15.000 --> 05:19.000
 Multi task.

05:19.000 --> 05:21.000
 All right.

05:21.000 --> 05:26.000
 I am just so happy about how this worked out, to be honest.

05:26.000 --> 05:31.000
 Although spoiler alert, it didn't turn out to help our score.

05:31.000 --> 05:34.000
 The score was about the same.

05:34.000 --> 05:39.000
 I was so happy about how the whole process turned out.

05:39.000 --> 05:46.000
 I kind of want to show you how I got there as well as where we ended up.

05:46.000 --> 05:57.000
 And yeah, as soon as I kind of like turned off zoom last time and I went for a walk and then as soon as I went to that, I was like, oh, no, of course I know how we should do this.

05:57.000 --> 06:08.000
 Really, so there's quite a few that, you know, we can make this much, much simpler. So let me explain what we're going to try to do.

06:08.000 --> 06:15.000
 We are going to try to.

06:15.000 --> 06:23.000
 Predict two things, the disease and the variety for each image.

06:23.000 --> 06:27.000
 And the first thing will be to create a.

06:27.000 --> 06:33.000
 Pair of data loaders that look like this to each image, they will have connected to things to them.

06:33.000 --> 06:36.000
 The disease.

06:36.000 --> 06:44.000
 And the type of race. So this is going to be step one. Right. So let me kind of show you how I got to that step.

06:44.000 --> 06:56.000
 So that step one that I talk was to first of all try to replicate what we've already had before. Right. So, Patty's ball.

06:56.000 --> 07:03.000
 But before I used image data loaders, which is like a, that's the highest level, least flexible function.

07:03.000 --> 07:13.000
 You know, we can do all the data processing in a single line of code, but only if we want to do something really standard and trying to predict two things is not standard enough for it.

07:13.000 --> 07:17.000
 Right. So we now need to go one layer down.

07:17.000 --> 07:21.000
 And.

07:21.000 --> 07:23.000
 There's like a lot of really good tutorials on Docs.

07:23.000 --> 07:32.000
 Fast to AI. And because it's been ages since I've done any of this, I'd forgotten entirely how fast I work.

07:32.000 --> 07:37.000
 So I use them very heavily to remind myself of what's going on.

07:37.000 --> 07:45.000
 But for example, there is a data block tutorial. This pets tutorial is is great.

07:45.000 --> 07:54.000
 It like it goes through all the layers of like different ways of doing things with fast AI pre processing.

07:54.000 --> 08:03.000
 This Siamese tutorial is another really good one. So these are some of the things I looked at. And the other thing that I looked at was the actual API docs.

08:03.000 --> 08:11.000
 So if I click here and data block. This is actually probably what I found the most useful in the end.

08:11.000 --> 08:24.000
 There's lots of great examples in the documentation. So yeah, I, you know, as a kind of like, you know, how it is you come back to something a couple of years after you built it and you're now kind of the customer of your documentation.

08:24.000 --> 08:33.000
 And so my experience as a customer of my documentation was I was really delighted by it. So I can definitely suggest checking all that out.

08:33.000 --> 08:44.000
 So, you know, what you can do is before we were using image data loaders from folder. So if we just do the double question mark trick, we can see the source code for it.

08:44.000 --> 08:49.000
 You know, and it's the normal size of fast AI things. It's very small.

08:49.000 --> 09:02.000
 And you can see that actually all the work's being done by data block. So data block is the like, still, you know, still high level API, but not not as high level. It's actually very flexible.

09:02.000 --> 09:12.000
 And so we're going to step step one that I did was to replicate exactly what we had before, but using data blocks.

09:12.000 --> 09:25.000
 And for this, there's actually, you know, so many good examples in the tutorials and in the book, you've seen them all before. We don't need to talk about it too much.

09:25.000 --> 09:32.000
 You know, we can basically say, okay, for the data block, the input will be an image. The output will be a category.

09:32.000 --> 09:35.000
 This is just to do disease prediction.

09:35.000 --> 09:49.000
 The labeling function will be the parent folder.

09:49.000 --> 10:05.000
 There, legal, do a random split, the item and batch transforms, we can copy and paste from what we had before.

10:05.000 --> 10:18.000
 And that creates a data block. So data loaders is then a data block dot data loaders, and you then have to pass in a source. So the source is basically at a.

10:18.000 --> 10:22.000
 Anything that you can.

10:22.000 --> 10:33.000
 Ederate through or index into to grab the things that will be passed to these to these blocks and this function.

10:33.000 --> 10:41.000
 So for this, it's going to be a path.

10:41.000 --> 10:48.000
 And then we also need to get items.

10:48.000 --> 10:53.000
 And so the, well, when we get a path, we're going to pass that path into the.

10:53.000 --> 11:02.000
 Get image files function because that's the thing that returns a list of all of the images in a path.

11:02.000 --> 11:07.000
 And let's see if that works.

11:07.000 --> 11:14.000
 How do you know that in the, okay, so the block, you have an image block category block.

11:14.000 --> 11:27.000
 How do you know that, like, how do you, how do you know that the get image files is going to be able to feed both those blocks.

11:27.000 --> 11:41.000
 So I guess the short answer would be, you know, to read the documentation about those blocks to see what they take and what they do.

11:41.000 --> 11:52.000
 Or any of the tutorials that use them, as you can see, they used all over the place, right? So start with this tutorial or this tutorial or this tutorial.

11:52.000 --> 12:00.000
 So any of those would show you what it does.

12:00.000 --> 12:11.000
 Yeah, the actual, let's say this, this is not good documentation. I'd really never bother to look at this because it's basically all of those.

12:11.000 --> 12:23.000
 We should fix that. I guess because there's so many tutorials. I mean, as you can see, like, I guess the reason I never really wrote jocks right is it's literally a single line of code.

12:23.000 --> 12:38.000
 So that's like, yeah, so maybe look at the code is actually interesting in this case. So an image block is something which calls.

12:38.000 --> 12:42.000
 Class.create where a class is.

12:42.000 --> 12:53.000
 image that's going to call pil image.create. So to find out what's actually going to be called by it, you can go.

12:53.000 --> 12:58.000
 Pil image.create.

12:58.000 --> 13:05.000
 And you can see it's going to get passed to file name, which can be a path or a string or various other things.

13:05.000 --> 13:16.000
 So get image files, then obviously you can either run it to see what it comes out with or let's do that so we could just run get image files.

13:16.000 --> 13:21.000
 Passing in the thing it's going to be given, which is the path.

13:21.000 --> 13:28.000
 And so as you can see, it's a bunch of paths. And so we could pass one of those.

13:28.000 --> 13:34.000
 I'll be that and it's going to be passed into this function.

13:34.000 --> 13:41.000
 So we've now just replicated exactly what's happening in the code.

13:41.000 --> 13:47.000
 Yeah, but for this I generally just look at the tutorials which tell you what to do.

13:47.000 --> 13:53.000
 Could you have two different get items that feed different blocks.

13:53.000 --> 13:58.000
 We're going to come to that. Okay. Okay. Park Park that.

13:58.000 --> 14:02.000
 So.

14:02.000 --> 14:08.000
 Yeah, so also a bunch of transform like it gets transformed later after reading.

14:08.000 --> 14:12.000
 Right. Yeah, we got the batch transform. Yeah.

14:12.000 --> 14:15.000
 But in the in the block.

14:15.000 --> 14:21.000
 Because right now we have a image or something and it needs to become a sensor. Right.

14:21.000 --> 14:22.000
 Yeah, that's right.

14:22.000 --> 14:26.000
 It gets changed from an answer to a float tensor later on.

14:26.000 --> 14:27.000
 That's right.

14:27.000 --> 14:28.000
 Yeah.

14:28.000 --> 14:33.000
 That's a, yeah, that's a fairly subtle thing, but that's right.

14:33.000 --> 14:37.000
 The.

14:37.000 --> 14:41.000
 We stick that in something image equals.

14:41.000 --> 14:47.000
 And we look at like NP dot array image.

14:47.000 --> 14:54.000
 It's actually stored as bytes or you would hate as they call it in PyTorch.

14:54.000 --> 14:58.000
 So, yes, the.

14:58.000 --> 15:02.000
 This is going to add a batch transform that's going to turn that into a float tensor,

15:02.000 --> 15:04.000
 which we can see.

15:04.000 --> 15:09.000
 That's going to look like we could run it here. I expect.

15:09.000 --> 15:16.000
 To float tensor.

15:16.000 --> 15:24.000
 The transformation that we're applying is 224, which is like a square image. Correct.

15:24.000 --> 15:26.000
 A 224 by 224.

15:26.000 --> 15:27.000
 This one here.

15:27.000 --> 15:28.000
 Yes.

15:28.000 --> 15:35.000
 Yeah. So this is doing data augmentation of lots of different kinds. So.

15:35.000 --> 15:39.000
 Let's.

15:39.000 --> 15:42.000
 Copy.

15:42.000 --> 15:47.000
 Paste.

15:47.000 --> 15:55.000
 And if we show the data augmentation, looking at the docs is particularly important because you can see examples of the.

15:55.000 --> 16:03.000
 Or notations of does, so it tells you a list of all the augmentations and how you can change them and here's some examples of what they look like.

16:03.000 --> 16:08.000
 And augmentations would happen after the into float tensor.

16:08.000 --> 16:12.000
 Yes, that's.

16:12.000 --> 16:17.000
 Some data augmentation that operate on the entire batch and some operation.

16:17.000 --> 16:24.000
 Yeah, that's right. So the ones in batch transforms operate on a whole batch and the ones in item transforms operate on a single item.

16:24.000 --> 16:27.000
 And so batch transforms.

16:27.000 --> 16:39.000
 And so they operate because they operate on a batch before you get there, everything has to be the same shape. So it can be turned into a batch. So this resize resizes everything to the same shape.

16:39.000 --> 16:44.000
 And then this does these various different types of data augmentation.

16:44.000 --> 16:54.000
 And one of the key pieces of data augmentation it does is to randomly zoom into a subset of the image as you can see.

16:54.000 --> 17:00.000
 And these various examples here.

17:00.000 --> 17:03.000
 And the data looking guy.

17:03.000 --> 17:09.000
 Can you also use it with data frames where you would be reading your images from a different.

17:09.000 --> 17:12.000
 We're going to do that. We're going to do that in a moment. Yes.

17:12.000 --> 17:20.000
 So yeah, I'm kind of like skipping over quite a bit of this because.

17:20.000 --> 17:31.000
 Super well covered in the tutorials so I don't want to like say stuff that you can very easily read rest of stuff and better show you isn't as well covered in the tutorials and it's kind of new.

17:31.000 --> 17:36.000
 But yeah, feel free to keep asking questions about anything you see.

17:36.000 --> 17:46.000
 So basically, yeah, so all we've done is we've just this is just the same thing that we have in lesson one.

17:46.000 --> 17:54.000
 I just and it's doing exactly the same thing as my image data load is not from folder but just 10 and 10.

17:54.000 --> 18:08.000
 And so that this is what I did just to show you through my process with step one was to get this working and then I passed that into a learner and I.

18:08.000 --> 18:10.000
 So let's go copy.

18:10.000 --> 18:12.000
 And.

18:12.000 --> 18:15.000
 And I want this to order run as fast as possible.

18:15.000 --> 18:24.000
 So I would use the fastest.

18:24.000 --> 18:34.000
 Do you when you make this data loader thing do you try to make sure that the shape that it's outputting is what you need for your model or that's later.

18:34.000 --> 18:41.000
 Well, I generally use models have all which don't care what size they get.

18:41.000 --> 18:45.000
 So yeah, that's one of my that's one of my tricks.

18:45.000 --> 18:49.000
 So resident 18 is happy with any size.

18:49.000 --> 18:52.000
 So actually for my testing, I'm going to bring this back down to 128.

18:52.000 --> 18:54.000
 So it's super fast.

18:54.000 --> 19:01.000
 And so I just want to get the maximum iteration speed here.

19:01.000 --> 19:05.000
 And so now I can call learn dot.

19:05.000 --> 19:11.000
 One cycle.

19:11.000 --> 19:18.000
 And let's do one epoch.

19:18.000 --> 19:22.000
 Okay, so this is going to run in under 20 seconds, which is kind of what you want.

19:22.000 --> 19:29.000
 Right. You want something that you can test in under about 20 seconds so that way you can just quickly try things and make sure that end to end.

19:29.000 --> 19:30.000
 It's working.

19:30.000 --> 19:39.000
 So the error rate is down to 30%. So that's, that's a good sign.

19:39.000 --> 19:43.000
 I guess one correlated question is, okay, I understand the input size.

19:43.000 --> 19:49.000
 But what about the output size of your data block like, you know that this is what you need for that model.

19:49.000 --> 19:53.000
 You know, let's say the model doesn't care the model's happy with any size.

19:53.000 --> 19:56.000
 I mean, the targets, or whatever.

19:56.000 --> 19:58.000
 You hear about the labels.

19:58.000 --> 20:01.000
 I mean, labels don't have sizes. The labels are strings.

20:01.000 --> 20:05.000
 Or just to this the shape of that like, hey, like is it.

20:05.000 --> 20:10.000
 You know, because maybe different models are kind of kind of predict different types of stuff.

20:10.000 --> 20:13.000
 Potentially, I don't know.

20:13.000 --> 20:17.000
 Like, some might have shape of the.

20:17.000 --> 20:32.000
 I suspect the thing you're kind of asking is the thing that we're going to be covering in a moment. So maybe put that on hold and then tell me if it makes sense. Okay.

20:32.000 --> 20:36.000
 I have a question.

20:36.000 --> 20:39.000
 On the data block.

20:39.000 --> 20:49.000
 And you randomly select the amount of records or the amount of the batch size that you're going to process.

20:49.000 --> 20:56.000
 I don't randomly pick the batch size. No, the batch size is actually selected in the data letters call.

20:56.000 --> 20:59.000
 And it's 64 64.

20:59.000 --> 21:09.000
 So, what is the guarantee that that every single one of the images in this particular case will be selected or there's no way to know.

21:09.000 --> 21:12.000
 Is there any way to know that every single one will be.

21:12.000 --> 21:13.000
 Yes.

21:13.000 --> 21:22.000
 I mean, well, I'll be there. Yes, except that we're randomly selecting 20% of the validation set.

21:22.000 --> 21:32.000
 But every single, every single one will go through the learner of the of the 80% that are in there. Everyone will go through our learner because we randomly shuffle them.

21:32.000 --> 21:35.000
 And then we iterate through the whole lot.

21:35.000 --> 21:37.000
 In a single epoch.

21:37.000 --> 21:44.000
 The model is guaranteed to see every example that this train just wants.

21:44.000 --> 21:46.000
 Yeah.

21:46.000 --> 21:57.000
 And that's what this one means. That's what one epoch means is look at everything once. And so if we put to there or look at everything twice, but each time it randomly shuffles it so it doesn't in a different random order.

21:57.000 --> 22:03.000
 I'll have a quick question. What I guess this is by torch data loader stuff.

22:03.000 --> 22:06.000
 But what actually happens for the last batch?

22:06.000 --> 22:15.000
 The last batch, it depends. And this is actually not the high torch data loader. It's actually fast day is data loader. So we have our own data loader.

22:15.000 --> 22:19.000
 Although in the next version, we're likely to replace it with the first day one.

22:19.000 --> 22:25.000
 So it depends what drop last is if drop last is true, then it deletes the last batch.

22:25.000 --> 22:31.000
 And if it's false, that includes the last batch. And the reason that's interesting is that the last batch may not be.

22:31.000 --> 22:35.000
 Of size 64. Yeah.

22:35.000 --> 22:39.000
 For the validation set, it always keeps the last batch.

22:39.000 --> 22:53.000
 And it's super important to shuffle the transit the first day I does it for you. But if you will, you know, mess around with the data loaders or do something yourself. If you don't suffer the transit, you might get very poor training performance.

22:53.000 --> 22:54.000
 Yeah.

22:54.000 --> 22:58.000
 When we used to use care us I used to mess all this stuff up all the time.

22:58.000 --> 23:01.000
 Yeah, trying to get all those details right. It's really annoying.

23:01.000 --> 23:06.000
 Just to make sure on something you said, you said in next iteration, you're going to replace it with the pie torch data lures.

23:06.000 --> 23:07.000
 Yeah, probably.

23:07.000 --> 23:08.000
 Yeah.

23:08.000 --> 23:11.000
 You said fast. I've said I've confused.

23:11.000 --> 23:12.000
 Oh, did I.

23:12.000 --> 23:14.000
 That is confusing.

23:14.000 --> 23:16.000
 Thanks.

23:16.000 --> 23:24.000
 Okay. So that was my step one is to just get it working exactly like before. And then I ran, then I ran it with.

23:24.000 --> 23:30.000
 In the background on the same architecture for the same epochs to make sure I got about the same error rate and I did.

23:30.000 --> 23:34.000
 So then I was happy that, okay, I'm matching what we had before.

23:34.000 --> 23:44.000
 So then step two was to try to make it so that the data block spits out three things, which would be one image and two categories.

23:44.000 --> 23:50.000
 The category of disease and the category of rice type.

23:50.000 --> 23:57.000
 So to get it to spit out an image and two categories, hopefully you wouldn't be surprised to hear that we just.

23:57.000 --> 23:58.000
 Do that.

23:58.000 --> 24:01.000
 We say we want three blocks an image and two categories.

24:01.000 --> 24:12.000
 Now, this variety, we did some way of getting that given an image ID.

24:12.000 --> 24:25.000
 And actually the way I did it was a bit ugly. And since then I thought of a better way of doing it, which is what I think we should do is we should create a dict that maps from image ID to variety.

24:25.000 --> 24:28.000
 And then our function will just be to look that up.

24:28.000 --> 24:35.000
 Right. So let's call this image to variety.

24:35.000 --> 24:40.000
 Equals. Okay, and it's going to be a dict, a dict comprehension.

24:40.000 --> 24:48.000
 So we're going to loop through.

24:48.000 --> 24:52.000
 The rows in.

24:52.000 --> 24:58.000
 D F dot.

24:58.000 --> 25:01.000
 Data items.

25:01.000 --> 25:05.000
 Now I always forget what these differences are.

25:05.000 --> 25:08.000
 Column name, comma series pair.

25:08.000 --> 25:11.000
 Returning a tuple with the column name.

25:11.000 --> 25:13.000
 Okay, that's not what I want.

25:13.000 --> 25:15.000
 Okay, get a rose.

25:15.000 --> 25:19.000
 Yeah, get a rose.

25:19.000 --> 25:21.000
 Index comma series.

25:21.000 --> 25:23.000
 Okay, cool.

25:23.000 --> 25:28.000
 I think like this, it a tuples is the fastest one.

25:28.000 --> 25:30.000
 But you know, this is not very big.

25:30.000 --> 25:33.000
 So let's keep it simple.

25:33.000 --> 25:38.000
 Okay, so this is going to iterate over rows and return.

25:38.000 --> 25:48.000
 Index class series. Okay, so we don't really care about the index.

25:48.000 --> 25:54.000
 And another thing we could do is make the image ID the index and then you could actually jump straight into it.

25:54.000 --> 25:57.000
 But I think I'd rather not use pandas features.

25:57.000 --> 25:59.000
 I'd rather use more pure Python.

25:59.000 --> 26:03.000
 Things because I think that'll make the explanation a little clearer.

26:03.000 --> 26:04.000
 So we're going to look through.

26:04.000 --> 26:09.000
 It's going to give us the index and the row.

26:09.000 --> 26:16.000
 And so what we want is the key will be the rose image ID.

26:16.000 --> 26:22.000
 And the value will be the rose variety.

26:22.000 --> 26:29.000
 Okay, that looks good.

26:29.000 --> 26:35.000
 So then there's a couple of ways we could turn this into a function.

26:35.000 --> 26:42.000
 And I'm just going to show you a little neat trick, which is when you go like the let's pick out something.

26:42.000 --> 26:45.000
 Let's see, we're going to grab this one.

26:45.000 --> 26:49.000
 When you go like this.

26:49.000 --> 27:01.000
 Behind the scenes that square bracket thing is actually calling a special magic method in Python called done to get item.

27:01.000 --> 27:03.000
 Which is a function.

27:03.000 --> 27:05.000
 This is the cool thing about Python.

27:05.000 --> 27:11.000
 It's so dynamic and flexible like all the syntax sugar is like behind the scenes just calling functions.

27:11.000 --> 27:14.000
 Basically, that's exactly the same thing.

27:14.000 --> 27:15.000
 Right.

27:15.000 --> 27:28.000
 And so that means that this function here image to variety done to get item is a function that converts a file name into a variety.

27:28.000 --> 27:29.000
 So here's the cool thing.

27:29.000 --> 27:35.000
 Forget why you can pass it an array.

27:35.000 --> 27:41.000
 And it's going to call each of those functions.

27:41.000 --> 27:49.000
 Which I think is rather nice.

27:49.000 --> 27:52.000
 So another thing I find helpful.

27:52.000 --> 27:53.000
 Okay, cool.

27:53.000 --> 27:56.000
 So when I call that, it complains.

27:56.000 --> 28:01.000
 And it says, Oh, get why it contains two functions, but it should contain one one for each target.

28:01.000 --> 28:04.000
 It thinks that there's only one target.

28:04.000 --> 28:05.000
 Why is that?

28:05.000 --> 28:10.000
 Well, if you think about it, we've said there's three blocks, but we haven't told it how many of those blocks.

28:10.000 --> 28:14.000
 So for the independent variable and how many of the dependent variable.

28:14.000 --> 28:16.000
 And so we have to tell it.

28:16.000 --> 28:19.000
 And the way we do that is to say the number of inputs equals.

28:19.000 --> 28:21.000
 And so it's one.

28:21.000 --> 28:22.000
 We have one input.

28:22.000 --> 28:25.000
 And then the rest will be outputs.

28:25.000 --> 28:29.000
 So when we do that, it's now happy.

28:29.000 --> 28:31.000
 Okay.

28:31.000 --> 28:36.000
 And personally, before I jump to data loaders, I first create data sets.

28:36.000 --> 28:38.000
 Just to make sure they work.

28:38.000 --> 28:40.000
 So you can create data sets.

28:40.000 --> 28:42.000
 So you can create data sets.

28:42.000 --> 28:44.000
 And so, all right.

28:44.000 --> 28:46.000
 So we've got an error.

28:46.000 --> 28:47.000
 Okay.

28:47.000 --> 28:49.000
 So here's the problem.

28:49.000 --> 28:52.000
 It tried to look up our function.

28:52.000 --> 28:54.000
 And then we have a problem.

28:54.000 --> 28:57.000
 And then we have a problem.

28:57.000 --> 28:59.000
 And then we have a problem.

28:59.000 --> 29:01.000
 And then we have a problem.

29:01.000 --> 29:03.000
 And then we have a problem.

29:03.000 --> 29:09.000
 It tried to look up our function.

29:09.000 --> 29:12.000
 And in fact, it's not indexed.

29:12.000 --> 29:14.000
 It's not passing in.

29:14.000 --> 29:17.000
 The string of the name.

29:17.000 --> 29:19.000
 It's actually passing in.

29:19.000 --> 29:21.000
 The path.

29:21.000 --> 29:23.000
 And so that's why we got a key error.

29:23.000 --> 29:29.000
 This path does not exist as a key in this dictionary, which is quite true.

29:29.000 --> 29:30.000
 Right?

29:30.000 --> 29:31.000
 It doesn't.

29:31.000 --> 29:36.000
 So what I think we should do is fix this up.

29:36.000 --> 29:41.000
 So that we've got train images, bacterial leaf streak.

29:41.000 --> 29:42.000
 Okay.

29:42.000 --> 29:45.000
 Get files.

29:45.000 --> 29:46.000
 Function.

29:46.000 --> 29:48.000
 The output of that is being passed to the get.

29:48.000 --> 29:50.000
 Or get items is being passed to get.

29:50.000 --> 29:51.000
 Right.

29:51.000 --> 29:53.000
 So get image files.

29:53.000 --> 29:54.000
 Yeah.

29:54.000 --> 29:58.000
 So we haven't kind of gone into the details of exactly what's going on behind the scenes.

29:58.000 --> 30:01.000
 So we're going to do that.

30:01.000 --> 30:02.000
 Okay.

30:02.000 --> 30:04.000
 Let's do that in a moment.

30:04.000 --> 30:05.000
 Okay.

30:05.000 --> 30:09.000
 I kind of like the way you're wanting to jump into the nitty gritty.

30:09.000 --> 30:10.000
 But it's a little bit.

30:10.000 --> 30:12.000
 I'm trying to do more top down.

30:12.000 --> 30:14.000
 Right. So I'm going to get to your bottom up.

30:14.000 --> 30:16.000
 We'll meet in the middle. Okay.

30:16.000 --> 30:17.000
 Okay.

30:17.000 --> 30:18.000
 Okay.

30:18.000 --> 30:19.000
 By the way, your video is not on.

30:19.000 --> 30:20.000
 That's fine.

30:20.000 --> 30:22.000
 I just don't know if it's intentional.

30:22.000 --> 30:24.000
 I always like to see people when they're.

30:24.000 --> 30:26.000
 You know, seeable.

30:26.000 --> 30:27.000
 Hello.

30:27.000 --> 30:29.000
 We're not going to use this trick after all.

30:29.000 --> 30:32.000
 We're going to create a function called.

30:32.000 --> 30:35.000
 Called get variety.

30:35.000 --> 30:40.000
 Actually, no, but yeah, let's create a function called get variety.

30:40.000 --> 30:43.000
 And so it's going to get past.

30:43.000 --> 30:45.000
 A path.

30:45.000 --> 30:47.000
 Okay.

30:47.000 --> 30:50.000
 And so we're going to return.

30:50.000 --> 30:54.000
 Image to variety.

30:54.000 --> 30:59.000
 And we're going to return image to variety.

30:59.000 --> 31:02.000
 With the name.

31:02.000 --> 31:04.000
 Of the file.

31:04.000 --> 31:05.000
 So the name of the file.

31:05.000 --> 31:07.000
 Is the string.

31:07.000 --> 31:09.000
 Wait.

31:09.000 --> 31:11.000
 We need image to variety.

31:11.000 --> 31:13.000
 The dunder thing.

31:13.000 --> 31:14.000
 Oh, yeah.

31:14.000 --> 31:15.000
 I'll just grab record.

31:15.000 --> 31:16.000
 Actually, yes.

31:16.000 --> 31:18.000
 Yes.

31:18.000 --> 31:20.000
 Okay.

31:20.000 --> 31:23.000
 Oh, and then we need to use that.

31:23.000 --> 31:25.000
 Okay.

31:25.000 --> 31:27.000
 Yeah.

31:27.000 --> 31:31.000
 Okay.

31:31.000 --> 31:32.000
 Okay.

31:32.000 --> 31:34.000
 So dss.

31:34.000 --> 31:37.000
 Um.

31:37.000 --> 31:43.000
 It contains a dot train data set.

31:43.000 --> 31:44.000
 Okay.

31:44.000 --> 31:47.000
 And it also contains a dot valid data set.

31:47.000 --> 31:49.000
 Okay.

31:49.000 --> 31:56.000
 And so we can look at the zero thing in the training data set, which is a single thing.

31:56.000 --> 31:57.000
 Right.

31:57.000 --> 31:58.000
 So we can have a look now.

31:58.000 --> 32:06.000
 There's image and y one and y two.

32:06.000 --> 32:09.000
 And so then we can look at the image, for example.

32:09.000 --> 32:10.000
 Okay.

32:10.000 --> 32:15.000
 So what's happened here is that get image files returned a list of paths.

32:15.000 --> 32:23.000
 The first one got passed to image block, which as we saw earlier got passed to pio image dot create.

32:23.000 --> 32:25.000
 And here it is.

32:25.000 --> 32:32.000
 Um, and that path name also got passed to a function called parent label.

32:32.000 --> 32:33.000
 In fact, let's do it.

32:33.000 --> 32:34.000
 Right.

32:34.000 --> 32:39.000
 So let's say file name equals get image files.

32:39.000 --> 32:43.000
 And then the thing that we passed in training path.

32:43.000 --> 32:45.000
 And it's just get the zero one.

32:45.000 --> 32:46.000
 Okay.

32:46.000 --> 32:48.000
 And so.

32:48.000 --> 32:49.000
 There it is.

32:49.000 --> 32:50.000
 Right.

32:50.000 --> 32:52.000
 So, um.

32:52.000 --> 32:55.000
 It ended up calling pio image dot create.

32:55.000 --> 32:59.000
 With that file name.

32:59.000 --> 33:00.000
 Okay.

33:00.000 --> 33:03.000
 It also called parent label with that file name.

33:03.000 --> 33:07.000
 Okay.

33:07.000 --> 33:14.000
 And it also called get variety with that file name.

33:14.000 --> 33:18.000
 Jeremy, can we look at get variety one more time?

33:18.000 --> 33:21.000
 I'm just curious how you build the path.

33:21.000 --> 33:23.000
 I didn't.

33:23.000 --> 33:24.000
 I removed the path.

33:24.000 --> 33:25.000
 I called dot.

33:25.000 --> 33:26.000
 Okay.

33:26.000 --> 33:27.000
 Okay.

33:27.000 --> 33:28.000
 Yeah.

33:28.000 --> 33:29.000
 I see.

33:29.000 --> 33:30.000
 Yeah.

33:30.000 --> 33:42.000
 Yeah. And my original version of this, I did it the other way round of like building back up the path and then realize that that was kind of stupid. So, um, yeah, it's unique. So that works.

33:42.000 --> 33:45.000
 One question.

33:45.000 --> 33:47.000
 Okay.

33:47.000 --> 33:52.000
 Okay. This could be to, you know, low level, but just let me know.

33:52.000 --> 33:56.000
 Can you have multiple get items? Is this the right place to ask that or that's.

33:56.000 --> 34:01.000
 Yeah, so it wouldn't make sense to have multiple get items, right? Like, right.

34:01.000 --> 34:05.000
 It returns a single thing, but it could be anything you like, right? It could be.

34:05.000 --> 34:08.000
 It could return a top hole or a list or an object or whatever.

34:08.000 --> 34:09.000
 Right.

34:09.000 --> 34:11.000
 And so, or a dict.

34:11.000 --> 34:14.000
 And then get why and get X.

34:14.000 --> 34:19.000
 Now, then the things responsible for pulling out the bit that you need to pass to your blocks.

34:19.000 --> 34:23.000
 Now, we don't, we don't need to get X because image blocks.

34:23.000 --> 34:26.000
 Just take parts directly.

34:26.000 --> 34:34.000
 So if I needed something a bit more like, I need it wanted to put more things and get image file, like have it admitted to pull.

34:34.000 --> 34:37.000
 Then would I have to like make my own image walk to ignore.

34:37.000 --> 34:42.000
 No, not your image block. You would write your own function, just like get image files.

34:42.000 --> 34:48.000
 That returns the list of all of the objects you want, whichever the information you need.

34:48.000 --> 34:49.000
 Okay.

34:49.000 --> 35:05.000
 And then like, it almost never happens. I don't think that's ever happened to me because like nearly like nearly always there's like a row of a database table or a path or something has all the information you need to like go out and get the stuff with your

35:05.000 --> 35:08.000
 get X's and get wise.

35:08.000 --> 35:20.000
 And that's like the central piece of information for each row. And based on this information, you can read in text can read an images. Yeah, but you know, specific to that one.

35:20.000 --> 35:22.000
 Actually, let me show you my hacky version.

35:22.000 --> 35:25.000
 This is the version that uses a data frame.

35:25.000 --> 35:26.000
 So this is.

35:26.000 --> 35:34.000
 So the version that uses data frame.

35:34.000 --> 35:38.000
 Yes. Is it, is it right to think.

35:38.000 --> 35:42.000
 Yeah, that's interesting.

35:42.000 --> 35:52.000
 Let me just do this and then we'll get a come to your question. Okay. So in this data blog, I started out with a data frame.

35:52.000 --> 36:00.000
 Like so. Right. And so by passing into data blocked up data load as I passed in the data frame.

36:00.000 --> 36:07.000
 It's going to get it's going to get each row. Right. And so then get why.

36:07.000 --> 36:19.000
 Becomes call read or one, which is just a function, which I mean, it let's look at it. It's doesn't do much.

36:19.000 --> 36:20.000
 It.

36:20.000 --> 36:30.000
 Let's see what it does. So it's got it's it's done as an object because you can do things like add in a prefix path and a suffix path and you can split it with a label delimiter and whatever.

36:30.000 --> 36:33.000
 But basically.

36:33.000 --> 36:43.000
 You know, all it's basically doing. Okay. And it like checks what kind of thing you're passing in.

36:43.000 --> 36:47.000
 But basically all it does is it calls.

36:47.000 --> 36:53.000
 Get at your to grab the column.

36:53.000 --> 36:57.000
 And we.

36:57.000 --> 37:02.000
 Or reader for on that, like reading data.

37:02.000 --> 37:03.000
 Sorry.

37:03.000 --> 37:07.000
 Is this call reader function specifically for data frames?

37:07.000 --> 37:19.000
 I mean, it can work with anything basically that that you're so what it's doing here is it's yeah, it's saying grab that column.

37:19.000 --> 37:24.000
 But it's really, you know, I've only really used it for data frames, but you could use it for anything.

37:24.000 --> 37:32.000
 But yeah, so basically here get why it's saying, okay, well, let's return the index one field and the index two field.

37:32.000 --> 37:36.000
 You know, and.

37:36.000 --> 37:40.000
 What's up with the eggs.

37:40.000 --> 37:46.000
 Yeah, so, so because now we're being passed. So you can't pass a row of a database table to P.

37:46.000 --> 37:49.000
 Oh, image dot create.

37:49.000 --> 37:53.000
 So get X is this function.

37:53.000 --> 38:03.000
 Which basically is going, oh, it's going to be in the training path slash disease name slash.

38:03.000 --> 38:07.000
 Image name.

38:07.000 --> 38:12.000
 And then there's a special case for the test set because the test set things are not stored.

38:12.000 --> 38:15.000
 In sub folders according to label because we don't know the label.

38:15.000 --> 38:18.000
 So it's just directly in the test path.

38:18.000 --> 38:21.000
 That's the, as I said, this was more hacky.

38:21.000 --> 38:22.000
 I don't.

38:22.000 --> 38:23.000
 This is a.

38:23.000 --> 38:25.000
 This really helps.

38:25.000 --> 38:29.000
 So like, I get X is kind of like get why you can have a list in there.

38:29.000 --> 38:40.000
 Yeah, you can have it. Yeah, it's totally flexible. And I mean, seriously, how more like this, like we have so many examples of all of these.

38:40.000 --> 38:45.000
 Patterns in the docs in the tutorials. So like this exact pattern.

38:45.000 --> 38:48.000
 Let's take a look at one right. Docs.

38:48.000 --> 38:52.000
 Last day.

38:52.000 --> 38:56.000
 So tutorials.

38:56.000 --> 39:00.000
 Do data block tutorial right here. Look, model label.

39:00.000 --> 39:03.000
 So here's one.

39:03.000 --> 39:05.000
 And yeah, you can see here.

39:05.000 --> 39:14.000
 This is even splitting based on columns in the database table. And here's the call reader using the prefix and here's a call reader using a label delimiter.

39:14.000 --> 39:18.000
 And here's the examples coming out. Yeah. So there's some.

39:18.000 --> 39:22.000
 Yeah, lots of examples. You can you can check out.

39:22.000 --> 39:27.000
 To see how to do all this.

39:27.000 --> 39:37.000
 Yeah, so I think I'm at a point now where I actually do want to go into the weeds. So Hamill, you're now after this totally free to ask any super weedy questions.

39:37.000 --> 39:45.000
 The most basic kind of data block is called the transform block.

39:45.000 --> 39:51.000
 And the transform block.

39:51.000 --> 39:55.000
 Basically.

39:55.000 --> 40:04.000
 It's going to store a bunch of things you pass in. It's going to store things called type transforms. It's going to store things called item transforms. It's going to store things called batch transforms.

40:04.000 --> 40:10.000
 And also it always adds one thing, which is to tensor because pytorch is tensors.

40:10.000 --> 40:15.000
 If you look at the image block.

40:15.000 --> 40:19.000
 We saw that that's defined as a transform block.

40:19.000 --> 40:24.000
 Where the type transforms is this and the batch transforms is this.

40:24.000 --> 40:34.000
 So now's a good time to talk about how this all works, what this does. So if I pass in here transform block.

40:34.000 --> 40:37.000
 And don't pass any transforms. It won't do anything.

40:37.000 --> 40:45.000
 So if I.

40:45.000 --> 40:50.000
 Let's get rid of like.

40:50.000 --> 40:57.000
 Pretty much everything.

40:57.000 --> 41:08.000
 So if I do that.

41:08.000 --> 41:09.000
 Okay.

41:09.000 --> 41:13.000
 Here is the world simplest data block.

41:13.000 --> 41:20.000
 Okay. So if we.

41:20.000 --> 41:25.000
 All that.

41:25.000 --> 41:32.000
 As you can see, all it does is it takes the output of get image file zero.

41:32.000 --> 41:38.000
 And turns it into a tuple containing one thing, which is the thing itself.

41:38.000 --> 41:43.000
 If we have two transform blocks.

41:43.000 --> 41:47.000
 It returns a tuple with two things in it.

41:47.000 --> 41:52.000
 So, and the reason it's returning tuples is because this is what we want.

41:52.000 --> 41:57.000
 When we train, we have batches, right, containing.

41:57.000 --> 42:02.000
 Inputs and outputs potentially multiple inputs and potentially multiple outputs.

42:02.000 --> 42:04.000
 Right. So that's why.

42:04.000 --> 42:07.000
 You know, indexing into this gives you back.

42:07.000 --> 42:09.000
 A tuple.

42:09.000 --> 42:10.000
 My question.

42:10.000 --> 42:11.000
 Yes.

42:11.000 --> 42:12.000
 The block.

42:12.000 --> 42:14.000
 The blocks can either be a list or a tuple.

42:14.000 --> 42:15.000
 I don't know.

42:15.000 --> 42:17.000
 Probably.

42:17.000 --> 42:18.000
 Yeah.

42:18.000 --> 42:19.000
 Okay.

42:19.000 --> 42:23.000
 There's no idea.

42:23.000 --> 42:26.000
 Okay.

42:26.000 --> 42:29.000
 Okay.

42:29.000 --> 42:33.000
 So then we can like.

42:33.000 --> 42:36.000
 Do stuff to.

42:36.000 --> 42:44.000
 The first thing in the tuple.

42:44.000 --> 42:49.000
 So, get X equals.

42:49.000 --> 42:52.000
 So, let's get a lambda.

42:52.000 --> 42:56.000
 Oh, oh, oh, oh.

42:56.000 --> 43:10.000
 Name.

43:10.000 --> 43:16.000
 Hey, what are you doing?

43:16.000 --> 43:23.000
 Oh.

43:23.000 --> 43:25.000
 Something to do with lambda, right?

43:25.000 --> 43:28.000
 Does name have to be call?

43:28.000 --> 43:37.000
 No.

43:37.000 --> 43:47.000
 Maybe it's notebook restart time.

43:47.000 --> 43:50.000
 Oh, that's.

43:50.000 --> 43:54.000
 Oh, I wonder if something happened to my.

43:54.000 --> 43:58.000
 GPU server.

43:58.000 --> 44:01.000
 I mean, something has happened to my GPU server.

44:01.000 --> 44:08.000
 Oh, it looks like it's back.

44:08.000 --> 44:09.000
 Oh, okay.

44:09.000 --> 44:15.000
 It just recognized it just appeared.

44:15.000 --> 44:19.000
 That's wild.

44:19.000 --> 44:24.000
 Okay.

44:24.000 --> 44:34.000
 I'm very.

44:34.000 --> 44:41.000
 I don't know what just happened.

44:41.000 --> 44:43.000
 It doesn't really matter.

44:43.000 --> 44:45.000
 What are you, what are you doing right now?

44:45.000 --> 44:46.000
 I'm just looking at the logs.

44:46.000 --> 44:53.000
 See if anything just happened.

44:53.000 --> 45:03.000
 Okay.

45:03.000 --> 45:08.000
 All right.

45:08.000 --> 45:09.000
 Okay.

45:09.000 --> 45:16.000
 So, you see what happened here is.

45:16.000 --> 45:24.000
 We, you know, got the first thing from image files, which was this and.

45:24.000 --> 45:26.000
 Get X got its name.

45:26.000 --> 45:31.000
 So we could also do.

45:31.000 --> 45:35.000
 Get why.

45:35.000 --> 45:37.000
 It equals land.

45:37.000 --> 45:40.000
 Parents say.

45:40.000 --> 45:41.000
 Okay.

45:41.000 --> 45:47.000
 So, you know,

45:47.000 --> 45:50.000
 it first went like.

45:50.000 --> 45:55.000
 First, the, the thing went to the transform block.

45:55.000 --> 45:57.000
 The items yet. So whatever.

45:57.000 --> 46:00.000
 Get items got went to transform blocks.

46:00.000 --> 46:03.000
 And then it went to get X and get why.

46:03.000 --> 46:05.000
 Well, transform block doesn't do anything.

46:05.000 --> 46:06.000
 Right.

46:06.000 --> 46:11.000
 So, yeah, so it's basically.

46:11.000 --> 46:14.000
 But the number of them you have is the number of like pipelines.

46:14.000 --> 46:16.000
 It's going to, it's going to create.

46:16.000 --> 46:19.000
 So if we created another one.

46:19.000 --> 46:23.000
 But generally, if you have like an image block, it would do something.

46:23.000 --> 46:25.000
 We're going to get to that. Yeah.

46:25.000 --> 46:28.000
 So here, look, we've never.

46:28.000 --> 46:32.000
 We're not quite there yet. Right. So let's get to that.

46:32.000 --> 46:36.000
 And it's not quite the mental model you've got, I think.

46:36.000 --> 46:38.000
 Now that I've got three transform blocks.

46:38.000 --> 46:41.000
 I only have things to.

46:41.000 --> 46:43.000
 Create two of them.

46:43.000 --> 46:45.000
 So it's, it's sad. Right.

46:45.000 --> 46:48.000
 And so we could.

46:48.000 --> 46:56.000
 Put them here.

46:56.000 --> 46:59.000
 For instance.

46:59.000 --> 47:04.000
 And that's one is the Y in the first two or the X.

47:04.000 --> 47:05.000
 Correct.

47:05.000 --> 47:08.000
 Unless we say number of inputs.

47:08.000 --> 47:10.000
 Equals one.

47:10.000 --> 47:11.000
 Right.

47:11.000 --> 47:14.000
 In which case now.

47:14.000 --> 47:17.000
 We get X is just going to have to return one thing.

47:17.000 --> 47:19.000
 It's going to be one function.

47:19.000 --> 47:22.000
 And get why will be two things.

47:22.000 --> 47:25.000
 Okay.

47:25.000 --> 47:35.000
 So.

47:35.000 --> 47:41.000
 You could.

47:41.000 --> 47:44.000
 You know, you could even put it here instead, right?

47:44.000 --> 47:52.000
 So you could say, oh, well, this is actually.

47:52.000 --> 47:57.000
 We could put it here.

47:57.000 --> 48:02.000
 Item transforms equals.

48:02.000 --> 48:07.000
 And so the stuff, the transform block is stuff that is applied.

48:07.000 --> 48:12.000
 But that transform.

48:12.000 --> 48:19.000
 Why is that not working?

48:19.000 --> 48:34.000
 It's like surprising to me.

48:34.000 --> 48:35.000
 Okay.

48:35.000 --> 48:38.000
 It's to be a type transform.

48:38.000 --> 48:39.000
 Okay. Type transform.

48:39.000 --> 48:42.000
 So it's now converted to.

48:42.000 --> 48:44.000
 The type it's meant to be.

48:44.000 --> 48:49.000
 So, so, Radik, you were asking about image block.

48:49.000 --> 48:52.000
 I'm just, you know, curious.

48:52.000 --> 48:54.000
 I want the pieces.

48:54.000 --> 48:57.000
 Let me show you.

48:57.000 --> 48:58.000
 Let me show you.

48:58.000 --> 49:01.000
 So let's do it manually.

49:01.000 --> 49:04.000
 So image block is just this. Okay.

49:04.000 --> 49:06.000
 So let's not use image block.

49:06.000 --> 49:07.000
 Let's instead.

49:07.000 --> 49:09.000
 Why didn't the item transform work?

49:09.000 --> 49:11.000
 Let's figure that out later.

49:11.000 --> 49:15.000
 Yeah. I'll just be figuring out what's going on here and then we'll debug it.

49:15.000 --> 49:21.000
 Okay. So now we've got three transform blocks, two of them which do nothing.

49:21.000 --> 49:25.000
 The first one of which is going to call something.create.

49:25.000 --> 49:31.000
 That was PIL image.create.

49:31.000 --> 49:39.000
 So transform blocks don't, if you look at the code of them, transform blocks.

49:39.000 --> 49:42.000
 Don't do anything at all.

49:42.000 --> 49:47.000
 Right. They actually, they only store things.

49:47.000 --> 49:51.000
 There's no, there's no done to call.

49:51.000 --> 49:54.000
 There's no forward. There's nothing.

49:54.000 --> 49:58.000
 Transform blocks don't do anything. They just store stuff.

49:58.000 --> 50:02.000
 The data block is a thing that then going to go through and say, okay,

50:02.000 --> 50:07.000
 for each thing, call its type transforms and then call to tensor and then call

50:07.000 --> 50:12.000
 its item transforms and then a data load of time, call its batch transforms.

50:12.000 --> 50:15.000
 So does that help answer your question?

50:15.000 --> 50:20.000
 Hammel, it's not that a transform block doesn't get called.

50:20.000 --> 50:25.000
 It just stores the list of things that will get called at each of these times.

50:25.000 --> 50:28.000
 The first thing that gets called is type transforms.

50:28.000 --> 50:33.000
 Wait, is that right?

50:33.000 --> 50:34.000
 You think?

50:34.000 --> 50:37.000
 That's not correct.

50:37.000 --> 50:40.000
 The first thing that gets called is get X and get Y.

50:40.000 --> 50:44.000
 And then the result of that is passed into type transforms.

50:44.000 --> 50:46.000
 And so get X and get Y.

50:46.000 --> 50:52.000
 So get X would be responsible for making sure that you have a path that you can pass to

50:52.000 --> 50:53.000
 PIL image.create.

50:53.000 --> 50:55.000
 That's the order.

50:55.000 --> 51:00.000
 So this whole path of what happens, you know, sequence that legend.

51:00.000 --> 51:02.000
 That listen data block, exactly.

51:02.000 --> 51:08.000
 Now the data block code is frankly hairy and it could do with some, you know,

51:08.000 --> 51:11.000
 simplifying and documenting and refactoring.

51:11.000 --> 51:13.000
 It's not long.

51:13.000 --> 51:19.000
 It's about 50 or 60 lines of code.

51:19.000 --> 51:21.000
 In fact, it's almost all here.

51:21.000 --> 51:25.000
 But basically,

51:25.000 --> 51:31.000
 when you call dot data sets, really all it's doing is it creates a data sets

51:31.000 --> 51:38.000
 object passing in all of the type transforms to it.

51:38.000 --> 51:40.000
 And the answer to your question,

51:40.000 --> 51:43.000
 Hammer, why didn't the item transforms get done is because item transforms

51:43.000 --> 51:47.000
 actually get done by the data load or not by the data sets.

51:47.000 --> 51:51.000
 So data sets only use the type transforms.

51:51.000 --> 51:56.000
 And basically the only reason there's like quite a bit of code in here is we try

51:56.000 --> 52:02.000
 to kind of make sure that if two different things have like the same type

52:02.000 --> 52:06.000
 transforms, we kind of merge them together in a sensible way.

52:06.000 --> 52:10.000
 So this is stuff to try to make sure this all just works.

52:10.000 --> 52:16.000
 The type transforms are separate from the items transforms because of some

52:16.000 --> 52:20.000
 optimization you can do with the type transforms.

52:20.000 --> 52:26.000
 Because the type transforms are happening earlier,

52:26.000 --> 52:31.000
 they're happening before data loaders time.

52:31.000 --> 52:37.000
 So data loaders are the things that are going to take tenses.

52:37.000 --> 52:38.000
 Right?

52:38.000 --> 52:45.000
 So, or at least things that can be converted into tenses.

52:45.000 --> 52:50.000
 So, yeah, so type transforms are the things that are going to create your

52:50.000 --> 52:51.000
 data sets for you.

52:51.000 --> 52:56.000
 And they're going to spit out things which need to be convertible into tenses.

52:56.000 --> 53:01.000
 And then data loaders has item transforms,

53:01.000 --> 53:06.000
 which are things like reshaping everything to the same size and batch transforms,

53:06.000 --> 53:08.000
 which are things like data augmentation.

53:08.000 --> 53:16.000
 But you can have an item transform around on the GPU or not.

53:16.000 --> 53:21.000
 Right? It depends on the ordering.

53:21.000 --> 53:25.000
 I don't think an item transforms generally going to run on the GPU because

53:25.000 --> 53:27.000
 it's not a batch yet.

53:27.000 --> 53:30.000
 I mean, maybe it's theoretically possible, but that would be pretty

53:30.000 --> 53:34.000
 weird because you, yeah, you really would need things to be in a batch

53:34.000 --> 53:38.000
 of things that you can be optimizing it effectively.

53:38.000 --> 53:43.000
 And everything you buy transforms will run on the GPU.

53:43.000 --> 53:47.000
 Assuming that you're using a GPU, I mean, there is a,

53:47.000 --> 53:51.000
 this is, okay, this is some part of the code base we're not looking at today,

53:51.000 --> 53:54.000
 but if there is a, I can't remember it.

53:54.000 --> 53:57.000
 I think it might be a callback, which sticks things on the GPU.

53:57.000 --> 54:01.000
 So it just depends on whether things are before or after that callback.

54:01.000 --> 54:05.000
 Yeah, that's, that's probably a bit of a distraction.

54:05.000 --> 54:07.000
 So let's skip that for now.

54:07.000 --> 54:13.000
 To, to kind of revise the difference between data set and data loader.

54:13.000 --> 54:17.000
 Is it best to revisit the PyTorch documentation and kind of?

54:17.000 --> 54:18.000
 Yeah, pretty much.

54:18.000 --> 54:21.000
 We have our own implementation of them, but our implementation of data

54:21.000 --> 54:28.000
 loader is a superset of PyTorch's and PyTorch's data set is like,

54:28.000 --> 54:31.000
 literally, it's an abstract class, it doesn't do anything at all.

54:31.000 --> 54:35.000
 It's just a, so a data set is something that you can index into.

54:35.000 --> 54:40.000
 And it returns a single tuple of your independent independent variables.

54:40.000 --> 54:44.000
 That's what a data set's defined as a PyTorch.

54:44.000 --> 54:48.000
 And therefore, that's what we do as well.

54:48.000 --> 54:52.000
 A data loader is, is, you can't index into it.

54:52.000 --> 54:54.000
 The only thing you can do is, is iterate through it.

54:54.000 --> 54:57.000
 You can grab the next one and it gives you a mini batch.

54:57.000 --> 54:59.000
 Which is a tensor.

54:59.000 --> 55:05.000
 So that's, but yeah, this is a, that's a PyTorch concept.

55:05.000 --> 55:09.000
 I guess I'm trying to understand the type transform thing,

55:09.000 --> 55:13.000
 why it has to be done in the data set before the data loader.

55:13.000 --> 55:16.000
 It doesn't have to be, but it's, it's like, we want data sets.

55:16.000 --> 55:21.000
 Like data sets are a very convenient thing to have to have something you can like.

55:21.000 --> 55:26.000
 Go into and grab items, you know, numbered x, y or z.

55:26.000 --> 55:30.000
 That's, that's the basic foundation of the PyTorch data model.

55:30.000 --> 55:32.000
 You know, is that there's things you can.

55:32.000 --> 55:36.000
 I'm asking the type transform aspect of it.

55:36.000 --> 55:41.000
 Yeah. So you need, you need something that converts the output of get image files.

55:41.000 --> 55:44.000
 Into what you want in your data set.

55:44.000 --> 55:49.000
 And that thing needs a name and the name we gave it was type transforms.

55:49.000 --> 55:50.000
 Okay.

55:50.000 --> 55:55.000
 I think I think I understand.

55:55.000 --> 55:56.000
 Okay.

55:56.000 --> 55:59.000
 Like you, this is not the only way you could do this.

55:59.000 --> 56:00.000
 Right.

56:00.000 --> 56:05.000
 But it's, it's, it's our way that's really nice because we now have this thing that you can say like,

56:05.000 --> 56:09.000
 Oh, Hamill, can you show me the 14th image and it's label?

56:09.000 --> 56:11.000
 And you can say, yes, no problem, Jeremy.

56:11.000 --> 56:13.000
 You can type dss.train.

56:13.000 --> 56:14.000
 Bracket 13.

56:14.000 --> 56:16.000
 And, and there it is.

56:16.000 --> 56:17.000
 Right.

56:17.000 --> 56:23.000
 So, um, yeah, so that's just a convenient thing, basically.

56:23.000 --> 56:28.000
 I guess a question around that is that if we did not have type transforms,

56:28.000 --> 56:34.000
 then it would just be one more step in the item transforms, right?

56:34.000 --> 56:36.000
 Yeah, I think so.

56:36.000 --> 56:38.000
 You're just separating the sets out.

56:38.000 --> 56:39.000
 Yeah.

56:39.000 --> 56:43.000
 Your data sets would always just return a single thing or maybe the three,

56:43.000 --> 56:46.000
 two things that get X and get Y results.

56:46.000 --> 56:51.000
 And then your data loader would have to do more work, basically.

56:51.000 --> 56:52.000
 Exactly.

56:52.000 --> 56:57.000
 Yeah, which would be as perfectly okay way to do things as far as I can tell.

56:57.000 --> 57:02.000
 And I think it would be a little harder to debug and work with and.

57:02.000 --> 57:03.000
 Keep things decoupled.

57:03.000 --> 57:04.000
 Yeah.

57:04.000 --> 57:07.000
 I think it's a reasonable comment.

57:07.000 --> 57:11.000
 Is it like anything you want to do upfront?

57:11.000 --> 57:17.000
 That is like kind of uniform across your whole data set, maybe put it in the type of transform that you don't need to.

57:17.000 --> 57:19.000
 Change at training time.

57:19.000 --> 57:24.000
 Basically, like anything that you want to be able to like.

57:24.000 --> 57:27.000
 Index into it and look at that thing.

57:27.000 --> 57:29.000
 Really, you know.

57:29.000 --> 57:32.000
 If you're not sure where to put it.

57:32.000 --> 57:35.000
 I'd say just check it somewhere and don't worry about it.

57:35.000 --> 57:40.000
 You know, like, like, you know, we kind of put.

57:40.000 --> 57:46.000
 The rule is that, you know, you need something that.

57:46.000 --> 57:49.000
 Can be turned into a tensor.

57:49.000 --> 57:52.000
 Like that's, that's the way fast AI does it.

57:52.000 --> 57:56.000
 So you need to make sure that your type transform.

57:56.000 --> 58:02.000
 When you're working with our say I return something that is a tensor or going to be turned into a tensor.

58:02.000 --> 58:05.000
 Which PIL image can be.

58:05.000 --> 58:07.000
 For example.

58:07.000 --> 58:09.000
 Okay.

58:09.000 --> 58:16.000
 I think I understand it's kind of like a you want to just you want to make sure it's like a convenient thing that you understand to look at.

58:16.000 --> 58:17.000
 Yeah.

58:17.000 --> 58:19.000
 Okay.

58:19.000 --> 58:20.000
 Yeah.

58:20.000 --> 58:21.000
 Okay.

58:21.000 --> 58:22.000
 So then like.

58:22.000 --> 58:23.000
 Okay.

58:23.000 --> 58:25.000
 So I can remove all that.

58:25.000 --> 58:29.000
 That is that this is the definition of image block.

58:29.000 --> 58:32.000
 So let's replace it with the word image block.

58:32.000 --> 58:33.000
 Okay.

58:33.000 --> 58:35.000
 And then.

58:35.000 --> 58:39.000
 Let's change.

58:39.000 --> 58:47.000
 Okay.

58:47.000 --> 58:54.000
 Okay.

58:54.000 --> 58:55.000
 Okay.

58:55.000 --> 59:01.000
 So let's pop a.name here.

59:01.000 --> 59:06.000
 Here's kind of something we want as our label right. That's one of our labels.

59:06.000 --> 59:10.000
 And then the other label we wanted.

59:10.000 --> 59:14.000
 Was the.

59:14.000 --> 59:20.000
 Function call get variety.

59:20.000 --> 59:22.000
 Right.

59:22.000 --> 59:27.000
 Now we can't this breaks our rule. This can't be turned into a tensor.

59:27.000 --> 59:29.000
 Because it's string.

59:29.000 --> 59:33.000
 So what do we do about that?

59:33.000 --> 59:39.000
 You might remember from a previous lesson we learned that what we do is we replace strings with integers.

59:39.000 --> 59:45.000
 Where that integer is a look up into a vocabulary. It's a list of all of the possible options.

59:45.000 --> 59:56.000
 So if we change this to category block.

59:56.000 --> 1:00:02.000
 That is exactly what category block will do.

1:00:02.000 --> 1:00:04.000
 Right.

1:00:04.000 --> 1:00:07.000
 And so.

1:00:07.000 --> 1:00:14.000
 Category block.

1:00:14.000 --> 1:00:21.000
 It's got to type transform categories, which I'm not going to go into because it's not particularly exciting.

1:00:21.000 --> 1:00:27.000
 But if you look up the documentation for categories, you can see how it does that.

1:00:27.000 --> 1:00:35.000
 So basically internally now you'll find that the vocab is stored for these things.

1:00:35.000 --> 1:00:40.000
 So if we look at this at the high level, get items.

1:00:40.000 --> 1:00:43.000
 By the way, just about here's a vocab. Right. It's got two things.

1:00:43.000 --> 1:00:48.000
 It's got the vocab for the diseases and the vocab for the varieties. Yeah. Sorry about it.

1:00:48.000 --> 1:00:51.000
 Okay.

1:00:51.000 --> 1:00:59.000
 So get items, it gets us the rows or the examples or whatever allows us to, and the core.

1:00:59.000 --> 1:01:07.000
 And then from get items, we use get why or get eggs to transform it somehow.

1:01:07.000 --> 1:01:10.000
 So that we can pass it into those blocks.

1:01:10.000 --> 1:01:20.000
 Into type transforms are things that you can get triggered.

1:01:20.000 --> 1:01:27.000
 Right. So they're doing a little bit something similar to get why, but like our building on what you can find us.

1:01:27.000 --> 1:01:31.000
 Correct. Exactly. Because because these are like very general things.

1:01:31.000 --> 1:01:32.000
 Right.

1:01:32.000 --> 1:01:35.000
 And so I didn't want you guys to have to write your own every time.

1:01:35.000 --> 1:01:42.000
 So these, these, these basically say, this is, I will work if you can pass me a path to an image.

1:01:42.000 --> 1:01:45.000
 And this says I will work if you pass me a string.

1:01:45.000 --> 1:01:51.000
 And so get X and get why then are responsible for ensuring that you pass them a path.

1:01:51.000 --> 1:01:58.000
 And pass this one string and get image files is already returning paths. So we don't need to get X.

1:01:58.000 --> 1:02:08.000
 This guy, but it's not returning strings. So we do need to get why for these guys.

1:02:08.000 --> 1:02:15.000
 Okay. So I'm going to finish. I'm going to run a slightly over time.

1:02:15.000 --> 1:02:24.000
 But let's have a look at.

1:02:24.000 --> 1:02:30.000
 So this is exactly. Okay. So this is exactly the same as what we just had.

1:02:30.000 --> 1:02:35.000
 Right. And so then we also then add the two things, which is the item transforms and the batch transforms.

1:02:35.000 --> 1:02:41.000
 Some other time, we will talk about how it is that how come this is not being applied to the categories.

1:02:41.000 --> 1:02:43.000
 It's only being applied to the images.

1:02:43.000 --> 1:02:50.000
 For those of you interested in skipping ahead, the secret is using fast calls type dispatch functionality.

1:02:50.000 --> 1:02:54.000
 Anyway, so that's.

1:02:54.000 --> 1:02:58.000
 That's why we're getting these three different things image. We've got Y1.

1:02:58.000 --> 1:03:04.000
 So it's turning me if we had an image, if we had an image block in our.

1:03:04.000 --> 1:03:07.000
 Or our wives for our target. Yes.

1:03:07.000 --> 1:03:09.000
 I think possible.

1:03:09.000 --> 1:03:11.000
 Correct.

1:03:11.000 --> 1:03:13.000
 Oh, wow.

1:03:13.000 --> 1:03:22.000
 And there's a, there's a, have a look at the Siamese tutorial on the first day adopts because that has two images.

1:03:22.000 --> 1:03:23.000
 Yeah.

1:03:23.000 --> 1:03:27.000
 And like if you think about it, anytime we do segmentation, that's exactly what's happening.

1:03:27.000 --> 1:03:32.000
 Right. The data augmentation is happening to X and Y. And this is like really.

1:03:32.000 --> 1:03:38.000
 Unusual. I don't know of any other libraries that have this kind of totally transparent ability to do.

1:03:38.000 --> 1:03:49.000
 Bounding boxes, segmentation, point clouds, whatever is dependent variables and have it all happen in unison very, very automatically.

1:03:49.000 --> 1:03:55.000
 But at least it didn't used to be. Maybe there is now.

1:03:55.000 --> 1:04:00.000
 Okay. So.

1:04:00.000 --> 1:04:07.000
 So now I can create data loaders from that.

1:04:07.000 --> 1:04:10.000
 And thanks to the magic of.

1:04:10.000 --> 1:04:16.000
 Fast AI. This is so cool. Check this out. It's actually auto, auto labeling it with each of our categories.

1:04:16.000 --> 1:04:22.000
 So thanks to stuff we'll discuss later. Basically, this stuff called.

1:04:22.000 --> 1:04:24.000
 Type dispatch.

1:04:24.000 --> 1:04:31.000
 Fast AI does a lot of things automatically, even though I don't think I've ever like explicitly coded this to work.

1:04:31.000 --> 1:04:35.000
 It just does because of how the API is designed.

1:04:35.000 --> 1:04:39.000
 So we now have something which can create batches of.

1:04:39.000 --> 1:04:45.000
 Pictures and two different dependent variables. Each one of which has a category.

1:04:45.000 --> 1:04:49.000
 And so.

1:04:49.000 --> 1:05:00.000
 What we will get to next time is.

1:05:00.000 --> 1:05:05.000
 It actually turns out well briefly mention it now actually.

1:05:05.000 --> 1:05:12.000
 All that stuff I did last time about messing around with like multiple different heads and all that is actually totally unnecessary.

1:05:12.000 --> 1:05:15.000
 All we need to do when we create our vision learner.

1:05:15.000 --> 1:05:20.000
 Is tell it we don't have we don't want 10 outputs, but we are on 20 outputs.

1:05:20.000 --> 1:05:27.000
 So normally it automatically figures out how many outputs you want by how many levels are in your category called dependent variable.

1:05:27.000 --> 1:05:32.000
 But in this case we've got something custom right which is we've got a tuple of outputs.

1:05:32.000 --> 1:05:41.000
 So we have to tell it we want 20 outputs that's going to make the final matrix that it multiplies by have 20 outputs.

1:05:41.000 --> 1:05:46.000
 Now then you basically need to tell it what loss function.

1:05:46.000 --> 1:05:48.000
 To use.

1:05:48.000 --> 1:05:54.000
 And so if you look it up it turns out we used to use a loss function for this called cross entropy loss flat.

1:05:54.000 --> 1:06:03.000
 So we're going to call that exact loss function on the first 10 items and we're going to compare that to the.

1:06:03.000 --> 1:06:08.000
 Disease probabilities and then the second 10.

1:06:08.000 --> 1:06:14.000
 We're going to compare to the variety probabilities and we'll do the same thing for having an error rate.

1:06:14.000 --> 1:06:21.000
 Which just looks at the first 10 in the area of disease and the same thing for variety look at the second 10.

1:06:21.000 --> 1:06:25.000
 The variety and so basically then if you train that.

1:06:25.000 --> 1:06:32.000
 It's going to print out the disease and the variety error and the loss function will be the loss function on both.

1:06:32.000 --> 1:06:37.000
 Both the two halves and interestingly.

1:06:37.000 --> 1:06:40.000
 For this single model.

1:06:40.000 --> 1:06:47.000
 This 2.3% disease error is the best I'd have got for this architecture.

1:06:47.000 --> 1:06:52.000
 So at least for you for this single model case this was better than.

1:06:52.000 --> 1:06:55.000
 Training.

1:06:55.000 --> 1:06:58.000
 Something that only predicts disease.

1:06:58.000 --> 1:07:01.000
 Anyway, we can talk about that more later because yeah we kind of spent more time.

1:07:01.000 --> 1:07:03.000
 A quick question.

1:07:03.000 --> 1:07:04.000
 Yeah.

1:07:04.000 --> 1:07:07.000
 The last layer it's it's it's a flat 20.

1:07:07.000 --> 1:07:09.000
 20 output layered.

1:07:09.000 --> 1:07:16.000
 Does this mean at inference time that we would have to do the soft max plus.

1:07:16.000 --> 1:07:18.000
 What would it be?

1:07:18.000 --> 1:07:19.000
 I can't remember.

1:07:19.000 --> 1:07:21.000
 I had all that for you automatically.

1:07:21.000 --> 1:07:22.000
 Yeah.

1:07:22.000 --> 1:07:23.000
 Yeah.

1:07:23.000 --> 1:07:24.000
 Great.

1:07:24.000 --> 1:07:25.000
 All right.

1:07:25.000 --> 1:07:34.000
 And by the way in the inference functions you'll see there's like always a.

1:07:34.000 --> 1:07:47.000
 I think all the options is to like whether to do code and whether to put the final activation function on ocean stuff like that.

1:07:47.000 --> 1:07:52.000
 Actually, now I think about it in this case because we used to custom loss function.

1:07:52.000 --> 1:07:55.000
 I think that would have broken its ability to do it automatically.

1:07:55.000 --> 1:07:59.000
 So yeah, okay, I'm going to say actually you would need to.

1:07:59.000 --> 1:08:05.000
 Because like at least for the Kaggle competition I just needed the.

1:08:05.000 --> 1:08:10.000
 Which disease had the highest prediction and whether it's soft max or not.

1:08:10.000 --> 1:08:14.000
 It's going to be the same because that's a.

1:08:14.000 --> 1:08:17.000
 Monotonic function.

1:08:17.000 --> 1:08:22.000
 So depends whether you actually need probabilities or not.

1:08:22.000 --> 1:08:25.000
 In my case, but in the.

1:08:25.000 --> 1:08:26.000
 Yeah.

1:08:26.000 --> 1:08:30.000
 Yeah, but you would really look at the first 10 or the second.

1:08:30.000 --> 1:08:31.000
 I guess the first one.

1:08:31.000 --> 1:08:32.000
 Yeah.

1:08:32.000 --> 1:08:35.000
 So you can see it because otherwise.

1:08:35.000 --> 1:08:36.000
 Yeah.

1:08:36.000 --> 1:08:38.000
 So I was using TTA.

1:08:38.000 --> 1:08:39.000
 Right.

1:08:39.000 --> 1:08:44.000
 To do test plan and augmentation and I stacked up and I did an ensemble of TTA.

1:08:44.000 --> 1:08:48.000
 And then I just did an arg max on the.

1:08:48.000 --> 1:08:49.000
 Yeah.

1:08:49.000 --> 1:08:50.000
 Yeah.

1:08:50.000 --> 1:08:52.000
 All right.

1:08:52.000 --> 1:08:56.000
 Yeah.

1:08:56.000 --> 1:08:58.000
 In the architecture.

1:08:58.000 --> 1:09:03.000
 You selected for resnet 18, 128.

1:09:03.000 --> 1:09:09.000
 Is there any programmatic way to find out the size of or the input size of the.

1:09:09.000 --> 1:09:12.000
 Models that you are trying to use.

1:09:12.000 --> 1:09:15.000
 These models handle any input size.

1:09:15.000 --> 1:09:17.000
 All right.

1:09:17.000 --> 1:09:19.000
 All right.

1:09:19.000 --> 1:09:22.000
 All right.

1:09:22.000 --> 1:09:26.000
 All the resnets and all the com of next and or any input size.

1:09:26.000 --> 1:09:27.000
 All right.

1:09:27.000 --> 1:09:28.000
 Thank you.

1:09:28.000 --> 1:09:30.000
 It's already the transfer model.

1:09:30.000 --> 1:09:37.000
 That also tripped me up in the beginning, but there's a lot of interesting stuff there that might take a whole lecture to understand.

1:09:37.000 --> 1:09:38.000
 All right.

1:09:38.000 --> 1:09:39.000
 Thanks.

1:09:39.000 --> 1:09:40.000
 Thank you.

1:09:40.000 --> 1:09:41.000
 Thank you.

1:09:41.000 --> 1:09:42.000
 Thank you.

1:09:42.000 --> 1:09:43.000
 Thank you.

1:09:43.000 --> 1:09:44.000
 Thank you.

1:09:44.000 --> 1:09:50.000
 Thank you.

1:09:50.000 --> 1:09:58.000
 Thank you.

