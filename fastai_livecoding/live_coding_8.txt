 Okay, yeah, you've got a question. Yeah, okay so I've got my paper space open, and I can see. Yeah, my machine is not actually starting, which is great. So I can see. I missed off the directly, it's like, it's clean image tools, but I don't want to go to the 20, the course to the current course. Of course, 20, 30. So you would get cloned it. So you would open, so you would open up Jupyter lab. Go into a terminal, and you would CD to slash docs, sorry, say to slash notebooks, and then get cloned and copy and post the get URL from GitHub. Okay, let's see what happens. Okay. Thank you. Any other questions anybody having any trouble getting things working smoothly. I am ready. Oops. You got enough. Please go on. So, I have a question. I tried to look at my history, my bash history. I tried the same link. I can see it there. Yeah, in my home, but I don't seem to be able to history from my previous session. Yeah, so the bash underscore history file dot bash is only created when you close the terminal. You can't send link it to it to exist. And so to make it exist, there's two things you could do. The first is you could open a terminal, run a command like LS, and then close the terminal, and open a terminal again. And now the bash history file will be there because you've done something and you can send link to it. Or you can just create it and to create an empty file in Unix, you just type touch space and then the file name. So dot, I should just go history. Okay. And somebody else had a question or comment. Yes. So my question is about with Kegel part from last lesson. So what I understand from from the lesson. You need to either do everything in the Kegel website, the training and the inference, let's say, or it's possible to train your model in local machine or gradient let's say. Then somehow transfer it to the Kegel somehow. Right. So which we're going to do today. Yeah. Great. What is the proper way that was my question? Yeah, yeah, yeah, great. Perfect. I love it when people ask the question that I want to solve today because that's a sign that it's a question worth asking answering, I should say. Okay. Well, neither of my gradient machines are starting. Setting up instance. That's not good. All right. I guess we're going to use the terminal. Now, the bad news is that I'm on my Mac, or I don't think I've got anything set up. You can use your fancy set up. Things script. Yeah, I mean, I mean, yeah, it's, it's slightly set up. I don't have the Kegel stuff downloaded. So, all right. Well, it's always good to revise anyways. Share screen. Right. Okay, you guys can see that hopefully. I wonder if we should maybe make this a little bigger as well. Okay. I can't see that. Okay. Is that reasonably visible. Yes, it is. Great. Yes, this. All right. So, so this is T marks, obviously running in a terminal. And because I'm sharing my screen, I'm using a slightly low resolution kind of area that usual. So, particularly good idea to zoom into one of these panes. So, I just get control BZ to zoom into the pain. And let's see if on this machine, I already. Okay. So, this machine does not currently have a Kaggle directory. So, if you can store. Kaggle. Great. And if I try to run that, it's not going to work. So, I have SSH config set up. Oh, yeah, that's right. I think Max got some really old version of SCP that doesn't know how to do much. So, I might have to normally with a current version of open SSH, SCP, you could tap complete even to get remote files, which is quite great. And I think I noticed that Mac tends to ship really old versions of a lot of the unique software, which is a shame. So, we have to do it the slow way. So, we're going to copy.caggle slash Kaggle dot JSON to here. So, I'm putting in this is H move Kaggle dot JSON into Kaggle. And that should now work. Great. So, let's download the data. All right. And we're going to go competitions, Patty and data and copy. And paste. Okay. All right. And then we're going to see if you've got Jupyter running. We do. All right. Well, it's going to be crazy over there. So, let's open up Jupyter. And if anybody keeps an eye on paper space, let me know if paper space seems to start working. All right. Here's Patty. You. And all. Okay. From fast AI dot vision dot all import star. So, like this is finished. So, we can now unzip minus Q. Not that unzip minus Q. Patty disease classification. There we go. Oh, you know what we could do. We could run this on my GPU server because of course, running this on the max. You have a dumb idea anyway. So, I don't think we've talked about how to do that before. So, this might be slightly obscure. That's okay. So, I'm going to run something in the process. So, all right. I'm switching over now. Actually, let's jump out of T mux. Because running T mux in T mux is always a little bit weird. So, this is my GPU server. Okay. And it is running Jupyter. And it says, oh, you can go to local host 888 to use this. But I can't because that's not local host refers to the machine I'm currently on. And I'm not on this machine. I'm SSHing into a remote machine. But what I've done. And as I say, this is like something that not everybody needs to know about for sure. But for those who are interested, what I've done is when I SSH to this particular machine called local, it forwards anything that I use on my local machines port 888 to the remote machine machines. 888, which means that I can use local host 888 and it will actually forward those packets to the remote machine and forward remote machine packets back to here. So, this is called SSH forwarding. You know, if I. So, if I. Go here. Oh, and the other thing we should probably do is make sure that Jupyter is not running on the local machine. Cancel that. And so to exit out of this, I could create another window or another tab or whatever, but I can just hit control B.D. to detach from T. So that stuff's all running still in the background. And then I can SSH to my machine. And let's see if that's all. Working. There we go. Okay. So. That's great. And so here we actually have that going so we can create a new notebook. And it's easy enough, by the way, if you do like by a machine with a GPU, which it's not a terrible idea, especially if eventually GPU prices start to come back down to reasonable levels at some point. You know, it doesn't need to be a notebook or anything. You can check it anywhere in the house, just like I've done. And as you can see, log into it from your computer. Now, I can only log into mine. Right. You know, by default, I'd only be able to log in from home. If you want to be able to log in when you're not at home, you would have to go into your router's settings and say forward port 22, which is the SSH port. To your GPU server. And you'd also have to know the IP address that your house's Wi Fi is on, and that tends to change. So you can use something called dynamic DNS. There's lots of different providers of dynamic DNS. I use something called din.com just because they've been around forever. And so, yeah, so I can log into my machine from from anywhere, which is, which is very nice. Okay, so let's try this again from fast AI.vision.org imports. All right. And so path equals. So we can do LS in bash like so. Here we go. Great. So you can just use the current path. Is where our data is. And so our trading path. Oh, and we're also. That's fine. And then our training path. Is. So, I'm not sure we've really talked much about pathlib before us. So this. This path object comes from a Python class called pathlib. And it's imported by default with pretty much any fast core or fast AI thing you use. So basically, yeah, it lets you create a part. This is your path and your current working directory, or you can do something here to go to a relative directory, or you can go to a. Absolute directory. And then you can, you know, it's kind of got this somewhat neat. Use of the slash operator to mean, you know, go to a subdirectory.ls doesn't come with it by default. Fast core adds that to list things, as you see. Yeah, so that's pretty cool. And so the other thing we did yesterday was we looked at the files. Get image files. Inside. Let's have a look at the ones inside the training path. And so we could create an image. You can look at it. And then we could create a size. Okay, so there's a few things we can do that kind of gets us back to where we were yesterday. So a question I saw in the forum was how would I forget like the sizes of all of the files. Okay, which is, let's do it the slightly slow way in time how long it takes sizes equals. Let's just copy that paste that here. So size for in files. Yes. Is there a question coming. So to do this in parallel, which would obviously be faster. I mean, it would depend if the most of the time is spent reading this from the disk, then doing this in parallel won't be any faster. If most of the time is being spent decoding the JPEG, then doing this in parallel will be faster. And which of those is true will depend on whether we're using an SSD or not. So anyway, I'll show you how to do it. So if you import a fast quarter parallel, which is a module, that module contains a function. Or parallel, which applies this function to these items. So the function we want to apply is. Let's look at the doc for it. So here's an example of parallel. Oh, that should be. What a bit of a mind. So here's something that takes two things, x and a and adds something to each one. And so here's how we use parallel. The docs for faster libraries are a bit different to some in the tests and the docs are all one thing. So to read this, this is saying if you call parallel passing at this function, which is just. X plus a where a defaults to one. And you do it on this input, which is range 50. Then you would expect to get this output, which is the range from one to 51. So this kind of is showing you lots of examples of using the function and telling you what to expect to get for each one. So if we want a function, which is going to take some file and it's going to return. This. So. And so if we want to run that in parallel. Then we can say. And the function we want to run is this function and the files we want to run on his files and there's lots of other things we could pass in. So, like, let's say we want to do it on four parallel workers. See if that ends up any faster. So as you can see running stuff in parallel when he is fast core is actually pretty fast and easy. But as I said, it doesn't necessarily result in a speed up. If the main thing that's taking time is. Getting stuff off the disk. Then it won't be faster. Okay, so in this case it was a bit faster. I think that I think they use really slow disks on. Actually, this is my disc. This is a good disc. So ought to be fast. So we could see if increasing it further is faster still. I guess it's we've probably. See. Jeremy quick question about this. Yeah. Does this use CPU cores or is it using the view or running it in parallel CPU. So the GPU is only used for. For models, basically pretty much everything else is going to be done on CPU. Okay. Okay. So that's definitely worth the speed up. Now, I don't normally create. A function. To do one thing like this. What I would normally do instead is to use a lambda expression. And so to use a lambda expression. It's just basically it's a function you define in line. You just type lambda. And you say the argument and you don't have to say return. And so then we can get rid of the definition. And run. Okay. So that's interesting. So we can't use a lambda with parallel. I guess I didn't know that now I think about it. All right. That's fine. We won't use it then. Parallel processing on Python is notoriously crappy. So. Yeah. It's it's it has a lot of limitations, including now I think about it not being able to use lambdas. Okay. So then we created our data loaders. Image data from path. And we passed in the training path. And. And. And I think we want some resource transform as well. Right. Cool. So. And so then we created a model. So last time we used ResNet 34. But what I'd be inclined to do. Is to head over to Kaggle and look at the. Which image models are best. And see if there's something we might want to use. It's better than ResNet 34. So this is showing speed in a log scale. And this is showing accuracy on image net. And the different colors of various different kind of families. So. ResNet is. This family here. And things like. ResNet 34 and not particularly great, as you can see. So let's try using con next base in 22 blah blah blah instead. Okay. So vision learner we just passed in the data loaders. And so these image models here from. A library called Tim. Which to use it you need it installed. Which I probably have installed but just to check. Yep, it's already installed. And you can check out things on Tim such as so if you import it. Then you can say Tim dot. List models and you can pass in basically a glob so I want to look at com. Next models. See what options there are mainly because I just want to. Copy and post. And so okay so there's base this mall as well. Small. Now why small. Con next. If you double click you'll get this is base large. Extra large. That's weird. For some reason. The small ones not appearing. I think they are the small and the tiny one in the last version of team that is not in the people so. Right. Okay, so. Oh yeah. We need to install the dev version of it. Correct. Yes, thank you. So Ross who runs who creates Tim. Created a pre release version point six to. And so to install that we would need to. Call minus you upgrade. Oh, just one moment please. I don't have any computer problems. All right. Tim. Greater than. 0.6. 0.6. 0.6. 0.6. I think something like this. I'm not quite sure. Oh, it says I've already got 0.6.2 dev installed. Oh, I see so I've got it on my machine but it wasn't on the Kaggle machine because I didn't install the that version on Kaggle. Okay. Cool. Well, we might as well fix it on Kaggle just so you see how these things work as well. Because there's actually something quite nifty here. I will click edit on Kaggle. And we'll. Not here somehow but it's okay. Oh, all right. It's he doesn't have it in his data. I guess. All right. So not much we can do about that. All right. Well, I think we should just go ahead and try one of the smaller ones. So come let's try small. That has to be a string when you use Tim. Okay. See what happens. So when you use a pre trained model. It needs the weights. And so the first time you use it, it downloads the weights. Depending on how much space if you're using paper space, depending on how much space you have and how long this takes on paper space, you may want to consider. Sim linking your home directories dot cash slash torch. Into slash storage. And that way you won't have to download these, not that it seems to take too long. I don't know if you care or not. You know, one thing we might want to do. Well, let's, let's just try to find tune it, shall we? Yeah. It's good. Seems to be working. So, you know, if anybody's got any questions or thoughts along the way. So when it fine tunes. Oh, okay. So the other thing we want to do is tell it that we want to keep track of the error rate. Okay. So, yeah, so when we fine tune. Just create another copy. Okay. So we can look at the source code to see exactly what it's doing. When we call fine tune. So what it's actually doing. Is it's calling freeze? What that does is it. Says all of the weights except for the very last layer. You're the optimizer is not allowed to change. So if you think back to that, Siler and Fergus paper we saw with the different layers and the different like, you know, the later layers were more and more specific. So initially we just want to fit the last layer. So it calls fit on the last layer only. And then it decreases the learning rate and then unfreezes. So then it says, okay, you can train the whole thing and then it trains the whole model for however many epochs we asked for. So we can see. So generally speaking, first I methods or I mean pretty much any methods I write tend to be very small. So they're designed to be reasonably easy to read the source code and see what's going on. At least if you're reasonably comfortable with Python. Oh, and I just sort of something else we should do. Which is if you are using a. GPU released in the last, I don't know, four years or so. It's very likely that it'll be much faster using. What's called half precision floating point, which is basically like less less precise numbers. It'll be way way way faster. Most of the time on co lab and Kaggle you're not going to get. One of those more up to date GPUs, but having said that there's really never any harm in using half precision floating point. And even if you use an older GPU, it's still going to save memory. So actually to ask. I had to do that for you. You can add to floating point 16 as in 16 bit. At the end of your learner command. So, yeah, so when this finishes, we might try to re running it. With this instead. I'm just following along on purpose place. And if I don't want to bother with importing Tim just to keep up what instead of using con next, what would, what would be a good default to use. I mean, why not use come next what's your. I guess because I would. I think I missed that. So, yeah. Or if you want to get the more recent. Models, such as the one we're using then. Pip install. Let me copy this for you. So that's the command there. And Jeremy, just while we're. While we're talking about, you know, fine tuning and as that's going on. I don't know if anyone else would find it helpful, but I mean, obviously, like conceptually understand what's happening with fine tuning but. I don't know if anyone else kind of feels like trying to understand better what's actually going under the hood with fine tuning like what's actually being altered. With within the model like more than just like a kind of at a high level. I'm just trying to get a bit of a better grip on. Yeah, like what exactly where fine tuning and how it's going about fine tuning it. I guess just under that, that first surface level. Just want to make sure I understand it better. So, so we just looked at the source code for it. So what, what, what, yeah, what did you want to go. Which bit of this. Do you want a little deeper out or like what did you. Yeah, tell me, tell me more what you want to know. Yeah, I guess so, you know, like stepping through it so like we, we, you've got it frozen at a particular point, right, and then this fit one cycle so just go into the definition of fit one cycle again. Oh, so we haven't done that yet in the course I don't think. So yeah, so we can certainly talk about that. I don't want to hijack things if other people want to kind of move on that's fine. I can follow it up later but I just, I just kind of wanted to get a bit of an overview of what's actually going on there. Let's take a look at one cycle. So, look at the docs. So what does fit one cycle do. So actually, there's a paper you can read if you want to know exactly what it does. But there's a picture here, which tells you what it does. And what this picture is, is so fit one cycle is something called a scheduler and a scheduler is something which actually changes the learning rate during the training. So remember the learning rate is the thing we multiply the gradients by before we subtract them from the parameters. When you have a randomly initialized model or even a pre trained model we actually randomly initialized the last layer of weights. So at first, even a pre trained model that we're fine tuning can't do anything. It's right. It's still giving random answers. And so that means we want to use a really small learning rate because it's very difficult to get to a point where it's starting to learn something slightly useful. And so when we start training the first year batches use a tiny learning rate. And then as it gets better and better at like doing something useful, you can increase the learning rate because it's got to a point where it's like, yeah, it's kind of nose vaguely what it's doing. And so as it trains the learning rate goes up and up and up and up. And then as you start to get close to the answer, you need to decrease the learning rate again. And the reason for that is that you're really fine going to small little steps you're really, really close now. So when you. So you say, so you say, as you get closer to the answer, like are we saying that that's in comparison to the validation set so that we're, so that we're moving away from overfit that where those might, yeah, I guess whether training or anything. This is just so this is just a plot of the curve of batch number against learning rate. So this is this is the exact shape that is used. There's nothing clever going on it just it just follows this exact curve. Okay, so there's no there's that's not interacting with anything else to derive those numbers it's just doing that. Okay. All right. So in fact, I was code for it. What it does is it calls them in called combined cause. Which is something that uses two cosine schedules. And so a cosine schedule is one that. So it's also known as an annealer it's called learning rate and yelling is something that literally uses cosine. Got it. Yep. Okay. That's helpful. So I get now kind of where that's mapping to that, that idea. And, you know, for people who are interested in going deeper in understanding like what is fast, I do and why and what what actually makes what's important in deep learning and stuff. This is how exploring the documentation and source code of fast, I, when you add a point where you feel this is what you're ready to do can be super useful because the documentation can tell you what paper is being implemented and why and shows you pictures and stuff that you're doing and the source code is something that you can copy and paste into your notebook and try it yourself and so forth. Yes. To try any other questions about this. No, that's that's fine for me. I don't know if anyone else does. All right. I just wanted to comment that Sylvain had a very good blog post explaining those with one cycle. Policy. Yes, he does. Okay. Perfect. And so there's other policies you can use like the triangular version. So this is actually what we originally did I think for one cycle as you can see it ends up being pretty similar. And what would be, I guess, the criteria for where you would change that policy like it. Like what would I guess what's the basis for the decision you make about changing that policy. I mean, you don't basically it works fine and you just do it. Yeah. Okay. All right. So it's pretty arbitrary. Yeah. I mean, it's, it's, no, it's not arbitrary. It's something that lots of experimentation has found that this works well. And the things that need changing. We generally tell people all about them, but this is generally something that doesn't need changing too much. Okay. So is this related to learning trade finder. Okay. So let's talk about learning. Because I'm finding it quite confusing, which actually which, which number is correct with learning trade finder. So I'm just before we do that, I'll just point out so the, the mix precision version on my RTX card, which is a consumer GPU. The speed's gone from a minute 41 to 28 seconds. So you can see it really does make a huge difference to use. So this question about something called the learning rate finder. So the learning rate finder does something very similar to one cycle, the one cycle scheduler or one cycle in yelling, which is it gradually increases the learning rate while it trains. But it actually only does up to 100 batches. So generally speaking far less than even an epoch. And it doesn't increase the learning rate and then decrease it again. It just keeps increasing the learning rate until the whole thing falls apart. And so this is a graph of the learning rate. And remember it increases it logarithmically increasing every batch. So this is also kind of a graph of time of batch number. And then it shows you what loss it got. So for batch, the first year batches, it got a loss of about four. And until it got up to a learning rate of about 10 to the negative four, nothing really improved. So clearly learning rates of less than 10 to the negative four aren't very useful. And then as it increased the learning rate, you can see the slope started to get steeper and steeper. And so this area here is where it's learning the most quickly. And then it gets to a point up here where it's too high. And when it gets too high, initially it just doesn't really improve it all. And then it gets really too high. It jumps past the answer, right, and starts getting much worse. So the, yeah, so I generally just pick somewhere visually around the middle. Or you can, you know, see, it says something around. So is the magnitude of that thing, or why we wouldn't choose the minimum here. I mean, I, okay, sorry, that's what I thought like. Yeah, this would be a really bad spot right because at this point it's not learning. So what you want to look at is the is the gradient you want to look at the slope of this line because the slope is how quickly is it improving. So at this point here that this learning rate, it doesn't improve at all. So if we use this learning rate. So what did that make sense to use gradient actually for this. Yeah, to see what's the minimum. I mean, rather than doing that visually. Well, not necessarily because you see here there's a really steep gradient but that's definitely a bad spot. True. Okay, sorry. So, I mean, Debbie, sorry, it's a great question. Like, it's surprisingly difficult to come up algorithmically with the thing that our eyes do when we say like, oh, we're about somewhere around here. Wouldn't that be local mini minimum. No, sorry. No, because the minimums down here, which is definitely not what we want and the minimum gradient would be here, which is definitely not what we want. I'm not saying it's possible. It's totally possible. But the learning rate finder. So, Zach Mueller actually spent a lot of time trying different things and read a whole blog post for his company and came up with four different approaches, all of which actually don't work too bad. And you can actually look at all of them by saying what suggestion functions do you want to use. Oh. And I wonder if there's We probably should have a link to sex post in the docs because that would be quite helpful. I don't know. Maybe I'll second about that. Okay. So, Yeah, so you can see minimum. It's actually one of the suggestion functions, but I don't actually know why it's even there because you never use it. And so minimum will report the plot will be at the minimum, but the suggestion value is still like it's like 10, like divided by 10. Oh, is that what happens. Yeah, so it finds the minimum divided by 10. Oh, got it. So we should probably plot that then on the minimum rather than what's effectively 10 times that. Okay, thanks for explaining. So I can see all these numbers are all in the same order of magnitude. And the default is point. So, so something that fast AI use these is underneath the hood, or I mean, like what's the benefit of changing this learning rate manually, or trying to find it. So, so most of the time, our default works perfectly fine, which is why I don't talk about this as much as I used to actually. Sometimes some data more particularly like for a tabular data set, the learning rate can be almost anything. It really depends on the model. I find most. I have to all computer vision models seem to have pretty similar learning rates that are useful so the defaults generally work pretty well. So if you try something and it doesn't seem to be training quickly well, just try running the you know the first thing I try would be running a lot of fines just in case the default learning rates nowhere near the recommended values. And then you could try. Yeah, you could just try some different number. But yeah, these are all very close to route throughout default anyway. I wouldn't bother in this particular case. Thank you. Yeah, no worries. These are questions. Okay, we've got a model. I'm actually going to have to train it again because I just created a new learner for the purpose of that. And so the next thing we're going to have to do is to apply it to our. Training set sorry to our to our test set in order to submit to Kaggle. So the test set is always good to have two windows to tabs going on because that way we can start working on the next thing while this is training. Right. And you can see it's still training because a little hourglass icon is there in the fav icon. So there's something called test underscore. DL, which for some reason is not appearing. It must be from some different part of the library. Test you. Data core. First, I data dot or import star. Something. Oh, it's a method. Okay. My bad. The old start test deal. Okay. So, I'm going to go to the top. No doc. All right. So this creates a test data loader. So test data loader is a data loader used for inference of a bunch of things at once, basically. So there should be an example down here. Okay. So test deal is something that we pass some items to. So I don't know, like, rad act niche, anybody else, you know, I'm thinking I'm just going to call get image files on the test set and pass it to test deal. Is that what you guys would do or you have a better. Better way to do this. Yeah, I think that should work. Okay. I don't know, like what people, you know, I don't do nearly as much inference stuff as most people. So I never quite know what the. Fast AI communities preferred idiomatic approaches. Test images. Test files. Okay. So we've got 3,469 files to apply this to. So, um, so we could create a test data loader. And that's going to be deals.test deal. With those files, I guess. And we should be able to go test dl.show back. So I do always like to see what I'm doing. You know, so it looks like four. And so a test data loader that the key difference is that it doesn't have labels. So there's no dependent variable. All right, so then I guess we would go. Is it get threads or predict I never quite remember. I guess it's get threads. We need better names for these. Okay. And then dl data loader equals the test data loader. Oh, and I should have signed that to something obviously that was a bit silly of me. And also we should look at the documentation for it. So, I guess do not used to that keyboard shortcuts. Doc. Paste. Get the predictions with some particular data loader. It can optionally return the import. You can option return the loss. We don't need any of that. Okay. So what I think we should do is we should look at Kaggle at this point. And actually, we don't even need to look at Kaggle. What Kaggle normally does is they provide us with a sample submission. Here's one here. Right. So let's look at the submission. Sample submission equals PD dot read CSV. And notice in Jupiter, if you start quotes and you press tab, it will tab complete file names, which is nice. Okay. Not a very useful sample submission. Unless there's something wrong with Python. This is not a great sample submission, but they just want the name of the class or the tourist. I see. What a terrible sample submission, particularly for a training one, you would think they would people are helpful. So they just want the text of the name of the class. Do they? I mean, obviously we could actually look it up and find out rather than guessing when you don't have Reddit on the line to show you the answer. Or maybe you can just call Reddit and ask him. Oh, data evaluation. Yes. See, they've actually got a sample here. Yeah. All right. So let's try that. So, preds equals. And so by default, it's got to return the probability of every class, which we can certainly turn into what we want. But I think if we call with decoded. That will do it for us. Does that sound right? So I had a practice with this. Okay, it's pretty close, right? It's given us. The indexes of each one. So this is actually going to be a really good exercise. So in terms of like what's in there, there's three things. There's the probabilities. There's something that I don't care about. And there's the indexes. So these are the indexes. So what are these indexes of the indexes into the vocab? So if you remember, the vocab is the tells you what's what. Right. So we need to convert these predictions into these pieces of these strings. So the first had probably been inclined to. Just to maybe turn that into a pandas series. And so. I guess we should. To give it a name as well. There's okay. So let's call these indexes. Oops. Oh, and it's called. It's called name. Okay. So there's a pandas series and. I always find pandas. The pandas API. Difficult to remember it's I don't find it particularly. Consistent or intuitive, but there is. A map. Function. Which I think we can look up. In. To. Category. Is. Although it looked like a list. I guess it's not one, but we might be able to turn it into a list. Normally you can turn things into lists like so. Yes, we can. Let's see if that works. Oh, okay. That's annoying. So I'm pretty sure that you can pass a dictionary. Yes, you can. And I thought a list would count as a dictionary, but apparently it doesn't, which is. I mean, a mapping. So a mapping just basically refers to something that behaves like a dictionary. So we actually have to create a dictionary which maps from the index to the name, which is. A bit of a pointless thing to do in a sense, but that's okay. So for K comma V in. So if we enumerate through that. Okay, so that's a map. That's what a mapping looks like. So I could say mapping equals. And then here we'll say mapping. There we go. So that's what we want. So. This is basically our results, right? So I was thinking like an alternative way, like mapping also map function also takes functions. Correct. Correct. And I was avoiding that because that, I mean, I know it doesn't matter here, but it's really slow. So we could also pass in a function. But I was just thinking like you could just have a function that just indexes into the, into the list or something like that. Correct. Like a lambda function or something like that. Exactly. Let's go ahead and do that to see what it looks like. But almost nobody knows that you can use a dictionary or a mapping. So almost everybody on cackle uses a function and often it can take a very, very, very long time to run at, you know, on big data sets. So yeah, you could also have a lambda. And so that's going to be passed in each index. And you would just want to return the dls.gov. At I. So that does the same thing. Now obviously this is tiny. So it doesn't actually matter. But I've tried to show the neat trick, which almost nobody knows about, which is the mapping. Okay. So we basically want to use that as our labels. So I think we can go SS. So we can go to the label equals dots. There we go. Okay. So, you know, normally at this point, I would like visually check some results. And the easiest way to visually check some results is to go learn dot show results. And this is showing me the actual and the predicted and the accuracy is very high. So he's all correct. The problem is I don't know which of these are right. Which are wrong. So I have no idea what to look for. So I don't have that ability to do my normal checking. Okay, so we can say this is a CSV. To push in. There we go. Okay. So there's a few things we could do here. I guess probably the easiest one would be to use the Kaggle CLI. I was going to note something for the submission for the two CSV. I think you might have to do index equals false because I think right. I was going to say normally what I always do after that except this time, which I forgot is to do exclamation mark head to show me the first few lines. And yeah, so now we would see as to niche says we've got this extra column out the front, which is because the default is that it shows kind of the row number. Thanks to niche. And so that will fix it. And if we compare that to their sample. Yeah, it looks nice and similar. So that's good. So these are all kind of steps in the same thing. So I pop these all together and then we might. And. Oh, and there's no Kaggle installed on this machine. That's surprising. Okay. So generally minus help or minus minus sorry minus H or minus minus help normally gives you a quick version of help. And so. I want to do something with competitions competitions. Okay, there we go. And so we're going to do a submission. All right, we need a file for upload. And we're going to need the competition. And so I could go Kaggle competitions list pipe grip. Patty. That way I don't even have to. That's not what I expected to happen. Oh, I bet that pages it. Okay, so rather than grab, we should use minus S. And it's going to use a regular expression or something. I have a little bit of a few examples. Okay, so there's definitely something called space ship. All right. I will get a crew over here after all. And this is what it's called. So I don't know. Is it not active? Probably that's why it's active. Yeah. And I don't think it ought to matter. We need to go to the next table. Yeah. Or we need a capital letter. I agree. It's fine. But maybe it's group. Maybe this is considered in class. Yeah. Anyhow, so we were going to do a submission. And so we need to provide the file name. Minus F. Add a slash. Okay. And a message. Minus M. Initial con. Next. Next. Small. To epoch. Okay. And then the competition. And go. Took a while for a 70 K file. But so be it. Okay. So let's see if it's there. It is. How did we do? Oh, I see. Oh, I jumped to your leader position. 157. Out of. 167. So I'm guessing that there's a problem. With our submission, because it's. I think maybe what happened was the. Test files were not like. They got shuffled somehow. Like maybe when you did get. Image files, it got shuffled or something like that. I think sometimes that might happen. Yeah, that's a good question. Oh, yeah. Yeah. Yeah, that looks like that seems very likely. So we didn't do a much job of checking as we went. Yes. So they were expecting that 2001 would be first and we have 2000, 200,019 first. So that is not. Ideal. Yeah, this has happened to me sometimes too. It would be nice if get image files by default. Return things in a more sensible order. Anyway, it's good to see these problems. You know, we could just sort it, right? But. It looks like it works. It probably does work as long as they've got exactly the same number as long as they're all 123456 digits. If some of them are different numbers of digits, we can't sort it because this is sorting in string order. But yeah, maybe that's okay. Says that tail. Yes. 203469. 203469. Yeah, okay. Maybe we're fine then. So sorted. Obviously Daisy sorted returns the sorted version or a sort sorts in place. Okay. So. And those. Those. Okay. And so it's very nice to have things set up. You know, that you're doing things from the command line and notebooks and stuff so that when you screw up, which, you know, if you're anything like me, you always screw up. You can pretty quickly repeat the process. So I just hit up arrow. And just add sorted to our message. Literally and figuratively, hopefully. Welcome to the leaderboard. Not a very successful welcome. Okay. Oh, it's a bit better. It's not quite nine one. There we go. Good start. About in the middle. All right. So, does anybody have questions about. I see my question on the chat and I had the same problem. When we've been stalling Tim. We, this is in paper space. I assume Mike was the same. We can see the list of models, but it doesn't actually create the learner. It says name Tim is not defined. So you're going to, so. So actually, I was able to do that. Matt, I just restarted my kernel. Yeah. So just to explain when you see in Python, something is not defined. It means what it says. It means that that symbol. Python doesn't know what it is. And so there are. Two ways basically to define a symbol to create a symbol one is to say something like a equals one that defines the symbol called a. Right. Or another is to do something like to death. And that defines the symbol called f. Right. Or the other way to define symbols is to import them. So in this case, Tim is not defined means you have not imported Tim. Does that make sense. Yes, it does, but I. Yeah. It sort of I was importing Tim and running that command. I don't think it was working still. It will definitely work if you say import Tim, this will definitely work. So I'd say you might have reset your kernel or something and hadn't really run that cell. Yeah, if you say if you restart the kernel, it works. Yeah, if you say import module. Yeah. Oh, yeah, I mean, the other possibility is that you might have got a different message, which is something like this much or not found. And much or not found means, yeah, either you haven't been stored it, or if you have to have installed it, you might need to restart your kernel by clicking kernel restart. So it can like recheck what modules you have, since you just installed it. That's what I had got it. Great. Thank you. All right, well that was pretty successful, even if paper space wasn't. Thanks guys. And see you. Yeah, see you tomorrow. Thanks, joining. Thanks, Jeremy. Thank you. Thank you.
